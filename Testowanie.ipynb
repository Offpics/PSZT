{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pszt import net\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train_no_ignore_no_norm.npy')\n",
    "y_train = np.load('y_train_no_ignore_no_norm.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć pierwsza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 20, activation: relu\n",
      "2. Layer - input_dim: 20, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=20, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=20, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 641.00, accuracy: 66.2%\n",
      "Epoch: 100, loss: 700.54, accuracy: 58.2%\n",
      "Epoch: 150, loss: 683.58, accuracy: 61.5%\n",
      "Epoch: 200, loss: 654.28, accuracy: 71.7%\n",
      "Epoch: 250, loss: 607.63, accuracy: 72.3%\n",
      "Epoch: 300, loss: 627.81, accuracy: 73.6%\n",
      "Epoch: 350, loss: 677.18, accuracy: 70.8%\n",
      "Epoch: 400, loss: 664.83, accuracy: 72.9%\n",
      "Epoch: 450, loss: 715.49, accuracy: 57.2%\n",
      "Epoch: 500, loss: 683.78, accuracy: 60.8%\n",
      "Mean accuracy on T0: 66.38\n",
      "Mean losses on T0: 685.68\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 707.99, accuracy: 56.0%\n",
      "Epoch: 100, loss: 659.44, accuracy: 67.1%\n",
      "Epoch: 150, loss: 709.71, accuracy: 66.2%\n",
      "Epoch: 200, loss: 653.35, accuracy: 69.5%\n",
      "Epoch: 250, loss: 674.95, accuracy: 70.3%\n",
      "Epoch: 300, loss: 693.08, accuracy: 70.6%\n",
      "Epoch: 350, loss: 728.93, accuracy: 67.7%\n",
      "Epoch: 400, loss: 778.79, accuracy: 71.1%\n",
      "Epoch: 450, loss: 699.98, accuracy: 70.6%\n",
      "Epoch: 500, loss: 729.15, accuracy: 70.7%\n",
      "Mean accuracy on T1: 65.72\n",
      "Mean losses on T1: 718.30\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 696.79, accuracy: 57.3%\n",
      "Epoch: 100, loss: 647.04, accuracy: 61.4%\n",
      "Epoch: 150, loss: 710.58, accuracy: 57.3%\n",
      "Epoch: 200, loss: 710.69, accuracy: 57.3%\n",
      "Epoch: 250, loss: 710.71, accuracy: 57.3%\n",
      "Epoch: 300, loss: 618.62, accuracy: 68.6%\n",
      "Epoch: 350, loss: 700.61, accuracy: 59.1%\n",
      "Epoch: 400, loss: 656.80, accuracy: 69.3%\n",
      "Epoch: 450, loss: 653.78, accuracy: 71.2%\n",
      "Epoch: 500, loss: 669.65, accuracy: 67.7%\n",
      "Mean accuracy on T2: 61.88\n",
      "Mean losses on T2: 692.98\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 613.47, accuracy: 66.8%\n",
      "Epoch: 100, loss: 727.04, accuracy: 67.0%\n",
      "Epoch: 150, loss: 583.95, accuracy: 70.7%\n",
      "Epoch: 200, loss: 584.72, accuracy: 71.2%\n",
      "Epoch: 250, loss: 573.55, accuracy: 73.7%\n",
      "Epoch: 300, loss: 806.87, accuracy: 63.6%\n",
      "Epoch: 350, loss: 799.20, accuracy: 72.1%\n",
      "Epoch: 400, loss: 682.17, accuracy: 72.9%\n",
      "Epoch: 450, loss: 619.06, accuracy: 75.6%\n",
      "Epoch: 500, loss: 714.61, accuracy: 73.6%\n",
      "Mean accuracy on T3: 68.64\n",
      "Mean losses on T3: 668.94\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 50, loss: 599.20, accuracy: 70.4%\n",
      "Epoch: 100, loss: 554.90, accuracy: 72.6%\n",
      "Epoch: 150, loss: 533.88, accuracy: 72.5%\n",
      "Epoch: 200, loss: 577.72, accuracy: 71.6%\n",
      "Epoch: 250, loss: 537.73, accuracy: 75.3%\n",
      "Epoch: 300, loss: 522.70, accuracy: 74.7%\n",
      "Epoch: 350, loss: 594.69, accuracy: 74.1%\n",
      "Epoch: 400, loss: 571.58, accuracy: 77.1%\n",
      "Epoch: 450, loss: 659.94, accuracy: 75.8%\n",
      "Epoch: 500, loss: 762.66, accuracy: 72.0%\n",
      "Mean accuracy on T4: 70.92\n",
      "Mean losses on T4: 622.82\n",
      "\n",
      "Accuracy list on Ti sets: [66.38291721419185, 65.7203679369251, 61.87621550591327, 68.63837056504599, 70.92447368421054]\n",
      "Losses list on Ti sets: [685.67809980074, 718.296398495828, 692.9848012741649, 668.9407959450543, 622.8162076414782]\n",
      "Mean accuracy on all T sets: 66.71\n",
      "Mean losses on all T sets: 677.74\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć druga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 20, activation: sigmoid\n",
      "2. Layer - input_dim: 20, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=20, activation=\"sigmoid\")\n",
    "\n",
    "mlp.add_layer(input_dim=20, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 647.93, accuracy: 63.3%\n",
      "Epoch: 100, loss: 589.15, accuracy: 69.9%\n",
      "Epoch: 150, loss: 658.97, accuracy: 67.5%\n",
      "Epoch: 200, loss: 629.80, accuracy: 69.1%\n",
      "Epoch: 250, loss: 612.33, accuracy: 70.3%\n",
      "Epoch: 300, loss: 601.79, accuracy: 70.7%\n",
      "Epoch: 350, loss: 599.19, accuracy: 69.8%\n",
      "Epoch: 400, loss: 905.66, accuracy: 65.4%\n",
      "Epoch: 450, loss: 553.43, accuracy: 73.2%\n",
      "Epoch: 500, loss: 557.91, accuracy: 74.0%\n",
      "Mean accuracy on T0: 68.94\n",
      "Mean losses on T0: 629.21\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 630.63, accuracy: 65.4%\n",
      "Epoch: 100, loss: 564.53, accuracy: 71.5%\n",
      "Epoch: 150, loss: 573.42, accuracy: 69.9%\n",
      "Epoch: 200, loss: 599.45, accuracy: 69.3%\n",
      "Epoch: 250, loss: 581.96, accuracy: 70.2%\n",
      "Epoch: 300, loss: 574.97, accuracy: 71.0%\n",
      "Epoch: 350, loss: 577.04, accuracy: 71.4%\n",
      "Epoch: 400, loss: 546.17, accuracy: 73.3%\n",
      "Epoch: 450, loss: 514.01, accuracy: 76.6%\n",
      "Epoch: 500, loss: 515.29, accuracy: 77.3%\n",
      "Mean accuracy on T1: 69.80\n",
      "Mean losses on T1: 598.58\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 619.06, accuracy: 66.4%\n",
      "Epoch: 100, loss: 557.25, accuracy: 70.8%\n",
      "Epoch: 150, loss: 630.79, accuracy: 66.5%\n",
      "Epoch: 200, loss: 630.15, accuracy: 66.8%\n",
      "Epoch: 250, loss: 630.87, accuracy: 67.9%\n",
      "Epoch: 300, loss: 633.07, accuracy: 68.3%\n",
      "Epoch: 350, loss: 601.95, accuracy: 70.8%\n",
      "Epoch: 400, loss: 806.87, accuracy: 66.8%\n",
      "Epoch: 450, loss: 523.54, accuracy: 75.0%\n",
      "Epoch: 500, loss: 606.45, accuracy: 72.3%\n",
      "Mean accuracy on T2: 69.97\n",
      "Mean losses on T2: 604.62\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 615.14, accuracy: 66.2%\n",
      "Epoch: 100, loss: 551.33, accuracy: 72.3%\n",
      "Epoch: 150, loss: 528.72, accuracy: 74.1%\n",
      "Epoch: 200, loss: 564.46, accuracy: 73.1%\n",
      "Epoch: 250, loss: 551.33, accuracy: 72.8%\n",
      "Epoch: 300, loss: 534.99, accuracy: 74.6%\n",
      "Epoch: 350, loss: 520.45, accuracy: 76.0%\n",
      "Epoch: 400, loss: 500.13, accuracy: 77.0%\n",
      "Epoch: 450, loss: 508.10, accuracy: 77.5%\n",
      "Epoch: 500, loss: 494.79, accuracy: 75.0%\n",
      "Mean accuracy on T3: 71.33\n",
      "Mean losses on T3: 582.20\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 50, loss: 647.73, accuracy: 64.6%\n",
      "Epoch: 100, loss: 593.10, accuracy: 70.0%\n",
      "Epoch: 150, loss: 669.27, accuracy: 65.7%\n",
      "Epoch: 200, loss: 651.47, accuracy: 67.0%\n",
      "Epoch: 250, loss: 634.46, accuracy: 67.9%\n",
      "Epoch: 300, loss: 622.69, accuracy: 67.9%\n",
      "Epoch: 350, loss: 617.25, accuracy: 70.5%\n",
      "Epoch: 400, loss: 593.74, accuracy: 71.3%\n",
      "Epoch: 450, loss: 566.17, accuracy: 73.6%\n",
      "Epoch: 500, loss: 571.79, accuracy: 75.0%\n",
      "Mean accuracy on T4: 68.01\n",
      "Mean losses on T4: 643.93\n",
      "\n",
      "Accuracy list on Ti sets: [68.94113009198423, 69.8018396846255, 69.97187910643889, 71.32798948751643, 68.00684210526316]\n",
      "Losses list on Ti sets: [629.2099875582187, 598.5769329510384, 604.6245697442281, 582.1984295564115, 643.9337319692917]\n",
      "Mean accuracy on all T sets: 69.61\n",
      "Mean losses on all T sets: 611.71\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć trzecia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 100, activation: relu\n",
      "2. Layer - input_dim: 100, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=100, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=100, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 653.50, accuracy: 64.8%\n",
      "Epoch: 100, loss: 644.15, accuracy: 66.8%\n",
      "Epoch: 150, loss: 616.62, accuracy: 67.7%\n",
      "Epoch: 200, loss: 663.09, accuracy: 69.4%\n",
      "Epoch: 250, loss: 611.76, accuracy: 67.9%\n",
      "Epoch: 300, loss: 737.54, accuracy: 66.1%\n",
      "Epoch: 350, loss: 579.06, accuracy: 69.0%\n",
      "Epoch: 400, loss: 620.02, accuracy: 69.9%\n",
      "Epoch: 450, loss: 593.53, accuracy: 69.3%\n",
      "Epoch: 500, loss: 772.82, accuracy: 72.4%\n",
      "Mean accuracy on T0: 65.87\n",
      "Mean losses on T0: 684.32\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 600.03, accuracy: 67.0%\n",
      "Epoch: 100, loss: 603.83, accuracy: 69.6%\n",
      "Epoch: 150, loss: 647.90, accuracy: 65.8%\n",
      "Epoch: 200, loss: 566.96, accuracy: 71.4%\n",
      "Epoch: 250, loss: 603.34, accuracy: 71.4%\n",
      "Epoch: 300, loss: 746.44, accuracy: 64.3%\n",
      "Epoch: 350, loss: 645.97, accuracy: 72.4%\n",
      "Epoch: 400, loss: 732.29, accuracy: 72.0%\n",
      "Epoch: 450, loss: 645.08, accuracy: 74.4%\n",
      "Epoch: 500, loss: 590.95, accuracy: 77.1%\n",
      "Mean accuracy on T1: 69.25\n",
      "Mean losses on T1: 653.57\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 580.36, accuracy: 70.2%\n",
      "Epoch: 100, loss: 593.16, accuracy: 70.6%\n",
      "Epoch: 150, loss: 691.75, accuracy: 62.3%\n",
      "Epoch: 200, loss: 714.70, accuracy: 67.4%\n",
      "Epoch: 250, loss: 642.24, accuracy: 70.2%\n",
      "Epoch: 300, loss: 828.94, accuracy: 39.2%\n",
      "Epoch: 350, loss: 661.46, accuracy: 71.7%\n",
      "Epoch: 400, loss: 735.63, accuracy: 70.7%\n",
      "Epoch: 450, loss: 1263.31, accuracy: 57.7%\n",
      "Epoch: 500, loss: 622.85, accuracy: 65.3%\n",
      "Mean accuracy on T2: 64.82\n",
      "Mean losses on T2: 703.91\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 682.60, accuracy: 53.9%\n",
      "Epoch: 100, loss: 736.51, accuracy: 56.9%\n",
      "Epoch: 150, loss: 830.74, accuracy: 54.8%\n",
      "Epoch: 200, loss: 619.67, accuracy: 68.5%\n",
      "Epoch: 250, loss: 711.78, accuracy: 54.8%\n",
      "Epoch: 300, loss: 564.39, accuracy: 71.0%\n",
      "Epoch: 350, loss: 610.44, accuracy: 69.0%\n",
      "Epoch: 400, loss: 616.10, accuracy: 72.3%\n",
      "Epoch: 450, loss: 603.01, accuracy: 66.5%\n",
      "Epoch: 500, loss: 859.48, accuracy: 71.5%\n",
      "Mean accuracy on T3: 63.42\n",
      "Mean losses on T3: 694.39\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 50, loss: 588.42, accuracy: 69.5%\n",
      "Epoch: 100, loss: 603.86, accuracy: 68.4%\n",
      "Epoch: 150, loss: 579.35, accuracy: 73.2%\n",
      "Epoch: 200, loss: 578.38, accuracy: 70.8%\n",
      "Epoch: 250, loss: 554.58, accuracy: 75.9%\n",
      "Epoch: 300, loss: 685.55, accuracy: 71.4%\n",
      "Epoch: 350, loss: 592.47, accuracy: 77.8%\n",
      "Epoch: 400, loss: 633.74, accuracy: 73.9%\n",
      "Epoch: 450, loss: 873.33, accuracy: 67.1%\n",
      "Epoch: 500, loss: 746.13, accuracy: 69.2%\n",
      "Mean accuracy on T4: 68.54\n",
      "Mean losses on T4: 669.59\n",
      "\n",
      "Accuracy list on Ti sets: [65.8664914586071, 69.2533508541393, 64.81892247043363, 63.417345597897494, 68.54394736842107]\n",
      "Losses list on Ti sets: [684.3197152686557, 653.572010315565, 703.9138332821601, 694.3938502994126, 669.5881828589746]\n",
      "Mean accuracy on all T sets: 66.38\n",
      "Mean losses on all T sets: 681.16\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć czwarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 100, activation: sigmoid\n",
      "2. Layer - input_dim: 100, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=100, activation=\"sigmoid\")\n",
    "\n",
    "mlp.add_layer(input_dim=100, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 710.66, accuracy: 55.2%\n",
      "Epoch: 100, loss: 708.82, accuracy: 57.2%\n",
      "Epoch: 150, loss: 646.13, accuracy: 66.0%\n",
      "Epoch: 200, loss: 636.84, accuracy: 67.4%\n",
      "Epoch: 250, loss: 645.56, accuracy: 67.0%\n",
      "Epoch: 300, loss: 657.75, accuracy: 67.5%\n",
      "Epoch: 350, loss: 656.48, accuracy: 68.6%\n",
      "Epoch: 400, loss: 650.50, accuracy: 69.9%\n",
      "Epoch: 450, loss: 606.43, accuracy: 71.7%\n",
      "Epoch: 500, loss: 563.99, accuracy: 73.6%\n",
      "Mean accuracy on T0: 67.57\n",
      "Mean losses on T0: 676.87\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 680.99, accuracy: 57.4%\n",
      "Epoch: 100, loss: 648.29, accuracy: 61.2%\n",
      "Epoch: 150, loss: 589.97, accuracy: 67.9%\n",
      "Epoch: 200, loss: 570.71, accuracy: 69.9%\n",
      "Epoch: 250, loss: 570.94, accuracy: 70.4%\n",
      "Epoch: 300, loss: 567.72, accuracy: 70.4%\n",
      "Epoch: 350, loss: 550.99, accuracy: 72.3%\n",
      "Epoch: 400, loss: 551.81, accuracy: 72.5%\n",
      "Epoch: 450, loss: 558.45, accuracy: 73.3%\n",
      "Epoch: 500, loss: 567.02, accuracy: 74.0%\n",
      "Mean accuracy on T1: 67.94\n",
      "Mean losses on T1: 658.26\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 700.13, accuracy: 58.1%\n",
      "Epoch: 100, loss: 687.89, accuracy: 60.6%\n",
      "Epoch: 150, loss: 653.01, accuracy: 66.0%\n",
      "Epoch: 200, loss: 645.22, accuracy: 66.8%\n",
      "Epoch: 250, loss: 645.99, accuracy: 67.7%\n",
      "Epoch: 300, loss: 652.25, accuracy: 67.9%\n",
      "Epoch: 350, loss: 660.12, accuracy: 68.7%\n",
      "Epoch: 400, loss: 666.14, accuracy: 68.9%\n",
      "Epoch: 450, loss: 647.12, accuracy: 70.3%\n",
      "Epoch: 500, loss: 635.05, accuracy: 72.1%\n",
      "Mean accuracy on T2: 65.70\n",
      "Mean losses on T2: 732.40\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 655.73, accuracy: 59.1%\n",
      "Epoch: 100, loss: 632.30, accuracy: 62.7%\n",
      "Epoch: 150, loss: 595.18, accuracy: 68.2%\n",
      "Epoch: 200, loss: 578.90, accuracy: 70.3%\n",
      "Epoch: 250, loss: 577.47, accuracy: 71.1%\n",
      "Epoch: 300, loss: 564.43, accuracy: 72.1%\n",
      "Epoch: 350, loss: 553.15, accuracy: 72.9%\n",
      "Epoch: 400, loss: 545.33, accuracy: 73.7%\n",
      "Epoch: 450, loss: 509.27, accuracy: 76.2%\n",
      "Epoch: 500, loss: 513.33, accuracy: 76.7%\n",
      "Mean accuracy on T3: 68.96\n",
      "Mean losses on T3: 658.82\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 50, loss: 718.44, accuracy: 53.9%\n",
      "Epoch: 100, loss: 697.74, accuracy: 58.2%\n",
      "Epoch: 150, loss: 643.42, accuracy: 65.7%\n",
      "Epoch: 200, loss: 623.88, accuracy: 67.6%\n",
      "Epoch: 250, loss: 625.24, accuracy: 68.4%\n",
      "Epoch: 300, loss: 627.63, accuracy: 69.2%\n",
      "Epoch: 350, loss: 610.21, accuracy: 70.3%\n",
      "Epoch: 400, loss: 602.37, accuracy: 70.9%\n",
      "Epoch: 450, loss: 600.62, accuracy: 71.6%\n",
      "Epoch: 500, loss: 601.68, accuracy: 72.4%\n",
      "Mean accuracy on T4: 67.09\n",
      "Mean losses on T4: 674.77\n",
      "\n",
      "Accuracy list on Ti sets: [67.57319316688567, 67.94034165571615, 65.69671484888305, 68.96425755584757, 67.09236842105264]\n",
      "Losses list on Ti sets: [676.8652664421589, 658.2563124383411, 732.4027039979599, 658.8172579860947, 674.7653357897624]\n",
      "Mean accuracy on all T sets: 67.45\n",
      "Mean losses on all T sets: 680.22\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć piąta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 1500, activation: relu\n",
      "2. Layer - input_dim: 1500, output_dim: 750, activation: relu\n",
      "3. Layer - input_dim: 750, output_dim: 300, activation: relu\n",
      "4. Layer - input_dim: 300, output_dim: 100, activation: relu\n",
      "5. Layer - input_dim: 100, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=1500, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=1500, output_dim=750, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=750, output_dim=300, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=300, output_dim=100, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=100, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 676.97, accuracy: 59.3%\n",
      "Epoch: 100, loss: 710.56, accuracy: 56.8%\n",
      "Epoch: 150, loss: 710.60, accuracy: 56.8%\n",
      "Epoch: 200, loss: 710.60, accuracy: 56.8%\n",
      "Epoch: 250, loss: 710.60, accuracy: 56.8%\n",
      "Epoch: 300, loss: 710.60, accuracy: 56.8%\n",
      "Epoch: 350, loss: 710.60, accuracy: 56.8%\n",
      "Epoch: 400, loss: 710.60, accuracy: 56.8%\n",
      "Epoch: 450, loss: 710.60, accuracy: 56.8%\n",
      "Epoch: 500, loss: 710.60, accuracy: 56.8%\n",
      "Mean accuracy on T0: 56.64\n",
      "Mean losses on T0: 715.74\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 698.39, accuracy: 59.8%\n",
      "Epoch: 100, loss: 695.60, accuracy: 59.8%\n",
      "Epoch: 150, loss: 698.45, accuracy: 59.8%\n",
      "Epoch: 200, loss: 698.41, accuracy: 59.8%\n",
      "Epoch: 250, loss: 697.29, accuracy: 59.7%\n",
      "Epoch: 300, loss: 698.45, accuracy: 59.8%\n",
      "Epoch: 350, loss: 698.45, accuracy: 59.8%\n",
      "Epoch: 400, loss: 698.45, accuracy: 59.8%\n",
      "Epoch: 450, loss: 698.45, accuracy: 59.8%\n",
      "Epoch: 500, loss: 698.45, accuracy: 59.8%\n",
      "Mean accuracy on T1: 59.60\n",
      "Mean losses on T1: 710.58\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 642.21, accuracy: 64.1%\n",
      "Epoch: 100, loss: 719.34, accuracy: 53.7%\n",
      "Epoch: 150, loss: 700.47, accuracy: 53.7%\n",
      "Epoch: 200, loss: 716.75, accuracy: 53.7%\n",
      "Epoch: 250, loss: 716.75, accuracy: 53.7%\n",
      "Epoch: 300, loss: 716.75, accuracy: 53.7%\n",
      "Epoch: 350, loss: 716.75, accuracy: 53.7%\n",
      "Epoch: 400, loss: 716.75, accuracy: 53.7%\n",
      "Epoch: 450, loss: 716.75, accuracy: 53.7%\n",
      "Epoch: 500, loss: 716.75, accuracy: 53.7%\n",
      "Mean accuracy on T2: 53.79\n",
      "Mean losses on T2: 725.31\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 713.95, accuracy: 57.2%\n",
      "Epoch: 100, loss: 714.70, accuracy: 57.2%\n",
      "Epoch: 150, loss: 1353.81, accuracy: 57.2%\n",
      "Epoch: 200, loss: 714.45, accuracy: 57.2%\n",
      "Epoch: 250, loss: 714.45, accuracy: 57.2%\n",
      "Epoch: 300, loss: 714.45, accuracy: 57.2%\n",
      "Epoch: 350, loss: 714.45, accuracy: 57.2%\n",
      "Epoch: 400, loss: 714.45, accuracy: 57.2%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cb5c2e9f41aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_fold_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/version-control/pszt-projekt/pszt/net.py\u001b[0m in \u001b[0;36mk_fold_validation\u001b[0;34m(self, x, y_true, k, epochs)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;31m# Perform training and update weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/version-control/pszt-projekt/pszt/net.py\u001b[0m in \u001b[0;36m_backward\u001b[0;34m(self, x, y_true)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;31m# Calculate derivatives.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mdz_dw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0mdcost_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdz_dw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdcost_dz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mdcost_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcost_dz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
