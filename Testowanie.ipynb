{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pszt import net\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train_no_ignore_no_norm.npy')\n",
    "y_train = np.load('y_train_no_ignore_no_norm.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć pierwsza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 10, activation: relu\n",
      "2. Layer - input_dim: 10, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=10, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=10, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: 0, Len of fold: 3043\n",
      "loss: 3549.43, accuracy: 11.0%\n",
      "loss: 2819.72, accuracy: 57.2%\n",
      "loss: 2109.24, accuracy: 74.6%\n",
      "loss: 1932.93, accuracy: 78.4%\n",
      "loss: 2656.46, accuracy: 67.7%\n",
      "loss: 2058.39, accuracy: 75.4%\n",
      "loss: 1663.16, accuracy: 81.2%\n",
      "loss: 1630.54, accuracy: 82.0%\n",
      "loss: 1812.26, accuracy: 80.6%\n",
      "loss: 1812.31, accuracy: 79.4%\n",
      "loss: 1456.71, accuracy: 83.2% | last epoch\n",
      "Current fold: 1, Len of fold: 3043\n",
      "loss: 3278.53, accuracy: 32.2%\n",
      "loss: 2507.83, accuracy: 69.6%\n",
      "loss: 2073.52, accuracy: 76.0%\n",
      "loss: 1989.82, accuracy: 78.8%\n",
      "loss: 1640.40, accuracy: 81.2%\n",
      "loss: 1637.64, accuracy: 79.8%\n",
      "loss: 2248.17, accuracy: 71.9%\n",
      "loss: 1149.36, accuracy: 88.5%\n",
      "loss: 1095.56, accuracy: 89.6%\n",
      "loss: 1051.88, accuracy: 89.4%\n",
      "loss: 1579.72, accuracy: 84.4% | last epoch\n",
      "Current fold: 2, Len of fold: 3043\n",
      "loss: 3279.48, accuracy: 57.0%\n",
      "loss: 2520.29, accuracy: 67.9%\n",
      "loss: 2040.83, accuracy: 72.9%\n",
      "loss: 2450.46, accuracy: 68.3%\n",
      "loss: 1614.61, accuracy: 80.0%\n",
      "loss: 1585.66, accuracy: 78.7%\n",
      "loss: 1572.07, accuracy: 80.5%\n",
      "loss: 1625.94, accuracy: 81.8%\n",
      "loss: 2603.39, accuracy: 70.2%\n",
      "loss: 2028.18, accuracy: 76.8%\n",
      "loss: 2250.56, accuracy: 72.1% | last epoch\n",
      "Current fold: 3, Len of fold: 3043\n",
      "loss: 3451.01, accuracy: 11.2%\n",
      "loss: 2845.36, accuracy: 57.9%\n",
      "loss: 2052.13, accuracy: 74.7%\n",
      "loss: 1850.95, accuracy: 77.1%\n",
      "loss: 2246.95, accuracy: 62.8%\n",
      "loss: 1975.00, accuracy: 75.1%\n",
      "loss: 1373.47, accuracy: 80.6%\n",
      "loss: 1286.78, accuracy: 82.8%\n",
      "loss: 1337.62, accuracy: 81.8%\n",
      "loss: 2354.08, accuracy: 59.8%\n",
      "loss: 1117.96, accuracy: 83.9% | last epoch\n",
      "Current fold: 4, Len of fold: 3044\n",
      "loss: 3525.07, accuracy: 10.9%\n",
      "loss: 2240.38, accuracy: 73.2%\n",
      "loss: 2824.73, accuracy: 56.8%\n",
      "loss: 2152.94, accuracy: 74.5%\n",
      "loss: 2158.59, accuracy: 74.0%\n",
      "loss: 2085.75, accuracy: 76.0%\n",
      "loss: 2609.73, accuracy: 68.5%\n",
      "loss: 1557.89, accuracy: 82.3%\n",
      "loss: 1766.87, accuracy: 80.2%\n",
      "loss: 1596.80, accuracy: 82.1%\n",
      "loss: 2333.11, accuracy: 70.2% | last epoch\n",
      "Accuracies on k_folds: [71.35348226018397, 75.42706964520369, 69.38239159001314, 71.48488830486203, 70.13157894736842]\n",
      "Losses on k_fold: [2130.3593489593827, 1947.2448569265773, 1974.7733688153996, 1960.820003968541, 2007.7564195487082]\n",
      "Mean of accuracies: 71.55588214952624\n",
      "Mean of losses: 2004.1907996437217\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć druga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 10, activation: sigmoid\n",
      "2. Layer - input_dim: 10, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=10, activation=\"sigmoid\")\n",
    "\n",
    "mlp.add_layer(input_dim=10, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: 0, Len of fold: 3043\n",
      "loss: 4009.09, accuracy: 11.4%\n",
      "loss: 2189.46, accuracy: 73.1%\n",
      "loss: 2120.07, accuracy: 70.9%\n",
      "loss: 1864.31, accuracy: 75.9%\n",
      "loss: 1613.06, accuracy: 80.3%\n",
      "loss: 1373.70, accuracy: 84.1%\n",
      "loss: 1147.44, accuracy: 87.2%\n",
      "loss: 935.32, accuracy: 90.3%\n",
      "loss: 789.64, accuracy: 91.9%\n",
      "loss: 547.64, accuracy: 93.8%\n",
      "loss: 476.44, accuracy: 95.5% | last epoch\n",
      "Current fold: 1, Len of fold: 3043\n",
      "loss: 3091.42, accuracy: 50.1%\n",
      "loss: 2413.41, accuracy: 68.5%\n",
      "loss: 2082.44, accuracy: 71.5%\n",
      "loss: 1789.31, accuracy: 76.5%\n",
      "loss: 1450.20, accuracy: 81.1%\n",
      "loss: 1050.12, accuracy: 85.5%\n",
      "loss: 1632.03, accuracy: 80.7%\n",
      "loss: 2289.26, accuracy: 63.5%\n",
      "loss: 528.98, accuracy: 94.5%\n",
      "loss: 454.30, accuracy: 95.7%\n",
      "loss: 389.27, accuracy: 96.2% | last epoch\n",
      "Current fold: 2, Len of fold: 3043\n",
      "loss: 2916.65, accuracy: 57.1%\n",
      "loss: 2264.41, accuracy: 69.5%\n",
      "loss: 2096.48, accuracy: 71.0%\n",
      "loss: 1747.75, accuracy: 76.8%\n",
      "loss: 1396.61, accuracy: 80.3%\n",
      "loss: 1177.37, accuracy: 86.4%\n",
      "loss: 842.23, accuracy: 90.7%\n",
      "loss: 622.92, accuracy: 92.7%\n",
      "loss: 515.34, accuracy: 94.5%\n",
      "loss: 486.53, accuracy: 95.0%\n",
      "loss: 400.67, accuracy: 96.0% | last epoch\n",
      "Current fold: 3, Len of fold: 3043\n",
      "loss: 3197.43, accuracy: 56.5%\n",
      "loss: 2316.54, accuracy: 68.8%\n",
      "loss: 2107.55, accuracy: 71.4%\n",
      "loss: 1755.66, accuracy: 77.0%\n",
      "loss: 1357.05, accuracy: 82.3%\n",
      "loss: 1188.69, accuracy: 84.6%\n",
      "loss: 842.97, accuracy: 90.5%\n",
      "loss: 793.50, accuracy: 91.6%\n",
      "loss: 684.67, accuracy: 93.2%\n",
      "loss: 465.14, accuracy: 95.6%\n",
      "loss: 439.62, accuracy: 95.6% | last epoch\n",
      "Current fold: 4, Len of fold: 3044\n",
      "loss: 3196.54, accuracy: 32.2%\n",
      "loss: 2208.74, accuracy: 70.5%\n",
      "loss: 2064.72, accuracy: 72.0%\n",
      "loss: 1748.64, accuracy: 77.2%\n",
      "loss: 1423.83, accuracy: 81.7%\n",
      "loss: 1095.73, accuracy: 85.1%\n",
      "loss: 862.05, accuracy: 88.9%\n",
      "loss: 1165.18, accuracy: 84.2%\n",
      "loss: 534.27, accuracy: 94.3%\n",
      "loss: 476.70, accuracy: 95.0%\n",
      "loss: 398.53, accuracy: 95.8% | last epoch\n",
      "Accuracies on k_folds: [75.29566360052561, 75.68988173455979, 74.24441524310119, 76.08409986859395, 73.94736842105263]\n",
      "Losses on k_fold: [1553.1701561106054, 1496.9039772525794, 1473.4042539906097, 1473.3542782802133, 1461.239974157161]\n",
      "Mean of accuracies: 75.05228577356664\n",
      "Mean of losses: 1491.6145279582338\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć trzecia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 100, activation: relu\n",
      "2. Layer - input_dim: 100, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=100, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=100, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: 0, Len of fold: 3043\n",
      "loss: 3337.21, accuracy: 41.7%\n",
      "loss: 2353.78, accuracy: 72.0%\n",
      "loss: 1800.34, accuracy: 75.4%\n",
      "loss: 1444.55, accuracy: 82.2%\n",
      "loss: 1625.58, accuracy: 77.2%\n",
      "loss: 2415.65, accuracy: 62.8%\n",
      "loss: 1658.45, accuracy: 78.5%\n",
      "loss: 843.27, accuracy: 88.6%\n",
      "loss: 2199.40, accuracy: 68.5%\n",
      "loss: 1689.49, accuracy: 78.3%\n",
      "loss: 678.40, accuracy: 89.5% | last epoch\n",
      "Current fold: 1, Len of fold: 3043\n",
      "loss: 3305.64, accuracy: 32.4%\n",
      "loss: 2433.57, accuracy: 68.1%\n",
      "loss: 1983.20, accuracy: 73.3%\n",
      "loss: 2389.74, accuracy: 64.5%\n",
      "loss: 1376.09, accuracy: 80.9%\n",
      "loss: 2992.78, accuracy: 42.8%\n",
      "loss: 1146.05, accuracy: 86.4%\n",
      "loss: 1444.15, accuracy: 81.0%\n",
      "loss: 1293.84, accuracy: 79.6%\n",
      "loss: 1393.44, accuracy: 81.2%\n",
      "loss: 1685.16, accuracy: 74.7% | last epoch\n",
      "Current fold: 2, Len of fold: 3043\n",
      "loss: 3303.59, accuracy: 57.0%\n",
      "loss: 2221.59, accuracy: 71.9%\n",
      "loss: 1674.33, accuracy: 79.0%\n",
      "loss: 1560.47, accuracy: 79.5%\n",
      "loss: 1404.49, accuracy: 80.1%\n",
      "loss: 739.45, accuracy: 92.0%\n",
      "loss: 1694.31, accuracy: 76.5%\n",
      "loss: 1088.20, accuracy: 84.5%\n",
      "loss: 1579.24, accuracy: 78.1%\n",
      "loss: 788.62, accuracy: 86.2%\n",
      "loss: 1074.98, accuracy: 85.4% | last epoch\n",
      "Current fold: 3, Len of fold: 3043\n",
      "loss: 3396.14, accuracy: 11.3%\n",
      "loss: 2165.14, accuracy: 70.5%\n",
      "loss: 2188.95, accuracy: 65.7%\n",
      "loss: 2970.21, accuracy: 54.9%\n",
      "loss: 1561.75, accuracy: 79.4%\n",
      "loss: 1936.08, accuracy: 70.7%\n",
      "loss: 1684.98, accuracy: 77.5%\n",
      "loss: 935.51, accuracy: 89.4%\n",
      "loss: 487.92, accuracy: 94.1%\n",
      "loss: 972.84, accuracy: 87.9%\n",
      "loss: 480.88, accuracy: 94.5% | last epoch\n",
      "Current fold: 4, Len of fold: 3044\n",
      "loss: 3323.77, accuracy: 56.3%\n",
      "loss: 2398.93, accuracy: 71.9%\n",
      "loss: 1799.54, accuracy: 76.1%\n",
      "loss: 1932.25, accuracy: 77.2%\n",
      "loss: 1669.31, accuracy: 76.5%\n",
      "loss: 1405.76, accuracy: 75.5%\n",
      "loss: 2019.71, accuracy: 66.2%\n",
      "loss: 1748.84, accuracy: 78.0%\n",
      "loss: 667.65, accuracy: 90.7%\n",
      "loss: 1485.75, accuracy: 79.4%\n",
      "loss: 1292.85, accuracy: 82.4% | last epoch\n",
      "Accuracies on k_folds: [73.98160315374507, 55.97897503285151, 68.72536136662286, 75.9526938239159, 56.44736842105264]\n",
      "Losses on k_fold: [1713.1407961977718, 1756.3278579314679, 1705.7199422989156, 1674.106141802854, 1704.3425037502334]\n",
      "Mean of accuracies: 66.21720035963759\n",
      "Mean of losses: 1710.7274483962487\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć czwarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 100, activation: sigmoid\n",
      "2. Layer - input_dim: 100, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=100, activation=\"sigmoid\")\n",
    "\n",
    "mlp.add_layer(input_dim=100, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: 0, Len of fold: 3043\n",
      "loss: 3018.90, accuracy: 57.1%\n",
      "loss: 2699.26, accuracy: 65.4%\n",
      "loss: 2415.95, accuracy: 68.6%\n",
      "loss: 2215.51, accuracy: 71.0%\n",
      "loss: 2050.08, accuracy: 73.4%\n",
      "loss: 1872.62, accuracy: 75.2%\n",
      "loss: 1653.43, accuracy: 79.5%\n",
      "loss: 1406.92, accuracy: 83.2%\n",
      "loss: 1147.21, accuracy: 86.8%\n",
      "loss: 881.78, accuracy: 90.9%\n",
      "loss: 710.39, accuracy: 90.7% | last epoch\n",
      "Current fold: 1, Len of fold: 3043\n",
      "loss: 3187.08, accuracy: 56.8%\n",
      "loss: 2721.30, accuracy: 65.6%\n",
      "loss: 2443.36, accuracy: 68.8%\n",
      "loss: 2253.69, accuracy: 70.6%\n",
      "loss: 2080.99, accuracy: 73.0%\n",
      "loss: 1907.44, accuracy: 75.0%\n",
      "loss: 1728.14, accuracy: 78.0%\n",
      "loss: 1509.45, accuracy: 82.2%\n",
      "loss: 1206.44, accuracy: 86.0%\n",
      "loss: 946.40, accuracy: 89.6%\n",
      "loss: 784.00, accuracy: 89.8% | last epoch\n",
      "Current fold: 2, Len of fold: 3043\n",
      "loss: 3637.67, accuracy: 11.2%\n",
      "loss: 2612.83, accuracy: 61.9%\n",
      "loss: 2479.44, accuracy: 66.7%\n",
      "loss: 2270.58, accuracy: 71.2%\n",
      "loss: 2152.41, accuracy: 72.9%\n",
      "loss: 2042.81, accuracy: 74.2%\n",
      "loss: 1818.85, accuracy: 77.2%\n",
      "loss: 1486.81, accuracy: 80.6%\n",
      "loss: 1221.78, accuracy: 83.7%\n",
      "loss: 977.42, accuracy: 86.9%\n",
      "loss: 750.83, accuracy: 90.5% | last epoch\n",
      "Current fold: 3, Len of fold: 3043\n",
      "loss: 3464.30, accuracy: 11.1%\n",
      "loss: 2725.71, accuracy: 57.2%\n",
      "loss: 2517.20, accuracy: 65.6%\n",
      "loss: 2305.07, accuracy: 70.2%\n",
      "loss: 2168.31, accuracy: 72.5%\n",
      "loss: 2044.21, accuracy: 73.8%\n",
      "loss: 1890.31, accuracy: 76.0%\n",
      "loss: 1651.90, accuracy: 79.0%\n",
      "loss: 1392.36, accuracy: 82.1%\n",
      "loss: 1127.39, accuracy: 85.5%\n",
      "loss: 792.76, accuracy: 91.7% | last epoch\n",
      "Current fold: 4, Len of fold: 3044\n",
      "loss: 4093.24, accuracy: 11.1%\n",
      "loss: 2596.78, accuracy: 62.5%\n",
      "loss: 2468.12, accuracy: 67.1%\n",
      "loss: 2273.72, accuracy: 71.2%\n",
      "loss: 2149.54, accuracy: 72.8%\n",
      "loss: 1942.21, accuracy: 75.5%\n",
      "loss: 1642.58, accuracy: 79.3%\n",
      "loss: 1353.46, accuracy: 82.3%\n",
      "loss: 1089.48, accuracy: 85.4%\n",
      "loss: 1830.14, accuracy: 76.2%\n",
      "loss: 603.49, accuracy: 93.9% | last epoch\n",
      "Accuracies on k_folds: [72.93035479632063, 72.93035479632063, 73.06176084099869, 75.9526938239159, 74.60526315789474]\n",
      "Losses on k_fold: [2058.404658844914, 2077.3687390771584, 2082.8677897902294, 2099.5120148875044, 2085.8216150016824]\n",
      "Mean of accuracies: 73.89608548309012\n",
      "Mean of losses: 2080.7949635202976\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć piąta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 1500, activation: relu\n",
      "2. Layer - input_dim: 1500, output_dim: 750, activation: relu\n",
      "3. Layer - input_dim: 750, output_dim: 300, activation: relu\n",
      "4. Layer - input_dim: 300, output_dim: 100, activation: relu\n",
      "5. Layer - input_dim: 100, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=1500, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=1500, output_dim=750, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=750, output_dim=300, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=300, output_dim=100, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=100, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: 0, Len of fold: 3043\n",
      "loss: 3285.48, accuracy: 57.2%\n",
      "loss: 2822.35, accuracy: 57.2%\n",
      "loss: 2819.63, accuracy: 57.2%\n",
      "loss: 2822.45, accuracy: 57.2%\n",
      "loss: 2822.45, accuracy: 57.2%\n",
      "loss: 2822.45, accuracy: 57.2%\n",
      "loss: 2822.45, accuracy: 57.2%\n",
      "loss: 2822.45, accuracy: 57.2%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cb5c2e9f41aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_fold_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/version-control/pszt-projekt/pszt/net.py\u001b[0m in \u001b[0;36mk_fold_validation\u001b[0;34m(self, x, y_true, k, epochs)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Current fold: {i}, Len of fold: {len(x_tmp)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;31m# Train network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mloss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# Calculate cross_entropy_loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/version-control/pszt-projekt/pszt/net.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y_true, epochs, silent)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m# Perform forward propagation over neural network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# Perform backward propagation over neural network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/version-control/pszt-projekt/pszt/net.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Calculate input with weights and perform activation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
