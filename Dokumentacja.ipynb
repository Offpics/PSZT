{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dokumentacja projektu Sentiment Classification\n",
    "#### Aleksander Ogonowski\n",
    "   \n",
    "#### Paweł Rybak\n",
    "\n",
    "#### Kornel Szymczyk 267778\n",
    "\n",
    "##### 10 stycznia 2019 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instrukcja użytkownika\n",
    "\n",
    "Pakiet pszt zawiera dwa moduły:\n",
    "- refactor_csv.py zawierający funkcje pomocnicze do refaktoryzacji zbioru danych Tweetów dotyczących produktów Apple,\n",
    "- net.py zawierający klasę MLP, która jest definicją modelu sieci neuronowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Wymagania uruchomienia\n",
    "- Python 3.6+\n",
    "- Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Przekształcenie zbioru danych wykorzystując moduł refactor_csv.py\n",
    "\n",
    "Przed przystąpieniem do trenowania sieci neuronowej należy przekrzstałcić odpowiednio zbiór danych i zapisać go w nowym pliku csv. W tym celu korzystamy z funkcji *refactor(csv_path, new_csv_path)*. Pierwszy argument funkcji to ścieżka do pliku ze zbiorem danych w formacie *.csv*, drugi argument to ścieżka pliku, w którym zostanie zapisany przekształcony zbiór. \n",
    "\n",
    "Przykład kodu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pszt import refactor_csv\n",
    "\n",
    "# File path to the csv file.\n",
    "csv_path = 'Apple-Twitter-Sentiment-DFE.csv'\n",
    "\n",
    "# File path to the new csv file.\n",
    "new_csv_path = 'apple-twitter_example.csv'\n",
    "    \n",
    "refactor_csv.refactor(csv_path, new_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posiadając przekształcony zbiór plik csv należy przystąpić do wektoryzacji zbioru, w tym celu należy skorzystać z funkcji *vectorize_dataset(csv_path, x_train_path, y_train_path, ignore_words=None)*. Jej celem jest wykonanie przekształcenia zdań do modelu bag-of-words oraz zamiana sentymentu zdań (1, 3, 5) do postaci one-hot. Przekształcone zdania zapisywane są w tablicy numpy *x_train*, etykiety w tablicy numpy *y_train* oraz zapisywane są na dysku w formacie *.npy*. Pierwszy argument funkcji to ścieżka do pliku csv utworzonego przy pomocy funkcji *refactor()*, drugi argument to ścieżka pliku do zapisania tablicy *x_train*, trzeci argument to ścieżka pliku do zapisania tablicy *y_train* oraz ostatni argument przyjmuje opcjonalną tablicę słów, które mają być pomijane w zdaniach.\n",
    "\n",
    "Przykład kodu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "refactor_csv.vectorize_dataset(new_csv_path, 'x_train_no_ignore_no_norm', 'y_train_no_ignore_no_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train = np.load('x_train_no_ignore_no_norm.npy')\n",
    "np.max(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Trenowanie sieci neuronowej wykorzystując moduł net.py\n",
    "\n",
    "W celu wytrenowania sieci tworzymy obiekt klasy MLP. Następnie dodajemy warstwy sieci wykorzystując metodę *add_layer(input_dim, output_dim, activation)*. Pierwszy argument określa liczbę wejść do warstwy, drugi argument określa liczbę wyjść z warstwy, a ostatni określa rodzaj funkcji aktywacji ('relu', 'sigmoid', 'softmax'). Ze względu na to, że etykiety zbioru reprezentowane są w postaci one-hot, ostatnia warstwa powinna zawsze posiadać output_dim=3 oraz activation='softmax'. Model sieci został napisany w taki sposób, że należy pominąć dodawanie warstwy wejściowej sieci neurnowej, a input_dim pierwszej warstwy powinien odpowiadać długości wektora danych wejściowych. Po dodaniu warstw należy je zainicjalizować funkcją *init_layers()*.\n",
    "\n",
    "Proces trenowania wywołuje się funkcją *train(x, y_true, epochs, silent=False)*. Pierwszy argument to tablica numpy ze zdaniami w postaci bag-of-words, drugi argument to tablicy etykiet zdań w postaci one-hot, trzeci argument określa liczbę kroków trenowania, czwarty agrument opcjonalny określający czy wypisywać na ekran aktualny status trenowania sieci.\n",
    "\n",
    "Przykład kodu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3938.32, accuracy: 56.8%\n",
      "loss: 8875.00, accuracy: 56.8%\n",
      "loss: 23038.32, accuracy: 32.0%\n",
      "loss: 6041.75, accuracy: 56.8%\n",
      "loss: 4177.64, accuracy: 56.8%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pszt import net\n",
    "\n",
    "# Create a neural net.\n",
    "mlp = net.MLP();\n",
    "\n",
    "# Load dataset.\n",
    "x_train = np.load('x_train_3k.npy')\n",
    "y_train = np.load('y_train_3k.npy')\n",
    "\n",
    "# Add layers.\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=20, activation=\"sigmoid\")\n",
    "mlp.add_layer(input_dim=20, output_dim=3, activation=\"softmax\")\n",
    "\n",
    "# Initialize weights in layers.\n",
    "mlp.init_layers()\n",
    "\n",
    "# Train the neural net.\n",
    "mlp.train(x=x_train, y_true=y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasa MLP zawiera również metodę *k_fold_validation(x, y_true, k, epochs)*, która poddaje sieć neuronową walidacji k-fold.\n",
    "\n",
    "Przykład kodu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: 0, Len of fold: 761\n",
      "Current fold: 1, Len of fold: 761\n",
      "Current fold: 2, Len of fold: 761\n",
      "Current fold: 3, Len of fold: 761\n",
      "Accuracies on k_folds: [57.763157894736835, 57.763157894736835, 57.763157894736835, 57.763157894736835]\n",
      "Mean of accuracies: 57.763157894736835\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x=x_train, y_true=y_train, k=5, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Struktura programu\n",
    "\n",
    "# TODO: Opisać jak działa sieć. Najlepiej głównie skupić się na init_weights, forward i backward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kluczowe decyzje projektowe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Wnioski dotyczące osiągniętych rezultatów"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
