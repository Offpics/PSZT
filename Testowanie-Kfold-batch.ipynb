{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pszt import net\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train_no_ignore_no_norm.npy')\n",
    "y_train = np.load('y_train_no_ignore_no_norm.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć pierwsza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 20, activation: relu\n",
      "2. Layer - input_dim: 20, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=20, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=20, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 664.25, accuracy: 56.4%\n",
      "Epoch: 10, loss: 595.48, accuracy: 68.9%\n",
      "Epoch: 15, loss: 562.51, accuracy: 71.7%\n",
      "Epoch: 20, loss: 541.74, accuracy: 73.1%\n",
      "Epoch: 25, loss: 529.80, accuracy: 71.9%\n",
      "Epoch: 30, loss: 511.25, accuracy: 72.9%\n",
      "Epoch: 35, loss: 496.30, accuracy: 74.2%\n",
      "Epoch: 40, loss: 511.96, accuracy: 75.2%\n",
      "Epoch: 45, loss: 544.67, accuracy: 75.3%\n",
      "Epoch: 50, loss: 495.79, accuracy: 74.5%\n",
      "Epoch: 55, loss: 500.68, accuracy: 74.1%\n",
      "Epoch: 60, loss: 511.81, accuracy: 74.4%\n",
      "Epoch: 65, loss: 590.07, accuracy: 75.7%\n",
      "Epoch: 70, loss: 539.41, accuracy: 74.5%\n",
      "Epoch: 75, loss: 555.18, accuracy: 73.9%\n",
      "Epoch: 80, loss: 566.09, accuracy: 74.0%\n",
      "Epoch: 85, loss: 575.10, accuracy: 74.5%\n",
      "Epoch: 90, loss: 590.16, accuracy: 74.0%\n",
      "Epoch: 95, loss: 604.20, accuracy: 74.4%\n",
      "Epoch: 100, loss: 612.69, accuracy: 74.4%\n",
      "Mean accuracy on T0: 71.71\n",
      "Mean losses on T0: 576.81\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 655.50, accuracy: 56.0%\n",
      "Epoch: 10, loss: 614.49, accuracy: 67.5%\n",
      "Epoch: 15, loss: 589.83, accuracy: 69.6%\n",
      "Epoch: 20, loss: 572.42, accuracy: 69.9%\n",
      "Epoch: 25, loss: 568.32, accuracy: 69.8%\n",
      "Epoch: 30, loss: 559.84, accuracy: 70.3%\n",
      "Epoch: 35, loss: 547.01, accuracy: 71.2%\n",
      "Epoch: 40, loss: 537.82, accuracy: 70.7%\n",
      "Epoch: 45, loss: 525.06, accuracy: 72.5%\n",
      "Epoch: 50, loss: 533.00, accuracy: 72.4%\n",
      "Epoch: 55, loss: 548.43, accuracy: 72.9%\n",
      "Epoch: 60, loss: 549.45, accuracy: 74.0%\n",
      "Epoch: 65, loss: 559.13, accuracy: 72.9%\n",
      "Epoch: 70, loss: 570.99, accuracy: 73.9%\n",
      "Epoch: 75, loss: 583.30, accuracy: 73.7%\n",
      "Epoch: 80, loss: 595.30, accuracy: 73.9%\n",
      "Epoch: 85, loss: 606.29, accuracy: 74.0%\n",
      "Epoch: 90, loss: 617.12, accuracy: 73.9%\n",
      "Epoch: 95, loss: 626.41, accuracy: 73.9%\n",
      "Epoch: 100, loss: 635.60, accuracy: 73.6%\n",
      "Mean accuracy on T1: 70.21\n",
      "Mean losses on T1: 613.01\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 667.14, accuracy: 57.3%\n",
      "Epoch: 10, loss: 614.89, accuracy: 66.2%\n",
      "Epoch: 15, loss: 579.96, accuracy: 70.3%\n",
      "Epoch: 20, loss: 555.05, accuracy: 71.2%\n",
      "Epoch: 25, loss: 548.00, accuracy: 70.7%\n",
      "Epoch: 30, loss: 514.51, accuracy: 72.9%\n",
      "Epoch: 35, loss: 501.16, accuracy: 74.1%\n",
      "Epoch: 40, loss: 483.70, accuracy: 75.2%\n",
      "Epoch: 45, loss: 480.13, accuracy: 77.5%\n",
      "Epoch: 50, loss: 481.18, accuracy: 78.1%\n",
      "Epoch: 55, loss: 478.05, accuracy: 77.4%\n",
      "Epoch: 60, loss: 475.67, accuracy: 76.2%\n",
      "Epoch: 65, loss: 483.74, accuracy: 76.0%\n",
      "Epoch: 70, loss: 491.10, accuracy: 76.6%\n",
      "Epoch: 75, loss: 503.30, accuracy: 76.5%\n",
      "Epoch: 80, loss: 513.69, accuracy: 76.6%\n",
      "Epoch: 85, loss: 524.88, accuracy: 76.2%\n",
      "Epoch: 90, loss: 534.95, accuracy: 76.5%\n",
      "Epoch: 95, loss: 544.89, accuracy: 76.0%\n",
      "Epoch: 100, loss: 554.25, accuracy: 75.8%\n",
      "Mean accuracy on T2: 72.83\n",
      "Mean losses on T2: 550.78\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 637.06, accuracy: 57.7%\n",
      "Epoch: 10, loss: 581.94, accuracy: 70.2%\n",
      "Epoch: 15, loss: 556.96, accuracy: 72.3%\n",
      "Epoch: 20, loss: 535.92, accuracy: 72.5%\n",
      "Epoch: 25, loss: 513.19, accuracy: 72.7%\n",
      "Epoch: 30, loss: 518.97, accuracy: 72.8%\n",
      "Epoch: 35, loss: 509.37, accuracy: 72.8%\n",
      "Epoch: 40, loss: 477.81, accuracy: 75.3%\n",
      "Epoch: 45, loss: 467.50, accuracy: 75.4%\n",
      "Epoch: 50, loss: 468.31, accuracy: 75.7%\n",
      "Epoch: 55, loss: 472.32, accuracy: 76.0%\n",
      "Epoch: 60, loss: 517.84, accuracy: 75.6%\n",
      "Epoch: 65, loss: 495.94, accuracy: 71.1%\n",
      "Epoch: 70, loss: 499.58, accuracy: 76.2%\n",
      "Epoch: 75, loss: 489.54, accuracy: 75.3%\n",
      "Epoch: 80, loss: 503.16, accuracy: 75.4%\n",
      "Epoch: 85, loss: 517.59, accuracy: 75.3%\n",
      "Epoch: 90, loss: 531.02, accuracy: 75.3%\n",
      "Epoch: 95, loss: 543.67, accuracy: 75.2%\n",
      "Epoch: 100, loss: 555.14, accuracy: 75.0%\n",
      "Mean accuracy on T3: 72.36\n",
      "Mean losses on T3: 542.75\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 5, loss: 642.91, accuracy: 56.8%\n",
      "Epoch: 10, loss: 576.80, accuracy: 70.1%\n",
      "Epoch: 15, loss: 541.44, accuracy: 74.2%\n",
      "Epoch: 20, loss: 515.82, accuracy: 74.1%\n",
      "Epoch: 25, loss: 508.72, accuracy: 74.6%\n",
      "Epoch: 30, loss: 490.06, accuracy: 75.7%\n",
      "Epoch: 35, loss: 466.39, accuracy: 77.0%\n",
      "Epoch: 40, loss: 444.88, accuracy: 76.6%\n",
      "Epoch: 45, loss: 443.67, accuracy: 77.1%\n",
      "Epoch: 50, loss: 437.30, accuracy: 78.4%\n",
      "Epoch: 55, loss: 440.72, accuracy: 78.0%\n",
      "Epoch: 60, loss: 452.39, accuracy: 78.8%\n",
      "Epoch: 65, loss: 483.20, accuracy: 77.8%\n",
      "Epoch: 70, loss: 460.80, accuracy: 78.8%\n",
      "Epoch: 75, loss: 470.25, accuracy: 79.1%\n",
      "Epoch: 80, loss: 481.96, accuracy: 79.3%\n",
      "Epoch: 85, loss: 493.44, accuracy: 79.2%\n",
      "Epoch: 90, loss: 503.42, accuracy: 79.2%\n",
      "Epoch: 95, loss: 511.79, accuracy: 79.1%\n",
      "Epoch: 100, loss: 520.17, accuracy: 78.9%\n",
      "Mean accuracy on T4: 74.94\n",
      "Mean losses on T4: 513.41\n",
      "\n",
      "Accuracy list on Ti sets: [71.70893561103811, 70.20827858081472, 72.82512045554095, 72.3646517739816, 74.94462719298245]\n",
      "Losses list on Ti sets: [576.8142440554254, 613.007334851907, 550.7819405127378, 542.7506432655755, 513.4144051196303]\n",
      "Mean accuracy on all T sets: 72.41\n",
      "Mean losses on all T sets: 559.35\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć druga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 20, activation: sigmoid\n",
      "2. Layer - input_dim: 20, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=20, activation=\"sigmoid\")\n",
    "\n",
    "mlp.add_layer(input_dim=20, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 716.75, accuracy: 58.1%\n",
      "Epoch: 10, loss: 711.81, accuracy: 58.1%\n",
      "Epoch: 15, loss: 698.44, accuracy: 58.1%\n",
      "Epoch: 20, loss: 665.14, accuracy: 62.4%\n",
      "Epoch: 25, loss: 631.53, accuracy: 66.5%\n",
      "Epoch: 30, loss: 617.67, accuracy: 65.6%\n",
      "Epoch: 35, loss: 609.25, accuracy: 66.4%\n",
      "Epoch: 40, loss: 600.88, accuracy: 67.9%\n",
      "Epoch: 45, loss: 592.42, accuracy: 69.0%\n",
      "Epoch: 50, loss: 584.22, accuracy: 69.8%\n",
      "Epoch: 55, loss: 576.49, accuracy: 71.0%\n",
      "Epoch: 60, loss: 569.35, accuracy: 71.6%\n",
      "Epoch: 65, loss: 562.82, accuracy: 71.5%\n",
      "Epoch: 70, loss: 556.86, accuracy: 71.4%\n",
      "Epoch: 75, loss: 551.38, accuracy: 71.5%\n",
      "Epoch: 80, loss: 546.33, accuracy: 71.2%\n",
      "Epoch: 85, loss: 541.66, accuracy: 71.6%\n",
      "Epoch: 90, loss: 537.36, accuracy: 71.7%\n",
      "Epoch: 95, loss: 533.41, accuracy: 71.6%\n",
      "Epoch: 100, loss: 529.81, accuracy: 71.4%\n",
      "Mean accuracy on T0: 67.52\n",
      "Mean losses on T0: 601.80\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 695.54, accuracy: 56.6%\n",
      "Epoch: 10, loss: 691.46, accuracy: 56.6%\n",
      "Epoch: 15, loss: 681.70, accuracy: 56.6%\n",
      "Epoch: 20, loss: 658.29, accuracy: 57.3%\n",
      "Epoch: 25, loss: 623.27, accuracy: 68.3%\n",
      "Epoch: 30, loss: 600.04, accuracy: 67.4%\n",
      "Epoch: 35, loss: 587.65, accuracy: 68.3%\n",
      "Epoch: 40, loss: 578.21, accuracy: 70.0%\n",
      "Epoch: 45, loss: 569.57, accuracy: 70.4%\n",
      "Epoch: 50, loss: 561.23, accuracy: 71.2%\n",
      "Epoch: 55, loss: 553.00, accuracy: 72.3%\n",
      "Epoch: 60, loss: 544.87, accuracy: 72.1%\n",
      "Epoch: 65, loss: 536.91, accuracy: 72.9%\n",
      "Epoch: 70, loss: 529.27, accuracy: 73.7%\n",
      "Epoch: 75, loss: 522.09, accuracy: 73.5%\n",
      "Epoch: 80, loss: 515.49, accuracy: 73.3%\n",
      "Epoch: 85, loss: 509.52, accuracy: 73.9%\n",
      "Epoch: 90, loss: 504.18, accuracy: 73.9%\n",
      "Epoch: 95, loss: 499.45, accuracy: 74.2%\n",
      "Epoch: 100, loss: 495.29, accuracy: 74.4%\n",
      "Mean accuracy on T1: 68.53\n",
      "Mean losses on T1: 578.68\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 698.79, accuracy: 56.4%\n",
      "Epoch: 10, loss: 694.51, accuracy: 56.4%\n",
      "Epoch: 15, loss: 683.80, accuracy: 56.4%\n",
      "Epoch: 20, loss: 657.46, accuracy: 57.8%\n",
      "Epoch: 25, loss: 618.43, accuracy: 67.8%\n",
      "Epoch: 30, loss: 591.44, accuracy: 70.6%\n",
      "Epoch: 35, loss: 577.25, accuracy: 70.7%\n",
      "Epoch: 40, loss: 567.93, accuracy: 70.8%\n",
      "Epoch: 45, loss: 560.36, accuracy: 71.6%\n",
      "Epoch: 50, loss: 553.57, accuracy: 71.0%\n",
      "Epoch: 55, loss: 547.17, accuracy: 70.8%\n",
      "Epoch: 60, loss: 541.04, accuracy: 71.0%\n",
      "Epoch: 65, loss: 535.16, accuracy: 71.2%\n",
      "Epoch: 70, loss: 529.59, accuracy: 71.5%\n",
      "Epoch: 75, loss: 524.35, accuracy: 71.5%\n",
      "Epoch: 80, loss: 519.44, accuracy: 71.6%\n",
      "Epoch: 85, loss: 514.85, accuracy: 72.0%\n",
      "Epoch: 90, loss: 510.53, accuracy: 72.1%\n",
      "Epoch: 95, loss: 506.49, accuracy: 72.7%\n",
      "Epoch: 100, loss: 502.70, accuracy: 72.5%\n",
      "Mean accuracy on T2: 67.12\n",
      "Mean losses on T2: 578.71\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 695.40, accuracy: 58.3%\n",
      "Epoch: 10, loss: 691.01, accuracy: 58.3%\n",
      "Epoch: 15, loss: 680.40, accuracy: 58.3%\n",
      "Epoch: 20, loss: 653.74, accuracy: 59.9%\n",
      "Epoch: 25, loss: 614.57, accuracy: 68.9%\n",
      "Epoch: 30, loss: 591.01, accuracy: 68.7%\n",
      "Epoch: 35, loss: 579.19, accuracy: 69.1%\n",
      "Epoch: 40, loss: 569.89, accuracy: 70.0%\n",
      "Epoch: 45, loss: 561.12, accuracy: 71.9%\n",
      "Epoch: 50, loss: 552.68, accuracy: 71.9%\n",
      "Epoch: 55, loss: 544.63, accuracy: 71.4%\n",
      "Epoch: 60, loss: 537.04, accuracy: 71.6%\n",
      "Epoch: 65, loss: 529.96, accuracy: 72.3%\n",
      "Epoch: 70, loss: 523.44, accuracy: 72.9%\n",
      "Epoch: 75, loss: 517.49, accuracy: 73.1%\n",
      "Epoch: 80, loss: 512.05, accuracy: 73.9%\n",
      "Epoch: 85, loss: 507.05, accuracy: 73.9%\n",
      "Epoch: 90, loss: 502.44, accuracy: 73.9%\n",
      "Epoch: 95, loss: 498.17, accuracy: 73.2%\n",
      "Epoch: 100, loss: 494.20, accuracy: 73.6%\n",
      "Mean accuracy on T3: 69.02\n",
      "Mean losses on T3: 571.92\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 5, loss: 727.00, accuracy: 54.7%\n",
      "Epoch: 10, loss: 722.40, accuracy: 54.7%\n",
      "Epoch: 15, loss: 709.64, accuracy: 54.7%\n",
      "Epoch: 20, loss: 677.11, accuracy: 55.0%\n",
      "Epoch: 25, loss: 640.09, accuracy: 66.7%\n",
      "Epoch: 30, loss: 622.12, accuracy: 68.6%\n",
      "Epoch: 35, loss: 612.58, accuracy: 68.7%\n",
      "Epoch: 40, loss: 605.32, accuracy: 69.1%\n",
      "Epoch: 45, loss: 598.98, accuracy: 69.3%\n",
      "Epoch: 50, loss: 593.22, accuracy: 69.9%\n",
      "Epoch: 55, loss: 587.91, accuracy: 69.9%\n",
      "Epoch: 60, loss: 582.99, accuracy: 70.4%\n",
      "Epoch: 65, loss: 578.36, accuracy: 71.1%\n",
      "Epoch: 70, loss: 573.99, accuracy: 71.4%\n",
      "Epoch: 75, loss: 569.82, accuracy: 71.2%\n",
      "Epoch: 80, loss: 565.84, accuracy: 71.3%\n",
      "Epoch: 85, loss: 562.07, accuracy: 71.4%\n",
      "Epoch: 90, loss: 558.52, accuracy: 71.4%\n",
      "Epoch: 95, loss: 555.22, accuracy: 71.3%\n",
      "Epoch: 100, loss: 552.21, accuracy: 71.1%\n",
      "Mean accuracy on T4: 66.77\n",
      "Mean losses on T4: 610.78\n",
      "\n",
      "Accuracy list on Ti sets: [67.51960140166447, 68.53493210687691, 67.11990801576873, 69.02146298729741, 66.7671052631579]\n",
      "Losses list on Ti sets: [601.7989317332457, 578.6792152465523, 578.7072354737155, 571.9209023740799, 610.7778550248147]\n",
      "Mean accuracy on all T sets: 67.79\n",
      "Mean losses on all T sets: 588.38\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć trzecia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 50, activation: relu\n",
      "2. Layer - input_dim: 50, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=50, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=50, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 648.18, accuracy: 64.7%\n",
      "Epoch: 10, loss: 613.88, accuracy: 64.3%\n",
      "Epoch: 15, loss: 586.27, accuracy: 67.7%\n",
      "Epoch: 20, loss: 561.98, accuracy: 68.9%\n",
      "Epoch: 25, loss: 543.21, accuracy: 69.5%\n",
      "Epoch: 30, loss: 528.82, accuracy: 69.4%\n",
      "Epoch: 35, loss: 525.49, accuracy: 71.4%\n",
      "Epoch: 40, loss: 506.34, accuracy: 72.7%\n",
      "Epoch: 45, loss: 502.55, accuracy: 72.8%\n",
      "Epoch: 50, loss: 537.50, accuracy: 72.5%\n",
      "Epoch: 55, loss: 511.54, accuracy: 72.9%\n",
      "Epoch: 60, loss: 523.04, accuracy: 72.8%\n",
      "Epoch: 65, loss: 536.40, accuracy: 72.8%\n",
      "Epoch: 70, loss: 549.21, accuracy: 73.3%\n",
      "Epoch: 75, loss: 562.28, accuracy: 74.1%\n",
      "Epoch: 80, loss: 576.03, accuracy: 73.9%\n",
      "Epoch: 85, loss: 589.05, accuracy: 73.7%\n",
      "Epoch: 90, loss: 600.57, accuracy: 73.5%\n",
      "Epoch: 95, loss: 613.04, accuracy: 73.6%\n",
      "Epoch: 100, loss: 623.49, accuracy: 73.6%\n",
      "Mean accuracy on T0: 70.60\n",
      "Mean losses on T0: 570.05\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 635.13, accuracy: 58.7%\n",
      "Epoch: 10, loss: 583.89, accuracy: 67.1%\n",
      "Epoch: 15, loss: 554.29, accuracy: 70.8%\n",
      "Epoch: 20, loss: 530.10, accuracy: 72.7%\n",
      "Epoch: 25, loss: 510.61, accuracy: 72.8%\n",
      "Epoch: 30, loss: 491.35, accuracy: 74.4%\n",
      "Epoch: 35, loss: 475.87, accuracy: 74.6%\n",
      "Epoch: 40, loss: 468.09, accuracy: 75.4%\n",
      "Epoch: 45, loss: 466.92, accuracy: 75.7%\n",
      "Epoch: 50, loss: 471.84, accuracy: 76.1%\n",
      "Epoch: 55, loss: 488.39, accuracy: 75.8%\n",
      "Epoch: 60, loss: 490.89, accuracy: 76.0%\n",
      "Epoch: 65, loss: 502.56, accuracy: 76.6%\n",
      "Epoch: 70, loss: 514.35, accuracy: 76.3%\n",
      "Epoch: 75, loss: 525.92, accuracy: 75.7%\n",
      "Epoch: 80, loss: 537.56, accuracy: 76.1%\n",
      "Epoch: 85, loss: 549.10, accuracy: 75.8%\n",
      "Epoch: 90, loss: 559.45, accuracy: 76.0%\n",
      "Epoch: 95, loss: 569.57, accuracy: 75.7%\n",
      "Epoch: 100, loss: 578.17, accuracy: 76.0%\n",
      "Mean accuracy on T1: 73.25\n",
      "Mean losses on T1: 538.09\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 633.89, accuracy: 58.0%\n",
      "Epoch: 10, loss: 582.20, accuracy: 70.6%\n",
      "Epoch: 15, loss: 558.69, accuracy: 70.3%\n",
      "Epoch: 20, loss: 537.62, accuracy: 71.7%\n",
      "Epoch: 25, loss: 521.67, accuracy: 72.0%\n",
      "Epoch: 30, loss: 510.99, accuracy: 72.8%\n",
      "Epoch: 35, loss: 499.27, accuracy: 73.1%\n",
      "Epoch: 40, loss: 487.58, accuracy: 74.2%\n",
      "Epoch: 45, loss: 489.03, accuracy: 74.9%\n",
      "Epoch: 50, loss: 491.81, accuracy: 74.9%\n",
      "Epoch: 55, loss: 497.70, accuracy: 75.0%\n",
      "Epoch: 60, loss: 506.41, accuracy: 75.3%\n",
      "Epoch: 65, loss: 513.56, accuracy: 74.2%\n",
      "Epoch: 70, loss: 525.07, accuracy: 74.6%\n",
      "Epoch: 75, loss: 533.73, accuracy: 74.1%\n",
      "Epoch: 80, loss: 543.25, accuracy: 74.0%\n",
      "Epoch: 85, loss: 553.31, accuracy: 74.5%\n",
      "Epoch: 90, loss: 564.99, accuracy: 74.5%\n",
      "Epoch: 95, loss: 571.75, accuracy: 74.1%\n",
      "Epoch: 100, loss: 578.34, accuracy: 74.5%\n",
      "Mean accuracy on T2: 72.01\n",
      "Mean losses on T2: 561.88\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 660.91, accuracy: 53.9%\n",
      "Epoch: 10, loss: 604.53, accuracy: 68.3%\n",
      "Epoch: 15, loss: 565.09, accuracy: 72.3%\n",
      "Epoch: 20, loss: 534.02, accuracy: 73.1%\n",
      "Epoch: 25, loss: 517.06, accuracy: 73.2%\n",
      "Epoch: 30, loss: 499.08, accuracy: 73.5%\n",
      "Epoch: 35, loss: 485.74, accuracy: 74.8%\n",
      "Epoch: 40, loss: 458.37, accuracy: 76.2%\n",
      "Epoch: 45, loss: 460.07, accuracy: 75.4%\n",
      "Epoch: 50, loss: 516.63, accuracy: 75.8%\n",
      "Epoch: 55, loss: 500.71, accuracy: 76.0%\n",
      "Epoch: 60, loss: 503.24, accuracy: 75.4%\n",
      "Epoch: 65, loss: 496.47, accuracy: 75.4%\n",
      "Epoch: 70, loss: 499.78, accuracy: 75.2%\n",
      "Epoch: 75, loss: 497.44, accuracy: 75.0%\n",
      "Epoch: 80, loss: 510.48, accuracy: 75.3%\n",
      "Epoch: 85, loss: 522.96, accuracy: 75.0%\n",
      "Epoch: 90, loss: 534.83, accuracy: 74.9%\n",
      "Epoch: 95, loss: 543.22, accuracy: 75.3%\n",
      "Epoch: 100, loss: 552.61, accuracy: 74.9%\n",
      "Mean accuracy on T3: 72.41\n",
      "Mean losses on T3: 549.24\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 5, loss: 642.87, accuracy: 55.3%\n",
      "Epoch: 10, loss: 572.55, accuracy: 73.0%\n",
      "Epoch: 15, loss: 537.86, accuracy: 73.8%\n",
      "Epoch: 20, loss: 509.92, accuracy: 75.9%\n",
      "Epoch: 25, loss: 493.15, accuracy: 76.6%\n",
      "Epoch: 30, loss: 474.85, accuracy: 78.4%\n",
      "Epoch: 35, loss: 460.73, accuracy: 78.6%\n",
      "Epoch: 40, loss: 493.98, accuracy: 78.2%\n",
      "Epoch: 45, loss: 454.61, accuracy: 78.4%\n",
      "Epoch: 50, loss: 491.44, accuracy: 79.1%\n",
      "Epoch: 55, loss: 455.52, accuracy: 78.8%\n",
      "Epoch: 60, loss: 482.37, accuracy: 78.9%\n",
      "Epoch: 65, loss: 493.19, accuracy: 78.6%\n",
      "Epoch: 70, loss: 487.91, accuracy: 78.7%\n",
      "Epoch: 75, loss: 496.76, accuracy: 78.6%\n",
      "Epoch: 80, loss: 507.08, accuracy: 78.4%\n",
      "Epoch: 85, loss: 517.74, accuracy: 78.2%\n",
      "Epoch: 90, loss: 528.04, accuracy: 78.2%\n",
      "Epoch: 95, loss: 537.87, accuracy: 78.2%\n",
      "Epoch: 100, loss: 546.90, accuracy: 77.9%\n",
      "Mean accuracy on T4: 75.17\n",
      "Mean losses on T4: 521.57\n",
      "\n",
      "Accuracy list on Ti sets: [70.59789750328515, 73.24540078843626, 72.00613228208498, 72.41108190976786, 75.17291666666667]\n",
      "Losses list on Ti sets: [570.0522412277929, 538.0880801760859, 561.884488709119, 549.2413071048586, 521.5725063081903]\n",
      "Mean accuracy on all T sets: 72.69\n",
      "Mean losses on all T sets: 548.17\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć czwarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 50, activation: sigmoid\n",
      "2. Layer - input_dim: 50, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=50, activation=\"sigmoid\")\n",
    "\n",
    "mlp.add_layer(input_dim=50, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 699.15, accuracy: 56.5%\n",
      "Epoch: 10, loss: 696.15, accuracy: 56.5%\n",
      "Epoch: 15, loss: 682.25, accuracy: 56.5%\n",
      "Epoch: 20, loss: 634.48, accuracy: 62.9%\n",
      "Epoch: 25, loss: 590.54, accuracy: 68.9%\n",
      "Epoch: 30, loss: 574.66, accuracy: 69.3%\n",
      "Epoch: 35, loss: 566.24, accuracy: 69.6%\n",
      "Epoch: 40, loss: 559.59, accuracy: 70.8%\n",
      "Epoch: 45, loss: 553.79, accuracy: 71.7%\n",
      "Epoch: 50, loss: 548.58, accuracy: 72.8%\n",
      "Epoch: 55, loss: 543.86, accuracy: 72.7%\n",
      "Epoch: 60, loss: 539.60, accuracy: 73.1%\n",
      "Epoch: 65, loss: 535.75, accuracy: 73.3%\n",
      "Epoch: 70, loss: 532.24, accuracy: 73.1%\n",
      "Epoch: 75, loss: 528.97, accuracy: 72.8%\n",
      "Epoch: 80, loss: 525.88, accuracy: 72.5%\n",
      "Epoch: 85, loss: 522.90, accuracy: 72.5%\n",
      "Epoch: 90, loss: 520.01, accuracy: 72.7%\n",
      "Epoch: 95, loss: 517.18, accuracy: 73.1%\n",
      "Epoch: 100, loss: 514.41, accuracy: 73.2%\n",
      "Mean accuracy on T0: 68.78\n",
      "Mean losses on T0: 576.74\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 730.16, accuracy: 54.3%\n",
      "Epoch: 10, loss: 726.24, accuracy: 54.3%\n",
      "Epoch: 15, loss: 706.59, accuracy: 54.3%\n",
      "Epoch: 20, loss: 658.63, accuracy: 64.7%\n",
      "Epoch: 25, loss: 634.06, accuracy: 65.8%\n",
      "Epoch: 30, loss: 625.62, accuracy: 66.8%\n",
      "Epoch: 35, loss: 618.76, accuracy: 67.8%\n",
      "Epoch: 40, loss: 611.96, accuracy: 67.8%\n",
      "Epoch: 45, loss: 605.32, accuracy: 68.2%\n",
      "Epoch: 50, loss: 598.98, accuracy: 69.1%\n",
      "Epoch: 55, loss: 593.06, accuracy: 68.9%\n",
      "Epoch: 60, loss: 587.65, accuracy: 69.1%\n",
      "Epoch: 65, loss: 582.73, accuracy: 69.4%\n",
      "Epoch: 70, loss: 578.24, accuracy: 69.8%\n",
      "Epoch: 75, loss: 574.10, accuracy: 69.8%\n",
      "Epoch: 80, loss: 570.20, accuracy: 69.9%\n",
      "Epoch: 85, loss: 566.49, accuracy: 70.3%\n",
      "Epoch: 90, loss: 562.92, accuracy: 70.7%\n",
      "Epoch: 95, loss: 559.45, accuracy: 70.4%\n",
      "Epoch: 100, loss: 556.08, accuracy: 70.6%\n",
      "Mean accuracy on T1: 66.14\n",
      "Mean losses on T1: 619.60\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 716.21, accuracy: 55.6%\n",
      "Epoch: 10, loss: 712.89, accuracy: 55.6%\n",
      "Epoch: 15, loss: 697.76, accuracy: 55.6%\n",
      "Epoch: 20, loss: 650.10, accuracy: 62.4%\n",
      "Epoch: 25, loss: 610.15, accuracy: 69.5%\n",
      "Epoch: 30, loss: 593.79, accuracy: 70.4%\n",
      "Epoch: 35, loss: 583.66, accuracy: 71.4%\n",
      "Epoch: 40, loss: 575.31, accuracy: 72.1%\n",
      "Epoch: 45, loss: 568.10, accuracy: 71.4%\n",
      "Epoch: 50, loss: 561.79, accuracy: 71.6%\n",
      "Epoch: 55, loss: 556.17, accuracy: 71.7%\n",
      "Epoch: 60, loss: 551.08, accuracy: 72.0%\n",
      "Epoch: 65, loss: 546.40, accuracy: 72.3%\n",
      "Epoch: 70, loss: 542.03, accuracy: 72.5%\n",
      "Epoch: 75, loss: 537.92, accuracy: 72.3%\n",
      "Epoch: 80, loss: 534.00, accuracy: 72.1%\n",
      "Epoch: 85, loss: 530.25, accuracy: 72.7%\n",
      "Epoch: 90, loss: 526.65, accuracy: 72.7%\n",
      "Epoch: 95, loss: 523.19, accuracy: 72.5%\n",
      "Epoch: 100, loss: 519.85, accuracy: 72.7%\n",
      "Mean accuracy on T2: 68.28\n",
      "Mean losses on T2: 589.73\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 691.80, accuracy: 59.3%\n",
      "Epoch: 10, loss: 688.25, accuracy: 59.3%\n",
      "Epoch: 15, loss: 669.37, accuracy: 59.3%\n",
      "Epoch: 20, loss: 625.64, accuracy: 68.5%\n",
      "Epoch: 25, loss: 605.52, accuracy: 66.1%\n",
      "Epoch: 30, loss: 597.36, accuracy: 67.3%\n",
      "Epoch: 35, loss: 590.46, accuracy: 69.8%\n",
      "Epoch: 40, loss: 583.84, accuracy: 69.9%\n",
      "Epoch: 45, loss: 577.42, accuracy: 69.9%\n",
      "Epoch: 50, loss: 571.17, accuracy: 70.7%\n",
      "Epoch: 55, loss: 565.09, accuracy: 70.6%\n",
      "Epoch: 60, loss: 559.24, accuracy: 71.2%\n",
      "Epoch: 65, loss: 553.65, accuracy: 72.5%\n",
      "Epoch: 70, loss: 548.38, accuracy: 72.5%\n",
      "Epoch: 75, loss: 543.47, accuracy: 72.3%\n",
      "Epoch: 80, loss: 538.92, accuracy: 72.8%\n",
      "Epoch: 85, loss: 534.73, accuracy: 72.3%\n",
      "Epoch: 90, loss: 530.90, accuracy: 72.3%\n",
      "Epoch: 95, loss: 527.42, accuracy: 72.1%\n",
      "Epoch: 100, loss: 524.29, accuracy: 72.3%\n",
      "Mean accuracy on T3: 68.50\n",
      "Mean losses on T3: 588.57\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 5, loss: 696.87, accuracy: 58.6%\n",
      "Epoch: 10, loss: 693.74, accuracy: 58.6%\n",
      "Epoch: 15, loss: 678.22, accuracy: 58.6%\n",
      "Epoch: 20, loss: 634.55, accuracy: 68.6%\n",
      "Epoch: 25, loss: 603.78, accuracy: 67.6%\n",
      "Epoch: 30, loss: 587.06, accuracy: 67.2%\n",
      "Epoch: 35, loss: 573.75, accuracy: 69.6%\n",
      "Epoch: 40, loss: 562.05, accuracy: 70.4%\n",
      "Epoch: 45, loss: 551.37, accuracy: 71.4%\n",
      "Epoch: 50, loss: 541.53, accuracy: 72.4%\n",
      "Epoch: 55, loss: 532.51, accuracy: 73.2%\n",
      "Epoch: 60, loss: 524.30, accuracy: 73.6%\n",
      "Epoch: 65, loss: 516.87, accuracy: 74.3%\n",
      "Epoch: 70, loss: 510.14, accuracy: 74.7%\n",
      "Epoch: 75, loss: 503.99, accuracy: 74.9%\n",
      "Epoch: 80, loss: 498.29, accuracy: 75.1%\n",
      "Epoch: 85, loss: 492.91, accuracy: 75.5%\n",
      "Epoch: 90, loss: 487.76, accuracy: 75.5%\n",
      "Epoch: 95, loss: 482.79, accuracy: 75.9%\n",
      "Epoch: 100, loss: 477.98, accuracy: 75.9%\n",
      "Mean accuracy on T4: 70.02\n",
      "Mean losses on T4: 565.15\n",
      "\n",
      "Accuracy list on Ti sets: [68.77814279456855, 66.14137100306615, 68.28471309680245, 68.50032851511169, 70.02456140350878]\n",
      "Losses list on Ti sets: [576.738913311633, 619.5960349009733, 589.7256476789146, 588.5743925253853, 565.154881179301]\n",
      "Mean accuracy on all T sets: 68.35\n",
      "Mean losses on all T sets: 587.96\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć piąta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 100, activation: relu\n",
      "2. Layer - input_dim: 100, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=100, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=100, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 626.24, accuracy: 69.4%\n",
      "Epoch: 10, loss: 581.78, accuracy: 71.1%\n",
      "Epoch: 15, loss: 549.65, accuracy: 72.3%\n",
      "Epoch: 20, loss: 523.13, accuracy: 72.9%\n",
      "Epoch: 25, loss: 507.16, accuracy: 73.9%\n",
      "Epoch: 30, loss: 491.19, accuracy: 74.9%\n",
      "Epoch: 35, loss: 477.40, accuracy: 75.8%\n",
      "Epoch: 40, loss: 468.09, accuracy: 76.1%\n",
      "Epoch: 45, loss: 463.03, accuracy: 75.8%\n",
      "Epoch: 50, loss: 465.77, accuracy: 75.7%\n",
      "Epoch: 55, loss: 470.95, accuracy: 75.3%\n",
      "Epoch: 60, loss: 476.26, accuracy: 75.7%\n",
      "Epoch: 65, loss: 481.48, accuracy: 75.0%\n",
      "Epoch: 70, loss: 487.60, accuracy: 74.9%\n",
      "Epoch: 75, loss: 496.48, accuracy: 74.8%\n",
      "Epoch: 80, loss: 505.39, accuracy: 70.7%\n",
      "Epoch: 85, loss: 509.82, accuracy: 69.9%\n",
      "Epoch: 90, loss: 515.00, accuracy: 69.9%\n",
      "Epoch: 95, loss: 521.25, accuracy: 70.2%\n",
      "Epoch: 100, loss: 526.87, accuracy: 70.0%\n",
      "Mean accuracy on T0: 72.48\n",
      "Mean losses on T0: 551.33\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 635.85, accuracy: 68.3%\n",
      "Epoch: 10, loss: 590.39, accuracy: 69.6%\n",
      "Epoch: 15, loss: 559.79, accuracy: 71.9%\n",
      "Epoch: 20, loss: 538.56, accuracy: 72.1%\n",
      "Epoch: 25, loss: 525.26, accuracy: 72.3%\n",
      "Epoch: 30, loss: 509.81, accuracy: 72.5%\n",
      "Epoch: 35, loss: 497.01, accuracy: 73.9%\n",
      "Epoch: 40, loss: 489.55, accuracy: 74.8%\n",
      "Epoch: 45, loss: 489.59, accuracy: 74.5%\n",
      "Epoch: 50, loss: 495.11, accuracy: 74.1%\n",
      "Epoch: 55, loss: 504.92, accuracy: 70.4%\n",
      "Epoch: 60, loss: 513.63, accuracy: 69.9%\n",
      "Epoch: 65, loss: 520.56, accuracy: 70.0%\n",
      "Epoch: 70, loss: 531.77, accuracy: 69.9%\n",
      "Epoch: 75, loss: 542.57, accuracy: 70.0%\n",
      "Epoch: 80, loss: 552.61, accuracy: 69.6%\n",
      "Epoch: 85, loss: 556.48, accuracy: 69.8%\n",
      "Epoch: 90, loss: 570.88, accuracy: 69.6%\n",
      "Epoch: 95, loss: 568.25, accuracy: 69.6%\n",
      "Epoch: 100, loss: 574.29, accuracy: 69.5%\n",
      "Mean accuracy on T1: 72.35\n",
      "Mean losses on T1: 579.63\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 660.95, accuracy: 64.1%\n",
      "Epoch: 10, loss: 614.42, accuracy: 67.5%\n",
      "Epoch: 15, loss: 587.33, accuracy: 68.9%\n",
      "Epoch: 20, loss: 565.98, accuracy: 70.0%\n",
      "Epoch: 25, loss: 550.51, accuracy: 70.6%\n",
      "Epoch: 30, loss: 536.38, accuracy: 71.0%\n",
      "Epoch: 35, loss: 524.75, accuracy: 71.5%\n",
      "Epoch: 40, loss: 518.09, accuracy: 71.9%\n",
      "Epoch: 45, loss: 516.02, accuracy: 72.5%\n",
      "Epoch: 50, loss: 517.87, accuracy: 72.7%\n",
      "Epoch: 55, loss: 521.53, accuracy: 73.2%\n",
      "Epoch: 60, loss: 527.75, accuracy: 72.3%\n",
      "Epoch: 65, loss: 536.89, accuracy: 73.2%\n",
      "Epoch: 70, loss: 542.94, accuracy: 71.5%\n",
      "Epoch: 75, loss: 553.32, accuracy: 71.9%\n",
      "Epoch: 80, loss: 561.38, accuracy: 71.7%\n",
      "Epoch: 85, loss: 569.45, accuracy: 71.6%\n",
      "Epoch: 90, loss: 577.74, accuracy: 71.7%\n",
      "Epoch: 95, loss: 585.96, accuracy: 71.9%\n",
      "Epoch: 100, loss: 593.66, accuracy: 71.9%\n",
      "Mean accuracy on T2: 69.83\n",
      "Mean losses on T2: 593.31\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 620.16, accuracy: 61.8%\n",
      "Epoch: 10, loss: 566.05, accuracy: 69.3%\n",
      "Epoch: 15, loss: 536.89, accuracy: 71.1%\n",
      "Epoch: 20, loss: 513.92, accuracy: 72.7%\n",
      "Epoch: 25, loss: 499.88, accuracy: 73.1%\n",
      "Epoch: 30, loss: 482.71, accuracy: 73.3%\n",
      "Epoch: 35, loss: 469.58, accuracy: 74.2%\n",
      "Epoch: 40, loss: 456.06, accuracy: 75.8%\n",
      "Epoch: 45, loss: 442.95, accuracy: 77.1%\n",
      "Epoch: 50, loss: 455.96, accuracy: 75.6%\n",
      "Epoch: 55, loss: 458.78, accuracy: 76.0%\n",
      "Epoch: 60, loss: 455.94, accuracy: 77.5%\n",
      "Epoch: 65, loss: 463.52, accuracy: 77.0%\n",
      "Epoch: 70, loss: 471.57, accuracy: 77.0%\n",
      "Epoch: 75, loss: 477.25, accuracy: 77.1%\n",
      "Epoch: 80, loss: 483.03, accuracy: 77.3%\n",
      "Epoch: 85, loss: 489.08, accuracy: 77.1%\n",
      "Epoch: 90, loss: 495.21, accuracy: 77.3%\n",
      "Epoch: 95, loss: 501.21, accuracy: 77.1%\n",
      "Epoch: 100, loss: 506.83, accuracy: 77.0%\n",
      "Mean accuracy on T3: 73.79\n",
      "Mean losses on T3: 517.96\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 5, loss: 627.22, accuracy: 65.7%\n",
      "Epoch: 10, loss: 572.13, accuracy: 70.0%\n",
      "Epoch: 15, loss: 532.85, accuracy: 73.8%\n",
      "Epoch: 20, loss: 513.00, accuracy: 74.2%\n",
      "Epoch: 25, loss: 548.39, accuracy: 73.8%\n",
      "Epoch: 30, loss: 544.18, accuracy: 74.5%\n",
      "Epoch: 35, loss: 524.84, accuracy: 75.8%\n",
      "Epoch: 40, loss: 508.10, accuracy: 76.3%\n",
      "Epoch: 45, loss: 454.16, accuracy: 77.4%\n",
      "Epoch: 50, loss: 459.96, accuracy: 76.7%\n",
      "Epoch: 55, loss: 487.59, accuracy: 77.9%\n",
      "Epoch: 60, loss: 480.04, accuracy: 78.2%\n",
      "Epoch: 65, loss: 493.67, accuracy: 78.3%\n",
      "Epoch: 70, loss: 504.70, accuracy: 77.5%\n",
      "Epoch: 75, loss: 516.13, accuracy: 77.6%\n",
      "Epoch: 80, loss: 526.30, accuracy: 77.2%\n",
      "Epoch: 85, loss: 535.42, accuracy: 77.0%\n",
      "Epoch: 90, loss: 543.96, accuracy: 77.0%\n",
      "Epoch: 95, loss: 551.94, accuracy: 76.8%\n",
      "Epoch: 100, loss: 559.76, accuracy: 76.7%\n",
      "Mean accuracy on T4: 73.96\n",
      "Mean losses on T4: 537.58\n",
      "\n",
      "Accuracy list on Ti sets: [72.48160315374508, 72.35063512921596, 69.82971966710468, 73.78777923784494, 73.96260964912281]\n",
      "Losses list on Ti sets: [551.3300839430045, 579.6328414387928, 593.3116859589728, 517.9626790817825, 537.5758808492077]\n",
      "Mean accuracy on all T sets: 72.48\n",
      "Mean losses on all T sets: 555.96\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć szósta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 100, activation: sigmoid\n",
      "2. Layer - input_dim: 100, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=100, activation=\"sigmoid\")\n",
    "\n",
    "mlp.add_layer(input_dim=100, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 762.92, accuracy: 32.3%\n",
      "Epoch: 10, loss: 726.61, accuracy: 33.2%\n",
      "Epoch: 15, loss: 666.25, accuracy: 57.7%\n",
      "Epoch: 20, loss: 664.17, accuracy: 59.8%\n",
      "Epoch: 25, loss: 631.60, accuracy: 67.0%\n",
      "Epoch: 30, loss: 620.82, accuracy: 68.5%\n",
      "Epoch: 35, loss: 612.23, accuracy: 68.7%\n",
      "Epoch: 40, loss: 604.37, accuracy: 69.8%\n",
      "Epoch: 45, loss: 596.92, accuracy: 70.7%\n",
      "Epoch: 50, loss: 589.89, accuracy: 71.1%\n",
      "Epoch: 55, loss: 583.38, accuracy: 70.8%\n",
      "Epoch: 60, loss: 577.46, accuracy: 70.8%\n",
      "Epoch: 65, loss: 572.15, accuracy: 71.0%\n",
      "Epoch: 70, loss: 567.34, accuracy: 71.2%\n",
      "Epoch: 75, loss: 562.93, accuracy: 71.5%\n",
      "Epoch: 80, loss: 558.82, accuracy: 71.7%\n",
      "Epoch: 85, loss: 554.97, accuracy: 72.4%\n",
      "Epoch: 90, loss: 551.34, accuracy: 72.7%\n",
      "Epoch: 95, loss: 547.93, accuracy: 72.8%\n",
      "Epoch: 100, loss: 544.73, accuracy: 72.7%\n",
      "Mean accuracy on T0: 66.24\n",
      "Mean losses on T0: 622.34\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 781.83, accuracy: 32.3%\n",
      "Epoch: 10, loss: 751.01, accuracy: 32.3%\n",
      "Epoch: 15, loss: 694.45, accuracy: 55.2%\n",
      "Epoch: 20, loss: 677.81, accuracy: 57.2%\n",
      "Epoch: 25, loss: 619.13, accuracy: 68.1%\n",
      "Epoch: 30, loss: 601.57, accuracy: 69.4%\n",
      "Epoch: 35, loss: 589.46, accuracy: 70.2%\n",
      "Epoch: 40, loss: 579.26, accuracy: 71.0%\n",
      "Epoch: 45, loss: 570.19, accuracy: 71.6%\n",
      "Epoch: 50, loss: 561.99, accuracy: 72.0%\n",
      "Epoch: 55, loss: 554.54, accuracy: 72.4%\n",
      "Epoch: 60, loss: 547.73, accuracy: 72.8%\n",
      "Epoch: 65, loss: 541.45, accuracy: 73.1%\n",
      "Epoch: 70, loss: 535.54, accuracy: 73.1%\n",
      "Epoch: 75, loss: 529.89, accuracy: 73.3%\n",
      "Epoch: 80, loss: 524.42, accuracy: 73.7%\n",
      "Epoch: 85, loss: 519.13, accuracy: 73.9%\n",
      "Epoch: 90, loss: 514.06, accuracy: 73.7%\n",
      "Epoch: 95, loss: 509.28, accuracy: 73.7%\n",
      "Epoch: 100, loss: 504.82, accuracy: 74.1%\n",
      "Mean accuracy on T1: 66.95\n",
      "Mean losses on T1: 604.03\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 776.72, accuracy: 31.3%\n",
      "Epoch: 10, loss: 742.66, accuracy: 31.4%\n",
      "Epoch: 15, loss: 787.18, accuracy: 57.0%\n",
      "Epoch: 20, loss: 662.46, accuracy: 57.8%\n",
      "Epoch: 25, loss: 607.92, accuracy: 67.0%\n",
      "Epoch: 30, loss: 593.31, accuracy: 68.9%\n",
      "Epoch: 35, loss: 582.36, accuracy: 69.6%\n",
      "Epoch: 40, loss: 572.47, accuracy: 70.0%\n",
      "Epoch: 45, loss: 563.39, accuracy: 70.6%\n",
      "Epoch: 50, loss: 555.10, accuracy: 71.7%\n",
      "Epoch: 55, loss: 547.56, accuracy: 72.1%\n",
      "Epoch: 60, loss: 540.67, accuracy: 72.5%\n",
      "Epoch: 65, loss: 534.27, accuracy: 72.9%\n",
      "Epoch: 70, loss: 528.24, accuracy: 73.6%\n",
      "Epoch: 75, loss: 522.45, accuracy: 74.0%\n",
      "Epoch: 80, loss: 516.86, accuracy: 74.5%\n",
      "Epoch: 85, loss: 511.44, accuracy: 74.8%\n",
      "Epoch: 90, loss: 506.17, accuracy: 74.6%\n",
      "Epoch: 95, loss: 501.06, accuracy: 74.2%\n",
      "Epoch: 100, loss: 496.10, accuracy: 74.0%\n",
      "Mean accuracy on T2: 67.19\n",
      "Mean losses on T2: 595.51\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 758.07, accuracy: 32.3%\n",
      "Epoch: 10, loss: 723.75, accuracy: 33.5%\n",
      "Epoch: 15, loss: 677.71, accuracy: 67.1%\n",
      "Epoch: 20, loss: 638.91, accuracy: 60.2%\n",
      "Epoch: 25, loss: 594.35, accuracy: 69.0%\n",
      "Epoch: 30, loss: 582.93, accuracy: 68.9%\n",
      "Epoch: 35, loss: 574.02, accuracy: 69.4%\n",
      "Epoch: 40, loss: 566.44, accuracy: 69.9%\n",
      "Epoch: 45, loss: 559.99, accuracy: 71.0%\n",
      "Epoch: 50, loss: 554.43, accuracy: 71.5%\n",
      "Epoch: 55, loss: 549.49, accuracy: 71.7%\n",
      "Epoch: 60, loss: 544.96, accuracy: 72.1%\n",
      "Epoch: 65, loss: 540.69, accuracy: 72.8%\n",
      "Epoch: 70, loss: 536.59, accuracy: 72.4%\n",
      "Epoch: 75, loss: 532.65, accuracy: 72.9%\n",
      "Epoch: 80, loss: 528.87, accuracy: 72.9%\n",
      "Epoch: 85, loss: 525.25, accuracy: 72.9%\n",
      "Epoch: 90, loss: 521.74, accuracy: 73.2%\n",
      "Epoch: 95, loss: 518.32, accuracy: 72.9%\n",
      "Epoch: 100, loss: 514.97, accuracy: 73.6%\n",
      "Mean accuracy on T3: 67.52\n",
      "Mean losses on T3: 596.03\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 5, loss: 782.01, accuracy: 32.0%\n",
      "Epoch: 10, loss: 769.55, accuracy: 32.0%\n",
      "Epoch: 15, loss: 725.68, accuracy: 45.1%\n",
      "Epoch: 20, loss: 635.30, accuracy: 68.0%\n",
      "Epoch: 25, loss: 606.09, accuracy: 68.6%\n",
      "Epoch: 30, loss: 594.96, accuracy: 68.8%\n",
      "Epoch: 35, loss: 586.99, accuracy: 69.3%\n",
      "Epoch: 40, loss: 579.99, accuracy: 70.0%\n",
      "Epoch: 45, loss: 573.32, accuracy: 70.8%\n",
      "Epoch: 50, loss: 566.71, accuracy: 70.0%\n",
      "Epoch: 55, loss: 560.14, accuracy: 69.9%\n",
      "Epoch: 60, loss: 553.69, accuracy: 70.4%\n",
      "Epoch: 65, loss: 547.47, accuracy: 70.9%\n",
      "Epoch: 70, loss: 541.55, accuracy: 70.5%\n",
      "Epoch: 75, loss: 535.97, accuracy: 71.2%\n",
      "Epoch: 80, loss: 530.74, accuracy: 71.4%\n",
      "Epoch: 85, loss: 525.86, accuracy: 71.4%\n",
      "Epoch: 90, loss: 521.28, accuracy: 71.8%\n",
      "Epoch: 95, loss: 516.97, accuracy: 72.1%\n",
      "Epoch: 100, loss: 512.93, accuracy: 72.0%\n",
      "Mean accuracy on T4: 66.53\n",
      "Mean losses on T4: 601.70\n",
      "\n",
      "Accuracy list on Ti sets: [66.23915900131406, 66.94590451160754, 67.19218134034166, 67.51719229084539, 66.53377192982455]\n",
      "Losses list on Ti sets: [622.3437350538853, 604.0274869468371, 595.5137978472726, 596.0267012384106, 601.7012257972866]\n",
      "Mean accuracy on all T sets: 66.89\n",
      "Mean losses on all T sets: 603.92\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć siódma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 1500, activation: relu\n",
      "2. Layer - input_dim: 1500, output_dim: 300, activation: relu\n",
      "3. Layer - input_dim: 300, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=1500, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=1500, output_dim=300, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=300, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 705.28, accuracy: 56.9%\n",
      "Epoch: 10, loss: 630.60, accuracy: 66.4%\n",
      "Epoch: 15, loss: 600.41, accuracy: 69.1%\n",
      "Epoch: 20, loss: 673.61, accuracy: 61.4%\n",
      "Epoch: 25, loss: 566.74, accuracy: 71.1%\n",
      "Epoch: 30, loss: 579.05, accuracy: 69.6%\n",
      "Epoch: 35, loss: 548.08, accuracy: 70.7%\n",
      "Epoch: 40, loss: 547.55, accuracy: 73.1%\n",
      "Epoch: 45, loss: 508.44, accuracy: 75.4%\n",
      "Epoch: 50, loss: 550.96, accuracy: 72.5%\n",
      "Epoch: 55, loss: 537.25, accuracy: 74.2%\n",
      "Epoch: 60, loss: 566.57, accuracy: 74.1%\n",
      "Epoch: 65, loss: 590.95, accuracy: 74.0%\n",
      "Epoch: 70, loss: 615.81, accuracy: 73.6%\n",
      "Epoch: 75, loss: 633.00, accuracy: 73.6%\n",
      "Epoch: 80, loss: 646.28, accuracy: 73.3%\n",
      "Epoch: 85, loss: 659.53, accuracy: 73.2%\n",
      "Epoch: 90, loss: 670.21, accuracy: 73.1%\n",
      "Epoch: 95, loss: 680.28, accuracy: 73.2%\n",
      "Epoch: 100, loss: 686.81, accuracy: 73.5%\n",
      "Mean accuracy on T0: 71.19\n",
      "Mean losses on T0: 629.77\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 672.31, accuracy: 58.1%\n",
      "Epoch: 10, loss: 582.10, accuracy: 69.9%\n",
      "Epoch: 15, loss: 547.53, accuracy: 72.9%\n",
      "Epoch: 20, loss: 572.80, accuracy: 71.2%\n",
      "Epoch: 25, loss: 601.97, accuracy: 68.6%\n",
      "Epoch: 30, loss: 508.54, accuracy: 74.1%\n",
      "Epoch: 35, loss: 508.43, accuracy: 74.6%\n",
      "Epoch: 40, loss: 520.39, accuracy: 73.6%\n",
      "Epoch: 45, loss: 550.51, accuracy: 74.5%\n",
      "Epoch: 50, loss: 589.87, accuracy: 73.9%\n",
      "Epoch: 55, loss: 626.79, accuracy: 74.0%\n",
      "Epoch: 60, loss: 665.08, accuracy: 74.0%\n",
      "Epoch: 65, loss: 692.91, accuracy: 74.0%\n",
      "Epoch: 70, loss: 715.02, accuracy: 73.5%\n",
      "Epoch: 75, loss: 733.75, accuracy: 73.2%\n",
      "Epoch: 80, loss: 749.79, accuracy: 73.2%\n",
      "Epoch: 85, loss: 763.37, accuracy: 73.3%\n",
      "Epoch: 90, loss: 774.46, accuracy: 72.8%\n",
      "Epoch: 95, loss: 784.03, accuracy: 73.3%\n",
      "Epoch: 100, loss: 791.74, accuracy: 73.2%\n",
      "Mean accuracy on T1: 72.33\n",
      "Mean losses on T1: 665.82\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 671.59, accuracy: 57.3%\n",
      "Epoch: 10, loss: 583.06, accuracy: 70.4%\n",
      "Epoch: 15, loss: 546.75, accuracy: 71.6%\n",
      "Epoch: 20, loss: 633.38, accuracy: 70.6%\n",
      "Epoch: 25, loss: 543.79, accuracy: 71.7%\n",
      "Epoch: 30, loss: 502.37, accuracy: 75.0%\n",
      "Epoch: 35, loss: 579.23, accuracy: 73.6%\n",
      "Epoch: 40, loss: 557.74, accuracy: 74.1%\n",
      "Epoch: 45, loss: 510.82, accuracy: 76.2%\n",
      "Epoch: 50, loss: 539.48, accuracy: 74.0%\n",
      "Epoch: 55, loss: 584.47, accuracy: 75.6%\n",
      "Epoch: 60, loss: 622.72, accuracy: 75.4%\n",
      "Epoch: 65, loss: 652.11, accuracy: 75.3%\n",
      "Epoch: 70, loss: 676.09, accuracy: 75.6%\n",
      "Epoch: 75, loss: 696.48, accuracy: 75.4%\n",
      "Epoch: 80, loss: 712.13, accuracy: 75.6%\n",
      "Epoch: 85, loss: 724.80, accuracy: 75.6%\n",
      "Epoch: 90, loss: 736.18, accuracy: 75.4%\n",
      "Epoch: 95, loss: 745.03, accuracy: 75.2%\n",
      "Epoch: 100, loss: 753.53, accuracy: 75.3%\n",
      "Mean accuracy on T2: 72.83\n",
      "Mean losses on T2: 654.05\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 694.12, accuracy: 58.1%\n",
      "Epoch: 10, loss: 610.64, accuracy: 66.8%\n",
      "Epoch: 15, loss: 580.14, accuracy: 69.3%\n",
      "Epoch: 20, loss: 539.04, accuracy: 72.9%\n",
      "Epoch: 25, loss: 552.06, accuracy: 71.4%\n",
      "Epoch: 30, loss: 529.41, accuracy: 72.9%\n",
      "Epoch: 35, loss: 516.12, accuracy: 73.1%\n",
      "Epoch: 40, loss: 658.61, accuracy: 71.9%\n",
      "Epoch: 45, loss: 500.88, accuracy: 75.8%\n",
      "Epoch: 50, loss: 562.69, accuracy: 73.7%\n",
      "Epoch: 55, loss: 548.21, accuracy: 75.2%\n",
      "Epoch: 60, loss: 561.86, accuracy: 76.0%\n",
      "Epoch: 65, loss: 587.80, accuracy: 76.5%\n",
      "Epoch: 70, loss: 608.52, accuracy: 75.7%\n",
      "Epoch: 75, loss: 626.02, accuracy: 76.1%\n",
      "Epoch: 80, loss: 640.77, accuracy: 75.8%\n",
      "Epoch: 85, loss: 652.92, accuracy: 75.4%\n",
      "Epoch: 90, loss: 663.06, accuracy: 75.4%\n",
      "Epoch: 95, loss: 671.31, accuracy: 75.6%\n",
      "Epoch: 100, loss: 678.83, accuracy: 75.6%\n",
      "Mean accuracy on T3: 72.81\n",
      "Mean losses on T3: 611.82\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 5, loss: 701.47, accuracy: 53.8%\n",
      "Epoch: 10, loss: 622.78, accuracy: 68.4%\n",
      "Epoch: 15, loss: 572.25, accuracy: 72.0%\n",
      "Epoch: 20, loss: 575.36, accuracy: 72.4%\n",
      "Epoch: 25, loss: 532.84, accuracy: 72.0%\n",
      "Epoch: 30, loss: 521.58, accuracy: 72.4%\n",
      "Epoch: 35, loss: 697.60, accuracy: 69.2%\n",
      "Epoch: 40, loss: 568.23, accuracy: 74.3%\n",
      "Epoch: 45, loss: 537.89, accuracy: 74.5%\n",
      "Epoch: 50, loss: 637.41, accuracy: 70.1%\n",
      "Epoch: 55, loss: 626.14, accuracy: 75.0%\n",
      "Epoch: 60, loss: 651.26, accuracy: 74.3%\n",
      "Epoch: 65, loss: 679.48, accuracy: 74.3%\n",
      "Epoch: 70, loss: 704.23, accuracy: 74.5%\n",
      "Epoch: 75, loss: 726.62, accuracy: 75.0%\n",
      "Epoch: 80, loss: 745.83, accuracy: 75.1%\n",
      "Epoch: 85, loss: 762.43, accuracy: 75.0%\n",
      "Epoch: 90, loss: 774.20, accuracy: 75.1%\n",
      "Epoch: 95, loss: 785.12, accuracy: 75.4%\n",
      "Epoch: 100, loss: 795.40, accuracy: 75.5%\n",
      "Mean accuracy on T4: 71.55\n",
      "Mean losses on T4: 658.33\n",
      "\n",
      "Accuracy list on Ti sets: [71.19382391590014, 72.32993867717914, 72.82720105124837, 72.8080376697328, 71.54758771929825]\n",
      "Losses list on Ti sets: [629.7685164712339, 665.815693600799, 654.0491649025073, 611.8174426015092, 658.3269715628161]\n",
      "Mean accuracy on all T sets: 72.14\n",
      "Mean losses on all T sets: 643.96\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć ósma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 1500, activation: sigmoid\n",
      "2. Layer - input_dim: 1500, output_dim: 300, activation: sigmoid\n",
      "3. Layer - input_dim: 300, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=1500, activation=\"sigmoid\")\n",
    "\n",
    "mlp.add_layer(input_dim=1500, output_dim=300, activation=\"sigmoid\")\n",
    "\n",
    "mlp.add_layer(input_dim=300, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 695.05, accuracy: 56.4%\n",
      "Epoch: 10, loss: 694.86, accuracy: 56.4%\n",
      "Epoch: 15, loss: 694.67, accuracy: 56.4%\n",
      "Epoch: 20, loss: 694.45, accuracy: 56.4%\n",
      "Epoch: 25, loss: 694.20, accuracy: 56.4%\n",
      "Epoch: 30, loss: 693.92, accuracy: 56.4%\n",
      "Epoch: 35, loss: 693.59, accuracy: 56.4%\n",
      "Epoch: 40, loss: 693.19, accuracy: 56.4%\n",
      "Epoch: 45, loss: 692.72, accuracy: 56.4%\n",
      "Epoch: 50, loss: 692.14, accuracy: 56.4%\n",
      "Epoch: 55, loss: 691.42, accuracy: 56.4%\n",
      "Epoch: 60, loss: 690.55, accuracy: 56.4%\n",
      "Epoch: 65, loss: 689.48, accuracy: 56.4%\n",
      "Epoch: 70, loss: 688.15, accuracy: 56.4%\n",
      "Epoch: 75, loss: 686.52, accuracy: 56.4%\n",
      "Epoch: 80, loss: 684.53, accuracy: 56.4%\n",
      "Epoch: 85, loss: 682.08, accuracy: 56.4%\n",
      "Epoch: 90, loss: 679.12, accuracy: 56.4%\n",
      "Epoch: 95, loss: 675.55, accuracy: 56.4%\n",
      "Epoch: 100, loss: 671.29, accuracy: 56.4%\n",
      "Mean accuracy on T0: 56.35\n",
      "Mean losses on T0: 694.80\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 725.50, accuracy: 55.2%\n",
      "Epoch: 10, loss: 725.36, accuracy: 55.2%\n",
      "Epoch: 15, loss: 725.21, accuracy: 55.2%\n",
      "Epoch: 20, loss: 725.05, accuracy: 55.2%\n",
      "Epoch: 25, loss: 724.85, accuracy: 55.2%\n",
      "Epoch: 30, loss: 724.62, accuracy: 55.2%\n",
      "Epoch: 35, loss: 724.34, accuracy: 55.2%\n",
      "Epoch: 40, loss: 724.00, accuracy: 55.2%\n",
      "Epoch: 45, loss: 723.57, accuracy: 55.2%\n",
      "Epoch: 50, loss: 723.03, accuracy: 55.2%\n",
      "Epoch: 55, loss: 722.36, accuracy: 55.2%\n",
      "Epoch: 60, loss: 721.51, accuracy: 55.2%\n",
      "Epoch: 65, loss: 720.45, accuracy: 55.2%\n",
      "Epoch: 70, loss: 719.13, accuracy: 55.2%\n",
      "Epoch: 75, loss: 717.49, accuracy: 55.2%\n",
      "Epoch: 80, loss: 715.45, accuracy: 55.2%\n",
      "Epoch: 85, loss: 712.97, accuracy: 55.2%\n",
      "Epoch: 90, loss: 709.99, accuracy: 55.2%\n",
      "Epoch: 95, loss: 706.44, accuracy: 55.2%\n",
      "Epoch: 100, loss: 702.33, accuracy: 55.2%\n",
      "Mean accuracy on T1: 55.17\n",
      "Mean losses on T1: 726.58\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 707.95, accuracy: 57.6%\n",
      "Epoch: 10, loss: 707.78, accuracy: 57.6%\n",
      "Epoch: 15, loss: 707.60, accuracy: 57.6%\n",
      "Epoch: 20, loss: 707.40, accuracy: 57.6%\n",
      "Epoch: 25, loss: 707.16, accuracy: 57.6%\n",
      "Epoch: 30, loss: 706.88, accuracy: 57.6%\n",
      "Epoch: 35, loss: 706.55, accuracy: 57.6%\n",
      "Epoch: 40, loss: 706.15, accuracy: 57.6%\n",
      "Epoch: 45, loss: 705.67, accuracy: 57.6%\n",
      "Epoch: 50, loss: 705.09, accuracy: 57.6%\n",
      "Epoch: 55, loss: 704.37, accuracy: 57.6%\n",
      "Epoch: 60, loss: 703.50, accuracy: 57.6%\n",
      "Epoch: 65, loss: 702.42, accuracy: 57.6%\n",
      "Epoch: 70, loss: 701.10, accuracy: 57.6%\n",
      "Epoch: 75, loss: 699.47, accuracy: 57.6%\n",
      "Epoch: 80, loss: 697.48, accuracy: 57.6%\n",
      "Epoch: 85, loss: 695.05, accuracy: 57.6%\n",
      "Epoch: 90, loss: 692.12, accuracy: 57.6%\n",
      "Epoch: 95, loss: 688.60, accuracy: 57.6%\n",
      "Epoch: 100, loss: 684.45, accuracy: 57.6%\n",
      "Mean accuracy on T2: 57.53\n",
      "Mean losses on T2: 708.06\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 5, loss: 696.80, accuracy: 58.7%\n",
      "Epoch: 10, loss: 696.64, accuracy: 58.7%\n",
      "Epoch: 15, loss: 696.45, accuracy: 58.7%\n",
      "Epoch: 20, loss: 696.25, accuracy: 58.7%\n",
      "Epoch: 25, loss: 696.01, accuracy: 58.7%\n",
      "Epoch: 30, loss: 695.73, accuracy: 58.7%\n",
      "Epoch: 35, loss: 695.40, accuracy: 58.7%\n",
      "Epoch: 40, loss: 695.01, accuracy: 58.7%\n",
      "Epoch: 45, loss: 694.55, accuracy: 58.7%\n",
      "Epoch: 50, loss: 693.98, accuracy: 58.7%\n",
      "Epoch: 55, loss: 693.28, accuracy: 58.7%\n",
      "Epoch: 60, loss: 692.43, accuracy: 58.7%\n",
      "Epoch: 65, loss: 691.38, accuracy: 58.7%\n",
      "Epoch: 70, loss: 690.10, accuracy: 58.7%\n",
      "Epoch: 75, loss: 688.51, accuracy: 58.7%\n",
      "Epoch: 80, loss: 686.57, accuracy: 58.7%\n",
      "Epoch: 85, loss: 684.19, accuracy: 58.7%\n",
      "Epoch: 90, loss: 681.30, accuracy: 58.7%\n",
      "Epoch: 95, loss: 677.81, accuracy: 58.7%\n",
      "Epoch: 100, loss: 673.42, accuracy: 58.7%\n",
      "Mean accuracy on T3: 58.71\n",
      "Mean losses on T3: 696.81\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 5, loss: 712.80, accuracy: 56.3%\n",
      "Epoch: 10, loss: 712.65, accuracy: 56.3%\n",
      "Epoch: 15, loss: 712.49, accuracy: 56.3%\n",
      "Epoch: 20, loss: 712.30, accuracy: 56.3%\n",
      "Epoch: 25, loss: 712.08, accuracy: 56.3%\n",
      "Epoch: 30, loss: 711.82, accuracy: 56.3%\n",
      "Epoch: 35, loss: 711.50, accuracy: 56.3%\n",
      "Epoch: 40, loss: 711.12, accuracy: 56.3%\n",
      "Epoch: 45, loss: 710.65, accuracy: 56.3%\n",
      "Epoch: 50, loss: 710.08, accuracy: 56.3%\n",
      "Epoch: 55, loss: 709.37, accuracy: 56.3%\n",
      "Epoch: 60, loss: 708.49, accuracy: 56.3%\n",
      "Epoch: 65, loss: 707.41, accuracy: 56.3%\n",
      "Epoch: 70, loss: 706.07, accuracy: 56.3%\n",
      "Epoch: 75, loss: 704.43, accuracy: 56.3%\n",
      "Epoch: 80, loss: 702.41, accuracy: 56.3%\n",
      "Epoch: 85, loss: 699.94, accuracy: 56.3%\n",
      "Epoch: 90, loss: 696.94, accuracy: 56.3%\n",
      "Epoch: 95, loss: 693.35, accuracy: 56.3%\n",
      "Epoch: 100, loss: 689.08, accuracy: 56.3%\n",
      "Mean accuracy on T4: 56.30\n",
      "Mean losses on T4: 712.77\n",
      "\n",
      "Accuracy list on Ti sets: [56.35490582566799, 55.17148488830487, 57.53361804643013, 58.71495838808587, 56.29561403508771]\n",
      "Losses list on Ti sets: [694.804148208703, 726.5797168260274, 708.0596238722006, 696.8059397631018, 712.7670505813503]\n",
      "Mean accuracy on all T sets: 56.81\n",
      "Mean losses on all T sets: 707.80\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
