{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import MLP\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (1000, 8257), y_train.shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "print(f'x_train.shape: {x_train.shape}, y_train.shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 1000, activation: relu\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=1000, activation=\"relu\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 1000, activation: relu\n",
      "1. Layer - input_dim: 1000, output_dim: 20, activation: relu\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=1000, output_dim=20, activation=\"relu\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 1000, activation: relu\n",
      "1. Layer - input_dim: 1000, output_dim: 20, activation: relu\n",
      "1. Layer - input_dim: 20, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=20, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.init_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00548604, 0.00417872, 0.00584317, ..., 0.00667436, 0.00176829,\n",
       "        0.00939772],\n",
       "       [0.00844357, 0.00781857, 0.00773649, ..., 0.00289584, 0.00613755,\n",
       "        0.0035885 ],\n",
       "       [0.0054506 , 0.00790642, 0.00171168, ..., 0.00170385, 0.00867165,\n",
       "        0.00417008],\n",
       "       ...,\n",
       "       [0.00631597, 0.00496235, 0.00196661, ..., 0.00014997, 0.0027813 ,\n",
       "        0.00322009],\n",
       "       [0.00134574, 0.00925887, 0.00676911, ..., 0.00079903, 0.00384524,\n",
       "        0.00918386],\n",
       "       [0.00421566, 0.00258786, 0.00021377, ..., 0.00446141, 0.00875802,\n",
       "        0.00105812]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.param_values['w2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.forward(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30392067 0.30947686 0.29581975 ... 0.30358477 0.2789873  0.31591833]\n",
      " [0.40728776 0.41735862 0.3978703  ... 0.40805987 0.37870041 0.41571528]\n",
      " [0.2298877  0.23671549 0.22087262 ... 0.22571384 0.20639259 0.23904522]\n",
      " ...\n",
      " [0.40661899 0.41833895 0.39713285 ... 0.4060521  0.37654949 0.41470012]\n",
      " [0.67654038 0.69066003 0.6722436  ... 0.68563508 0.64126667 0.68626106]\n",
      " [0.60229574 0.61839894 0.59651126 ... 0.60677424 0.56857337 0.61520251]]\n",
      "[[0.57540068 0.57675756 0.5734203  ... 0.57531861 0.56929793 0.5783292 ]\n",
      " [0.60043736 0.60285102 0.59817587 ... 0.60062258 0.59355962 0.6024575 ]\n",
      " [0.55722015 0.55890408 0.55499476 ... 0.5561901  0.55141576 0.55947835]\n",
      " ...\n",
      " [0.6002769  0.60308571 0.5979986  ... 0.60014087 0.59304061 0.60221434]\n",
      " [0.66296611 0.66611374 0.66200536 ... 0.66499523 0.65503974 0.66513467]\n",
      " [0.64618136 0.64985432 0.64485773 ... 0.64720461 0.63843392 0.64912665]]\n"
     ]
    }
   ],
   "source": [
    "z = np.dot(mlp.memory['a1'], mlp.param_values['w2']) + mlp.param_values['b2']\n",
    "a = 1/(1+np.exp(-z))\n",
    "print(z)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1100.06, accuracy: 10.5%\n"
     ]
    }
   ],
   "source": [
    "mlp.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30392067, 0.30947686, 0.29581975, ..., 0.30358477, 0.2789873 ,\n",
       "        0.31591833],\n",
       "       [0.40728776, 0.41735862, 0.3978703 , ..., 0.40805987, 0.37870041,\n",
       "        0.41571528],\n",
       "       [0.2298877 , 0.23671549, 0.22087262, ..., 0.22571384, 0.20639259,\n",
       "        0.23904522],\n",
       "       ...,\n",
       "       [0.40661899, 0.41833895, 0.39713285, ..., 0.4060521 , 0.37654949,\n",
       "        0.41470012],\n",
       "       [0.67654038, 0.69066003, 0.6722436 , ..., 0.68563508, 0.64126667,\n",
       "        0.68626106],\n",
       "       [0.60229574, 0.61839894, 0.59651126, ..., 0.60677424, 0.56857337,\n",
       "        0.61520251]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.memory['a2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 970.36, accuracy: 55.5%\n",
      "loss: 966.56, accuracy: 55.5%\n",
      "loss: 944.58, accuracy: 55.5%\n",
      "loss: 939.88, accuracy: 55.5%\n",
      "loss: 936.79, accuracy: 55.5%\n",
      "loss: 934.80, accuracy: 55.5%\n",
      "loss: 932.99, accuracy: 55.5%\n",
      "loss: 931.22, accuracy: 55.5%\n",
      "loss: 929.38, accuracy: 55.5%\n",
      "loss: 927.40, accuracy: 55.5%\n",
      "loss: 925.22, accuracy: 55.5%\n",
      "loss: 922.79, accuracy: 55.5%\n",
      "loss: 920.03, accuracy: 55.5%\n",
      "loss: 916.89, accuracy: 55.5%\n",
      "loss: 913.28, accuracy: 55.5%\n",
      "loss: 909.13, accuracy: 55.5%\n",
      "loss: 904.34, accuracy: 55.5%\n",
      "loss: 898.81, accuracy: 55.8%\n",
      "loss: 892.46, accuracy: 55.9%\n",
      "loss: 885.16, accuracy: 56.2%\n",
      "loss: 876.84, accuracy: 57.4%\n",
      "loss: 867.44, accuracy: 58.2%\n",
      "loss: 856.94, accuracy: 59.9%\n",
      "loss: 845.45, accuracy: 61.5%\n",
      "loss: 833.27, accuracy: 62.7%\n",
      "loss: 821.25, accuracy: 65.6%\n",
      "loss: 811.83, accuracy: 66.0%\n",
      "loss: 817.77, accuracy: 69.2%\n",
      "loss: 883.46, accuracy: 62.5%\n",
      "loss: 1103.52, accuracy: 34.0%\n",
      "loss: 802.53, accuracy: 66.8%\n",
      "loss: 809.40, accuracy: 69.9%\n",
      "loss: 816.60, accuracy: 67.7%\n",
      "loss: 859.10, accuracy: 66.9%\n",
      "loss: 836.34, accuracy: 68.4%\n",
      "loss: 880.28, accuracy: 63.1%\n",
      "loss: 813.51, accuracy: 69.5%\n",
      "loss: 829.61, accuracy: 68.5%\n",
      "loss: 797.70, accuracy: 70.3%\n",
      "loss: 806.46, accuracy: 70.0%\n",
      "loss: 786.14, accuracy: 70.7%\n",
      "loss: 793.38, accuracy: 70.4%\n",
      "loss: 777.94, accuracy: 71.4%\n",
      "loss: 785.52, accuracy: 70.5%\n",
      "loss: 772.37, accuracy: 71.3%\n",
      "loss: 781.08, accuracy: 70.5%\n",
      "loss: 768.99, accuracy: 71.9%\n",
      "loss: 779.03, accuracy: 70.7%\n",
      "loss: 765.97, accuracy: 72.2%\n",
      "loss: 777.94, accuracy: 70.1%\n",
      "loss: 762.79, accuracy: 72.8%\n",
      "loss: 776.06, accuracy: 70.0%\n",
      "loss: 758.76, accuracy: 73.1%\n",
      "loss: 773.13, accuracy: 69.9%\n",
      "loss: 757.23, accuracy: 73.0%\n",
      "loss: 775.72, accuracy: 69.7%\n",
      "loss: 756.32, accuracy: 73.2%\n",
      "loss: 776.31, accuracy: 69.5%\n",
      "loss: 752.69, accuracy: 73.5%\n",
      "loss: 770.98, accuracy: 70.2%\n",
      "loss: 746.27, accuracy: 74.1%\n",
      "loss: 765.57, accuracy: 70.3%\n",
      "loss: 742.09, accuracy: 73.9%\n",
      "loss: 764.86, accuracy: 70.5%\n",
      "loss: 741.11, accuracy: 74.1%\n",
      "loss: 767.47, accuracy: 70.3%\n",
      "loss: 738.43, accuracy: 74.4%\n",
      "loss: 763.60, accuracy: 70.6%\n",
      "loss: 732.96, accuracy: 74.7%\n",
      "loss: 757.92, accuracy: 71.1%\n",
      "loss: 729.09, accuracy: 74.5%\n",
      "loss: 757.83, accuracy: 70.7%\n",
      "loss: 728.98, accuracy: 74.7%\n",
      "loss: 760.60, accuracy: 70.4%\n",
      "loss: 726.88, accuracy: 74.8%\n",
      "loss: 754.42, accuracy: 71.1%\n",
      "loss: 718.65, accuracy: 75.1%\n",
      "loss: 743.04, accuracy: 71.8%\n",
      "loss: 712.84, accuracy: 75.0%\n",
      "loss: 744.92, accuracy: 71.6%\n",
      "loss: 717.66, accuracy: 74.9%\n",
      "loss: 755.63, accuracy: 70.8%\n",
      "loss: 713.93, accuracy: 75.4%\n",
      "loss: 739.84, accuracy: 72.1%\n",
      "loss: 700.19, accuracy: 75.7%\n",
      "loss: 723.46, accuracy: 72.8%\n",
      "loss: 695.21, accuracy: 75.5%\n",
      "loss: 733.07, accuracy: 72.0%\n",
      "loss: 704.92, accuracy: 75.0%\n",
      "loss: 749.84, accuracy: 70.9%\n",
      "loss: 697.30, accuracy: 76.0%\n",
      "loss: 720.96, accuracy: 72.8%\n",
      "loss: 677.85, accuracy: 76.8%\n",
      "loss: 698.71, accuracy: 73.5%\n",
      "loss: 671.48, accuracy: 76.9%\n",
      "loss: 710.84, accuracy: 72.9%\n",
      "loss: 687.09, accuracy: 76.0%\n",
      "loss: 742.70, accuracy: 71.4%\n",
      "loss: 691.58, accuracy: 76.0%\n",
      "loss: 724.24, accuracy: 72.4%\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    mlp.train(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
