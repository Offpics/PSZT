{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import MLP\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (1000, 8257), y_train.shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "print(f'x_train.shape: {x_train.shape}, y_train.shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 4, activation: sigmoid\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=4, activation=\"sigmoid\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 4, activation: sigmoid\n",
      "1. Layer - input_dim: 4, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=4, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.init_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1063.205829364338, accuracy: 34.0%\n",
      "loss: 943.277904942403, accuracy: 55.5%\n",
      "loss: 935.2590892228111, accuracy: 55.5%\n",
      "loss: 933.1239313205226, accuracy: 55.5%\n",
      "loss: 932.2793523536168, accuracy: 55.5%\n",
      "loss: 931.8020887356797, accuracy: 55.5%\n",
      "loss: 931.4420026529243, accuracy: 55.5%\n",
      "loss: 931.1219764053122, accuracy: 55.5%\n",
      "loss: 930.8158539354838, accuracy: 55.5%\n",
      "loss: 930.5135859628746, accuracy: 55.5%\n",
      "loss: 930.2104342115457, accuracy: 55.5%\n",
      "loss: 929.9034680795286, accuracy: 55.5%\n",
      "loss: 929.590391542088, accuracy: 55.5%\n",
      "loss: 929.2691373028892, accuracy: 55.5%\n",
      "loss: 928.937718155488, accuracy: 55.5%\n",
      "loss: 928.5941657077542, accuracy: 55.5%\n",
      "loss: 928.2364992248392, accuracy: 55.5%\n",
      "loss: 927.8627051053019, accuracy: 55.5%\n",
      "loss: 927.4707202555621, accuracy: 55.5%\n",
      "loss: 927.0584169499407, accuracy: 55.5%\n",
      "loss: 926.6235882342075, accuracy: 55.5%\n",
      "loss: 926.163933434662, accuracy: 55.5%\n",
      "loss: 925.6770435107326, accuracy: 55.5%\n",
      "loss: 925.1603860533141, accuracy: 55.5%\n",
      "loss: 924.6112897573191, accuracy: 55.5%\n",
      "loss: 924.0269282107996, accuracy: 55.5%\n",
      "loss: 923.404302854153, accuracy: 55.5%\n",
      "loss: 922.7402249758798, accuracy: 55.5%\n",
      "loss: 922.0312966293212, accuracy: 55.5%\n",
      "loss: 921.2738903809943, accuracy: 55.5%\n",
      "loss: 920.464127839406, accuracy: 55.5%\n",
      "loss: 919.5978569683348, accuracy: 55.5%\n",
      "loss: 918.6706282665187, accuracy: 55.5%\n",
      "loss: 917.6776700039337, accuracy: 55.5%\n",
      "loss: 916.6138628525059, accuracy: 55.5%\n",
      "loss: 915.4737144471496, accuracy: 55.5%\n",
      "loss: 914.251334674281, accuracy: 55.5%\n",
      "loss: 912.9404128238552, accuracy: 55.5%\n",
      "loss: 911.5341981728736, accuracy: 55.5%\n",
      "loss: 910.0254861080534, accuracy: 55.5%\n",
      "loss: 908.4066125548325, accuracy: 55.5%\n",
      "loss: 906.6694602638504, accuracy: 55.5%\n",
      "loss: 904.8054814060484, accuracy: 55.5%\n",
      "loss: 902.8057419128908, accuracy: 55.5%\n",
      "loss: 900.6609940043277, accuracy: 55.5%\n",
      "loss: 898.3617842608282, accuracy: 55.5%\n",
      "loss: 895.8986052397547, accuracy: 55.5%\n",
      "loss: 893.2620987556362, accuracy: 55.5%\n",
      "loss: 890.4433182016385, accuracy: 55.5%\n",
      "loss: 887.4340552813827, accuracy: 55.5%\n",
      "loss: 884.2272328208157, accuracy: 55.5%\n",
      "loss: 880.8173595841472, accuracy: 55.5%\n",
      "loss: 877.2010350845612, accuracy: 55.5%\n",
      "loss: 873.3774825161423, accuracy: 55.6%\n",
      "loss: 869.3490769799645, accuracy: 55.6%\n",
      "loss: 865.1218256765552, accuracy: 55.9%\n",
      "loss: 860.7057488755675, accuracy: 56.6%\n",
      "loss: 856.115107766112, accuracy: 57.5%\n",
      "loss: 851.3684299829295, accuracy: 58.4%\n",
      "loss: 846.4882968977629, accuracy: 60.1%\n",
      "loss: 841.5008781249097, accuracy: 61.4%\n",
      "loss: 836.4352255311871, accuracy: 63.2%\n",
      "loss: 831.322367059, accuracy: 64.2%\n",
      "loss: 826.1942648064725, accuracy: 65.4%\n",
      "loss: 821.0827175628598, accuracy: 66.2%\n",
      "loss: 816.0182926370719, accuracy: 67.3%\n",
      "loss: 811.0293650218484, accuracy: 68.3%\n",
      "loss: 806.1413257005202, accuracy: 69.0%\n",
      "loss: 801.3759988037505, accuracy: 69.9%\n",
      "loss: 796.7512834803877, accuracy: 70.2%\n",
      "loss: 792.2810144497568, accuracy: 70.5%\n",
      "loss: 787.9750178622272, accuracy: 70.5%\n",
      "loss: 783.8393276002414, accuracy: 70.8%\n",
      "loss: 779.8765215838762, accuracy: 71.2%\n",
      "loss: 776.0861372012623, accuracy: 71.3%\n",
      "loss: 772.4651283756971, accuracy: 71.5%\n",
      "loss: 769.00833258805, accuracy: 71.2%\n",
      "loss: 765.708923101799, accuracy: 71.4%\n",
      "loss: 762.5588286670854, accuracy: 71.3%\n",
      "loss: 759.5491094076618, accuracy: 71.3%\n",
      "loss: 756.6702830187314, accuracy: 71.6%\n",
      "loss: 753.9125996657822, accuracy: 71.7%\n",
      "loss: 751.2662670893164, accuracy: 71.8%\n",
      "loss: 748.7216295097771, accuracy: 71.8%\n",
      "loss: 746.2693051660792, accuracy: 71.9%\n",
      "loss: 743.9002878992881, accuracy: 72.0%\n",
      "loss: 741.6060182886249, accuracy: 72.0%\n",
      "loss: 739.3784296143612, accuracy: 72.0%\n",
      "loss: 737.2099734858712, accuracy: 72.1%\n",
      "loss: 735.0936294282999, accuracy: 72.2%\n",
      "loss: 733.0229021366076, accuracy: 72.4%\n",
      "loss: 730.991809527927, accuracy: 72.5%\n",
      "loss: 728.9948641816201, accuracy: 72.5%\n",
      "loss: 727.0270502677204, accuracy: 72.4%\n",
      "loss: 725.0837976359355, accuracy: 72.5%\n",
      "loss: 723.1609543702473, accuracy: 72.7%\n",
      "loss: 721.2547588056291, accuracy: 72.7%\n",
      "loss: 719.3618117485127, accuracy: 72.9%\n",
      "loss: 717.4790494352987, accuracy: 73.0%\n",
      "loss: 715.6037175970711, accuracy: 73.0%\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    mlp.train(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
