{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import MLP\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (1000, 8257), y_train.shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "print(f'x_train.shape: {x_train.shape}, y_train.shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 4, activation: sigmoid\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=4, activation=\"sigmoid\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 4, activation: sigmoid\n",
      "2. Layer - input_dim: 4, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=4, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.init_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.param_values['w2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'input_dim': 4, 'output_dim': 3, 'activation': 'softmax'}\n",
      "1\n",
      "{'input_dim': 8257, 'output_dim': 4, 'activation': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "for i, layer in reversed(list(enumerate(mlp.layers, start=1))):\n",
    "    print(i)\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1098.75, accuracy: 34.0%\n",
      "loss: 959.37, accuracy: 55.5%\n",
      "loss: 939.46, accuracy: 55.5%\n",
      "loss: 933.27, accuracy: 55.5%\n",
      "loss: 930.61, accuracy: 55.5%\n",
      "loss: 929.23, accuracy: 55.5%\n",
      "loss: 928.36, accuracy: 55.5%\n",
      "loss: 927.69, accuracy: 55.5%\n",
      "loss: 927.08, accuracy: 55.5%\n",
      "loss: 926.48, accuracy: 55.5%\n",
      "loss: 925.86, accuracy: 55.5%\n",
      "loss: 925.20, accuracy: 55.5%\n",
      "loss: 924.48, accuracy: 55.5%\n",
      "loss: 923.71, accuracy: 55.5%\n",
      "loss: 922.86, accuracy: 55.5%\n",
      "loss: 921.93, accuracy: 55.5%\n",
      "loss: 920.91, accuracy: 55.5%\n",
      "loss: 919.80, accuracy: 55.5%\n",
      "loss: 918.59, accuracy: 55.5%\n",
      "loss: 917.26, accuracy: 55.5%\n",
      "loss: 915.80, accuracy: 55.5%\n",
      "loss: 914.21, accuracy: 55.5%\n",
      "loss: 912.48, accuracy: 55.5%\n",
      "loss: 910.60, accuracy: 55.5%\n",
      "loss: 908.56, accuracy: 55.5%\n",
      "loss: 906.35, accuracy: 55.5%\n",
      "loss: 903.96, accuracy: 55.5%\n",
      "loss: 901.38, accuracy: 55.5%\n",
      "loss: 898.62, accuracy: 55.5%\n",
      "loss: 895.65, accuracy: 55.5%\n",
      "loss: 892.49, accuracy: 55.5%\n",
      "loss: 889.13, accuracy: 55.5%\n",
      "loss: 885.58, accuracy: 55.5%\n",
      "loss: 881.83, accuracy: 55.5%\n",
      "loss: 877.89, accuracy: 55.5%\n",
      "loss: 873.77, accuracy: 55.5%\n",
      "loss: 869.48, accuracy: 55.5%\n",
      "loss: 865.04, accuracy: 55.5%\n",
      "loss: 860.46, accuracy: 55.7%\n",
      "loss: 855.76, accuracy: 56.2%\n",
      "loss: 850.97, accuracy: 56.8%\n",
      "loss: 846.11, accuracy: 57.4%\n",
      "loss: 841.20, accuracy: 58.2%\n",
      "loss: 836.27, accuracy: 59.5%\n",
      "loss: 831.34, accuracy: 61.1%\n",
      "loss: 826.44, accuracy: 62.7%\n",
      "loss: 821.58, accuracy: 64.7%\n",
      "loss: 816.80, accuracy: 66.3%\n",
      "loss: 812.11, accuracy: 66.7%\n",
      "loss: 807.53, accuracy: 68.0%\n",
      "loss: 803.06, accuracy: 68.4%\n",
      "loss: 798.74, accuracy: 68.9%\n",
      "loss: 794.55, accuracy: 68.5%\n",
      "loss: 790.51, accuracy: 68.6%\n",
      "loss: 786.62, accuracy: 69.8%\n",
      "loss: 782.88, accuracy: 70.2%\n",
      "loss: 779.30, accuracy: 70.6%\n",
      "loss: 775.86, accuracy: 71.0%\n",
      "loss: 772.57, accuracy: 71.2%\n",
      "loss: 769.41, accuracy: 71.1%\n",
      "loss: 766.39, accuracy: 71.1%\n",
      "loss: 763.49, accuracy: 71.1%\n",
      "loss: 760.71, accuracy: 71.2%\n",
      "loss: 758.04, accuracy: 71.2%\n",
      "loss: 755.47, accuracy: 71.5%\n",
      "loss: 752.99, accuracy: 71.6%\n",
      "loss: 750.60, accuracy: 71.7%\n",
      "loss: 748.30, accuracy: 71.9%\n",
      "loss: 746.06, accuracy: 71.8%\n",
      "loss: 743.88, accuracy: 71.9%\n",
      "loss: 741.77, accuracy: 71.9%\n",
      "loss: 739.71, accuracy: 72.0%\n",
      "loss: 737.69, accuracy: 72.3%\n",
      "loss: 735.72, accuracy: 72.3%\n",
      "loss: 733.78, accuracy: 72.3%\n",
      "loss: 731.88, accuracy: 72.6%\n",
      "loss: 730.00, accuracy: 72.8%\n",
      "loss: 728.14, accuracy: 72.8%\n",
      "loss: 726.31, accuracy: 72.8%\n",
      "loss: 724.49, accuracy: 72.8%\n",
      "loss: 722.69, accuracy: 72.9%\n",
      "loss: 720.90, accuracy: 72.9%\n",
      "loss: 719.12, accuracy: 72.9%\n",
      "loss: 717.35, accuracy: 73.1%\n",
      "loss: 715.58, accuracy: 73.1%\n",
      "loss: 713.81, accuracy: 73.2%\n",
      "loss: 712.05, accuracy: 73.0%\n",
      "loss: 710.28, accuracy: 73.0%\n",
      "loss: 708.52, accuracy: 73.3%\n",
      "loss: 706.75, accuracy: 73.4%\n",
      "loss: 704.98, accuracy: 73.5%\n",
      "loss: 703.21, accuracy: 73.9%\n",
      "loss: 701.43, accuracy: 74.1%\n",
      "loss: 699.64, accuracy: 74.2%\n",
      "loss: 697.85, accuracy: 74.3%\n",
      "loss: 696.06, accuracy: 74.5%\n",
      "loss: 694.26, accuracy: 74.5%\n",
      "loss: 692.45, accuracy: 74.8%\n",
      "loss: 690.63, accuracy: 74.9%\n",
      "loss: 688.81, accuracy: 74.9%\n",
      "loss: 686.98, accuracy: 75.4%\n",
      "loss: 685.14, accuracy: 75.4%\n",
      "loss: 683.30, accuracy: 75.5%\n",
      "loss: 681.45, accuracy: 75.5%\n",
      "loss: 679.60, accuracy: 75.6%\n",
      "loss: 677.73, accuracy: 75.7%\n",
      "loss: 675.87, accuracy: 75.8%\n",
      "loss: 673.99, accuracy: 75.8%\n",
      "loss: 672.11, accuracy: 76.1%\n",
      "loss: 670.23, accuracy: 76.4%\n",
      "loss: 668.34, accuracy: 76.5%\n",
      "loss: 666.44, accuracy: 76.6%\n",
      "loss: 664.54, accuracy: 76.7%\n",
      "loss: 662.64, accuracy: 76.8%\n",
      "loss: 660.73, accuracy: 76.9%\n",
      "loss: 658.82, accuracy: 77.1%\n",
      "loss: 656.91, accuracy: 77.1%\n",
      "loss: 654.99, accuracy: 77.1%\n",
      "loss: 653.07, accuracy: 77.3%\n",
      "loss: 651.15, accuracy: 77.4%\n",
      "loss: 649.22, accuracy: 77.6%\n",
      "loss: 647.30, accuracy: 77.5%\n",
      "loss: 645.37, accuracy: 77.6%\n",
      "loss: 643.45, accuracy: 77.8%\n",
      "loss: 641.52, accuracy: 78.0%\n",
      "loss: 639.59, accuracy: 78.2%\n",
      "loss: 637.66, accuracy: 78.3%\n",
      "loss: 635.73, accuracy: 78.4%\n",
      "loss: 633.80, accuracy: 78.5%\n",
      "loss: 631.87, accuracy: 78.5%\n",
      "loss: 629.94, accuracy: 78.5%\n",
      "loss: 628.01, accuracy: 78.6%\n",
      "loss: 626.09, accuracy: 79.0%\n",
      "loss: 624.16, accuracy: 79.0%\n",
      "loss: 622.23, accuracy: 79.1%\n",
      "loss: 620.31, accuracy: 79.2%\n",
      "loss: 618.39, accuracy: 79.2%\n",
      "loss: 616.47, accuracy: 79.3%\n",
      "loss: 614.54, accuracy: 79.7%\n",
      "loss: 612.63, accuracy: 79.9%\n",
      "loss: 610.71, accuracy: 79.9%\n",
      "loss: 608.79, accuracy: 80.0%\n",
      "loss: 606.88, accuracy: 80.1%\n",
      "loss: 604.97, accuracy: 80.0%\n",
      "loss: 603.06, accuracy: 80.0%\n",
      "loss: 601.16, accuracy: 80.2%\n",
      "loss: 599.25, accuracy: 80.2%\n",
      "loss: 597.35, accuracy: 80.3%\n",
      "loss: 595.45, accuracy: 80.3%\n",
      "loss: 593.56, accuracy: 80.4%\n",
      "loss: 591.66, accuracy: 80.4%\n",
      "loss: 589.77, accuracy: 80.5%\n",
      "loss: 587.89, accuracy: 80.5%\n",
      "loss: 586.00, accuracy: 80.6%\n",
      "loss: 584.12, accuracy: 80.8%\n",
      "loss: 582.24, accuracy: 80.8%\n",
      "loss: 580.37, accuracy: 80.8%\n",
      "loss: 578.50, accuracy: 80.9%\n",
      "loss: 576.63, accuracy: 80.8%\n",
      "loss: 574.77, accuracy: 81.0%\n",
      "loss: 572.91, accuracy: 81.0%\n",
      "loss: 571.05, accuracy: 81.0%\n",
      "loss: 569.20, accuracy: 81.0%\n",
      "loss: 567.36, accuracy: 81.0%\n",
      "loss: 565.51, accuracy: 81.2%\n",
      "loss: 563.67, accuracy: 81.4%\n",
      "loss: 561.84, accuracy: 81.4%\n",
      "loss: 560.01, accuracy: 81.4%\n",
      "loss: 558.18, accuracy: 81.4%\n",
      "loss: 556.36, accuracy: 81.5%\n",
      "loss: 554.55, accuracy: 81.6%\n",
      "loss: 552.74, accuracy: 81.6%\n",
      "loss: 550.93, accuracy: 81.7%\n",
      "loss: 549.13, accuracy: 81.7%\n",
      "loss: 547.34, accuracy: 81.7%\n",
      "loss: 545.55, accuracy: 81.9%\n",
      "loss: 543.76, accuracy: 81.9%\n",
      "loss: 541.98, accuracy: 82.0%\n",
      "loss: 540.21, accuracy: 82.2%\n",
      "loss: 538.44, accuracy: 82.2%\n",
      "loss: 536.68, accuracy: 82.2%\n",
      "loss: 534.93, accuracy: 82.2%\n",
      "loss: 533.18, accuracy: 82.3%\n",
      "loss: 531.43, accuracy: 82.4%\n",
      "loss: 529.70, accuracy: 82.4%\n",
      "loss: 527.96, accuracy: 82.5%\n",
      "loss: 526.24, accuracy: 82.5%\n",
      "loss: 524.52, accuracy: 82.6%\n",
      "loss: 522.81, accuracy: 82.8%\n",
      "loss: 521.10, accuracy: 82.9%\n",
      "loss: 519.41, accuracy: 83.0%\n",
      "loss: 517.71, accuracy: 83.1%\n",
      "loss: 516.03, accuracy: 83.1%\n",
      "loss: 514.35, accuracy: 83.3%\n",
      "loss: 512.68, accuracy: 83.3%\n",
      "loss: 511.01, accuracy: 83.5%\n",
      "loss: 509.35, accuracy: 83.5%\n",
      "loss: 507.70, accuracy: 83.6%\n",
      "loss: 506.06, accuracy: 83.6%\n",
      "loss: 504.42, accuracy: 83.6%\n"
     ]
    }
   ],
   "source": [
    "mlp.train(x=x_train, y_true=y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00186993,  0.0086562 ,  0.00356705,  0.00202884],\n",
       "       [-0.00288233,  0.00030999, -0.00214782,  0.00342248],\n",
       "       [-0.01532245, -0.00818486, -0.02007404, -0.01109458],\n",
       "       ...,\n",
       "       [ 0.00489668,  0.00635835,  0.00088111,  0.00095406],\n",
       "       [ 0.0077584 ,  0.00875856,  0.004914  ,  0.00630643],\n",
       "       [ 0.01033861,  0.00989636,  0.02098852,  0.00954959]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.param_values['w1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03391498, 0.91538376, 0.05070126],\n",
       "       [0.02441594, 0.9335276 , 0.04205645],\n",
       "       [0.32561837, 0.52374115, 0.15064049],\n",
       "       ...,\n",
       "       [0.0736053 , 0.84916867, 0.07722603],\n",
       "       [0.66596859, 0.18546461, 0.1485668 ],\n",
       "       [0.020592  , 0.94101831, 0.03838969]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = mlp.memory['a2']\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = 0\n",
    "for i in range(len(a2)):\n",
    "    equal = np.equal(np.argmax(y_train[i]), np.argmax(a2[i]))\n",
    "    correct_pred += equal.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(correct_pred/len(y_train)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(np.argmax(y_train), np.argmax(a2)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
