{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pszt import net\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = net.MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (1000, 8257), y_train.shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "print(f'x_train.shape: {x_train.shape}, y_train.shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 4, activation: sigmoid\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=4, activation=\"sigmoid\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 4, activation: sigmoid\n",
      "2. Layer - input_dim: 4, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=4, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.init_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.param_values['w2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'input_dim': 4, 'output_dim': 3, 'activation': 'softmax'}\n",
      "1\n",
      "{'input_dim': 8257, 'output_dim': 4, 'activation': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "for i, layer in reversed(list(enumerate(mlp.layers, start=1))):\n",
    "    print(i)\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1097.12, accuracy: 55.5%\n",
      "loss: 958.98, accuracy: 55.5%\n",
      "loss: 939.45, accuracy: 55.5%\n",
      "loss: 933.38, accuracy: 55.5%\n",
      "loss: 930.80, accuracy: 55.5%\n",
      "loss: 929.48, accuracy: 55.5%\n",
      "loss: 928.67, accuracy: 55.5%\n",
      "loss: 928.06, accuracy: 55.5%\n",
      "loss: 927.51, accuracy: 55.5%\n",
      "loss: 926.98, accuracy: 55.5%\n",
      "loss: 926.42, accuracy: 55.5%\n",
      "loss: 925.84, accuracy: 55.5%\n",
      "loss: 925.21, accuracy: 55.5%\n",
      "loss: 924.52, accuracy: 55.5%\n",
      "loss: 923.78, accuracy: 55.5%\n",
      "loss: 922.96, accuracy: 55.5%\n",
      "loss: 922.07, accuracy: 55.5%\n",
      "loss: 921.09, accuracy: 55.5%\n",
      "loss: 920.02, accuracy: 55.5%\n",
      "loss: 918.85, accuracy: 55.5%\n",
      "loss: 917.57, accuracy: 55.5%\n",
      "loss: 916.17, accuracy: 55.5%\n",
      "loss: 914.64, accuracy: 55.5%\n",
      "loss: 912.97, accuracy: 55.5%\n",
      "loss: 911.15, accuracy: 55.5%\n",
      "loss: 909.18, accuracy: 55.5%\n",
      "loss: 907.04, accuracy: 55.5%\n",
      "loss: 904.73, accuracy: 55.5%\n",
      "loss: 902.24, accuracy: 55.5%\n",
      "loss: 899.56, accuracy: 55.5%\n",
      "loss: 896.68, accuracy: 55.5%\n",
      "loss: 893.61, accuracy: 55.5%\n",
      "loss: 890.35, accuracy: 55.5%\n",
      "loss: 886.88, accuracy: 55.5%\n",
      "loss: 883.22, accuracy: 55.5%\n",
      "loss: 879.37, accuracy: 55.5%\n",
      "loss: 875.33, accuracy: 55.5%\n",
      "loss: 871.13, accuracy: 55.5%\n",
      "loss: 866.76, accuracy: 55.5%\n",
      "loss: 862.25, accuracy: 55.7%\n",
      "loss: 857.62, accuracy: 56.2%\n",
      "loss: 852.88, accuracy: 56.7%\n",
      "loss: 848.06, accuracy: 57.1%\n",
      "loss: 843.18, accuracy: 57.8%\n",
      "loss: 838.27, accuracy: 59.0%\n",
      "loss: 833.35, accuracy: 60.8%\n",
      "loss: 828.45, accuracy: 62.0%\n",
      "loss: 823.58, accuracy: 64.2%\n",
      "loss: 818.78, accuracy: 66.1%\n",
      "loss: 814.07, accuracy: 66.6%\n",
      "loss: 809.45, accuracy: 67.3%\n",
      "loss: 804.95, accuracy: 68.2%\n",
      "loss: 800.57, accuracy: 68.7%\n",
      "loss: 796.34, accuracy: 68.4%\n",
      "loss: 792.24, accuracy: 68.3%\n",
      "loss: 788.30, accuracy: 69.3%\n",
      "loss: 784.51, accuracy: 70.0%\n",
      "loss: 780.86, accuracy: 70.2%\n",
      "loss: 777.37, accuracy: 70.5%\n",
      "loss: 774.02, accuracy: 71.2%\n",
      "loss: 770.81, accuracy: 71.2%\n",
      "loss: 767.73, accuracy: 71.2%\n",
      "loss: 764.78, accuracy: 71.3%\n",
      "loss: 761.95, accuracy: 71.2%\n",
      "loss: 759.23, accuracy: 71.0%\n",
      "loss: 756.62, accuracy: 71.2%\n",
      "loss: 754.10, accuracy: 71.6%\n",
      "loss: 751.68, accuracy: 71.7%\n",
      "loss: 749.33, accuracy: 71.8%\n",
      "loss: 747.06, accuracy: 71.8%\n",
      "loss: 744.86, accuracy: 71.8%\n",
      "loss: 742.71, accuracy: 71.9%\n",
      "loss: 740.62, accuracy: 71.9%\n",
      "loss: 738.58, accuracy: 72.0%\n",
      "loss: 736.59, accuracy: 72.1%\n",
      "loss: 734.63, accuracy: 72.3%\n",
      "loss: 732.71, accuracy: 72.3%\n",
      "loss: 730.81, accuracy: 72.3%\n",
      "loss: 728.94, accuracy: 72.6%\n",
      "loss: 727.09, accuracy: 72.6%\n",
      "loss: 725.26, accuracy: 72.6%\n",
      "loss: 723.45, accuracy: 72.7%\n",
      "loss: 721.65, accuracy: 72.7%\n",
      "loss: 719.86, accuracy: 72.7%\n",
      "loss: 718.07, accuracy: 72.7%\n",
      "loss: 716.30, accuracy: 72.9%\n",
      "loss: 714.52, accuracy: 72.9%\n",
      "loss: 712.75, accuracy: 72.9%\n",
      "loss: 710.98, accuracy: 73.0%\n",
      "loss: 709.21, accuracy: 73.1%\n",
      "loss: 707.43, accuracy: 73.3%\n",
      "loss: 705.66, accuracy: 73.6%\n",
      "loss: 703.88, accuracy: 73.6%\n",
      "loss: 702.09, accuracy: 73.9%\n",
      "loss: 700.30, accuracy: 74.2%\n",
      "loss: 698.51, accuracy: 74.2%\n",
      "loss: 696.71, accuracy: 74.3%\n",
      "loss: 694.90, accuracy: 74.4%\n",
      "loss: 693.08, accuracy: 74.7%\n",
      "loss: 691.26, accuracy: 74.8%\n",
      "loss: 689.43, accuracy: 75.2%\n",
      "loss: 687.60, accuracy: 75.3%\n",
      "loss: 685.76, accuracy: 75.5%\n",
      "loss: 683.91, accuracy: 75.5%\n",
      "loss: 682.05, accuracy: 75.5%\n",
      "loss: 680.19, accuracy: 75.6%\n",
      "loss: 678.31, accuracy: 75.6%\n",
      "loss: 676.44, accuracy: 75.8%\n",
      "loss: 674.55, accuracy: 75.9%\n",
      "loss: 672.67, accuracy: 76.2%\n",
      "loss: 670.77, accuracy: 76.3%\n",
      "loss: 668.87, accuracy: 76.5%\n",
      "loss: 666.97, accuracy: 76.7%\n",
      "loss: 665.06, accuracy: 76.8%\n",
      "loss: 663.14, accuracy: 76.8%\n",
      "loss: 661.22, accuracy: 76.9%\n",
      "loss: 659.30, accuracy: 77.1%\n",
      "loss: 657.38, accuracy: 77.1%\n",
      "loss: 655.45, accuracy: 77.1%\n",
      "loss: 653.52, accuracy: 77.1%\n",
      "loss: 651.58, accuracy: 77.5%\n",
      "loss: 649.65, accuracy: 77.5%\n",
      "loss: 647.71, accuracy: 77.7%\n",
      "loss: 645.77, accuracy: 77.8%\n",
      "loss: 643.83, accuracy: 77.8%\n",
      "loss: 641.88, accuracy: 78.0%\n",
      "loss: 639.94, accuracy: 78.1%\n",
      "loss: 638.00, accuracy: 78.3%\n",
      "loss: 636.05, accuracy: 78.4%\n",
      "loss: 634.11, accuracy: 78.5%\n",
      "loss: 632.16, accuracy: 78.5%\n",
      "loss: 630.22, accuracy: 78.5%\n",
      "loss: 628.27, accuracy: 78.8%\n",
      "loss: 626.33, accuracy: 78.9%\n",
      "loss: 624.39, accuracy: 79.0%\n",
      "loss: 622.44, accuracy: 79.0%\n",
      "loss: 620.50, accuracy: 79.1%\n",
      "loss: 618.56, accuracy: 79.2%\n",
      "loss: 616.62, accuracy: 79.3%\n",
      "loss: 614.68, accuracy: 79.6%\n",
      "loss: 612.75, accuracy: 79.8%\n",
      "loss: 610.81, accuracy: 79.9%\n",
      "loss: 608.88, accuracy: 79.9%\n",
      "loss: 606.94, accuracy: 79.9%\n",
      "loss: 605.01, accuracy: 79.9%\n",
      "loss: 603.09, accuracy: 80.2%\n",
      "loss: 601.16, accuracy: 80.2%\n",
      "loss: 599.24, accuracy: 80.2%\n",
      "loss: 597.31, accuracy: 80.3%\n",
      "loss: 595.39, accuracy: 80.4%\n",
      "loss: 593.48, accuracy: 80.4%\n",
      "loss: 591.56, accuracy: 80.5%\n",
      "loss: 589.65, accuracy: 80.5%\n",
      "loss: 587.74, accuracy: 80.5%\n",
      "loss: 585.83, accuracy: 80.6%\n",
      "loss: 583.93, accuracy: 80.7%\n",
      "loss: 582.03, accuracy: 80.7%\n",
      "loss: 580.13, accuracy: 80.8%\n",
      "loss: 578.24, accuracy: 80.9%\n",
      "loss: 576.34, accuracy: 81.1%\n",
      "loss: 574.46, accuracy: 81.1%\n",
      "loss: 572.57, accuracy: 81.0%\n",
      "loss: 570.69, accuracy: 81.0%\n",
      "loss: 568.81, accuracy: 81.0%\n",
      "loss: 566.94, accuracy: 81.1%\n",
      "loss: 565.07, accuracy: 81.1%\n",
      "loss: 563.20, accuracy: 81.4%\n",
      "loss: 561.34, accuracy: 81.4%\n",
      "loss: 559.48, accuracy: 81.5%\n",
      "loss: 557.62, accuracy: 81.4%\n",
      "loss: 555.77, accuracy: 81.5%\n",
      "loss: 553.93, accuracy: 81.6%\n",
      "loss: 552.09, accuracy: 81.6%\n",
      "loss: 550.25, accuracy: 81.6%\n",
      "loss: 548.42, accuracy: 81.6%\n",
      "loss: 546.59, accuracy: 81.7%\n",
      "loss: 544.77, accuracy: 81.8%\n",
      "loss: 542.95, accuracy: 81.9%\n",
      "loss: 541.14, accuracy: 81.9%\n",
      "loss: 539.33, accuracy: 82.1%\n",
      "loss: 537.53, accuracy: 82.2%\n",
      "loss: 535.73, accuracy: 82.2%\n",
      "loss: 533.94, accuracy: 82.3%\n",
      "loss: 532.15, accuracy: 82.4%\n",
      "loss: 530.37, accuracy: 82.5%\n",
      "loss: 528.60, accuracy: 82.5%\n",
      "loss: 526.83, accuracy: 82.5%\n",
      "loss: 525.06, accuracy: 82.7%\n",
      "loss: 523.31, accuracy: 82.8%\n",
      "loss: 521.55, accuracy: 82.8%\n",
      "loss: 519.81, accuracy: 82.9%\n",
      "loss: 518.07, accuracy: 83.0%\n",
      "loss: 516.33, accuracy: 83.0%\n",
      "loss: 514.60, accuracy: 83.1%\n",
      "loss: 512.88, accuracy: 83.3%\n",
      "loss: 511.16, accuracy: 83.5%\n",
      "loss: 509.45, accuracy: 83.5%\n",
      "loss: 507.75, accuracy: 83.5%\n",
      "loss: 506.05, accuracy: 83.6%\n",
      "loss: 504.35, accuracy: 83.6%\n"
     ]
    }
   ],
   "source": [
    "mlp.train(x=x_train, y_true=y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0007846 ,  0.0098915 ,  0.00588264,  0.00386183],\n",
       "       [ 0.00133661,  0.00364618, -0.00849613,  0.00188632],\n",
       "       [-0.00809534, -0.01000073, -0.01896368, -0.014173  ],\n",
       "       ...,\n",
       "       [ 0.00687509,  0.00707646,  0.00959992,  0.00111735],\n",
       "       [ 0.00540036,  0.00473374,  0.00936287,  0.00786482],\n",
       "       [ 0.00950685,  0.01600886,  0.02002699,  0.01869586]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.param_values['w1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0349679 , 0.91431855, 0.05071355],\n",
       "       [0.0254335 , 0.93318589, 0.04138061],\n",
       "       [0.33026279, 0.51962843, 0.15010877],\n",
       "       ...,\n",
       "       [0.07500288, 0.8486338 , 0.07636331],\n",
       "       [0.66713795, 0.18517071, 0.14769134],\n",
       "       [0.02154983, 0.9386238 , 0.03982637]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = mlp.memory['a2']\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = 0\n",
    "for i in range(len(a2)):\n",
    "    equal = np.equal(np.argmax(y_train[i]), np.argmax(a2[i]))\n",
    "    correct_pred += equal.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(correct_pred/len(y_train)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(np.argmax(y_train), np.argmax(a2)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
