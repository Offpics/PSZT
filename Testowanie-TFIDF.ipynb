{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pszt import net\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train_tfidf.npy')\n",
    "y_train = np.load('y_train_no_ignore_no_norm.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć pierwsza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 20, activation: relu\n",
      "2. Layer - input_dim: 20, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=20, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=20, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 683.18, accuracy: 56.9%\n",
      "Epoch: 100, loss: 718.14, accuracy: 56.4%\n",
      "Epoch: 150, loss: 719.99, accuracy: 56.4%\n",
      "Epoch: 200, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 250, loss: 747.04, accuracy: 56.4%\n",
      "Epoch: 300, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 350, loss: 719.35, accuracy: 56.4%\n",
      "Epoch: 400, loss: 696.27, accuracy: 56.4%\n",
      "Epoch: 450, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 500, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 550, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 600, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 650, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 700, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 750, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 800, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 850, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 900, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 950, loss: 720.05, accuracy: 56.4%\n",
      "Epoch: 1000, loss: 720.05, accuracy: 56.4%\n",
      "Mean accuracy on T0: 56.14\n",
      "Mean losses on T0: 721.85\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 685.18, accuracy: 59.7%\n",
      "Epoch: 100, loss: 705.33, accuracy: 56.0%\n",
      "Epoch: 150, loss: 709.75, accuracy: 56.0%\n",
      "Epoch: 200, loss: 709.68, accuracy: 56.0%\n",
      "Epoch: 250, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 300, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 350, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 400, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 450, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 500, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 550, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 600, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 650, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 700, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 750, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 800, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 850, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 900, loss: 709.90, accuracy: 56.0%\n",
      "Epoch: 950, loss: 709.89, accuracy: 56.0%\n",
      "Epoch: 1000, loss: 709.89, accuracy: 56.0%\n",
      "Mean accuracy on T1: 55.92\n",
      "Mean losses on T1: 711.24\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 679.29, accuracy: 57.3%\n",
      "Epoch: 100, loss: 921.72, accuracy: 31.0%\n",
      "Epoch: 150, loss: 705.19, accuracy: 57.4%\n",
      "Epoch: 200, loss: 696.10, accuracy: 57.3%\n",
      "Epoch: 250, loss: 715.70, accuracy: 57.3%\n",
      "Epoch: 300, loss: 709.94, accuracy: 57.3%\n",
      "Epoch: 350, loss: 596.89, accuracy: 71.9%\n",
      "Epoch: 400, loss: 708.42, accuracy: 66.1%\n",
      "Epoch: 450, loss: 705.58, accuracy: 58.0%\n",
      "Epoch: 500, loss: 608.11, accuracy: 66.8%\n",
      "Epoch: 550, loss: 688.73, accuracy: 59.7%\n",
      "Epoch: 600, loss: 701.82, accuracy: 58.0%\n",
      "Epoch: 650, loss: 703.66, accuracy: 60.6%\n",
      "Epoch: 700, loss: 711.15, accuracy: 59.9%\n",
      "Epoch: 750, loss: 689.32, accuracy: 71.9%\n",
      "Epoch: 800, loss: 647.09, accuracy: 64.3%\n",
      "Epoch: 850, loss: 735.94, accuracy: 65.4%\n",
      "Epoch: 900, loss: 638.08, accuracy: 73.9%\n",
      "Epoch: 950, loss: 712.11, accuracy: 69.6%\n",
      "Epoch: 1000, loss: 809.14, accuracy: 67.7%\n",
      "Mean accuracy on T2: 61.20\n",
      "Mean losses on T2: 688.27\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 675.88, accuracy: 57.7%\n",
      "Epoch: 100, loss: 684.93, accuracy: 57.7%\n",
      "Epoch: 150, loss: 699.65, accuracy: 57.7%\n",
      "Epoch: 200, loss: 940.75, accuracy: 31.8%\n",
      "Epoch: 250, loss: 691.82, accuracy: 57.7%\n",
      "Epoch: 300, loss: 696.82, accuracy: 57.7%\n",
      "Epoch: 350, loss: 694.33, accuracy: 57.7%\n",
      "Epoch: 400, loss: 688.06, accuracy: 57.7%\n",
      "Epoch: 450, loss: 1145.26, accuracy: 31.8%\n",
      "Epoch: 500, loss: 1320.48, accuracy: 31.8%\n",
      "Epoch: 550, loss: 697.66, accuracy: 57.7%\n",
      "Epoch: 600, loss: 1548.37, accuracy: 57.7%\n",
      "Epoch: 650, loss: 694.73, accuracy: 57.7%\n",
      "Epoch: 700, loss: 691.56, accuracy: 57.7%\n",
      "Epoch: 750, loss: 545.03, accuracy: 72.4%\n",
      "Epoch: 800, loss: 541.45, accuracy: 72.3%\n",
      "Epoch: 850, loss: 1372.89, accuracy: 33.9%\n",
      "Epoch: 900, loss: 556.59, accuracy: 72.7%\n",
      "Epoch: 950, loss: 798.32, accuracy: 66.0%\n",
      "Epoch: 1000, loss: 680.38, accuracy: 57.7%\n",
      "Mean accuracy on T3: 58.48\n",
      "Mean losses on T3: 708.82\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 50, loss: 664.10, accuracy: 57.5%\n",
      "Epoch: 100, loss: 699.11, accuracy: 56.8%\n",
      "Epoch: 150, loss: 672.15, accuracy: 56.8%\n",
      "Epoch: 200, loss: 699.21, accuracy: 56.8%\n",
      "Epoch: 250, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 300, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 350, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 400, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 450, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 500, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 550, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 600, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 650, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 700, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 750, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 800, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 850, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 900, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 950, loss: 699.09, accuracy: 56.8%\n",
      "Epoch: 1000, loss: 699.09, accuracy: 56.8%\n",
      "Mean accuracy on T4: 56.72\n",
      "Mean losses on T4: 699.41\n",
      "\n",
      "Accuracy list on Ti sets: [56.14349540078845, 55.92312746386333, 61.203942181340345, 58.47503285151118, 56.7184210526316]\n",
      "Losses list on Ti sets: [721.8485654437203, 711.2361544465876, 688.2702984560738, 708.8150583439698, 699.414040644164]\n",
      "Mean accuracy on all T sets: 57.69\n",
      "Mean losses on all T sets: 705.92\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć druga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 20, activation: sigmoid\n",
      "2. Layer - input_dim: 20, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=20, activation=\"sigmoid\")\n",
    "\n",
    "mlp.add_layer(input_dim=20, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 738.02, accuracy: 58.1%\n",
      "Epoch: 100, loss: 719.23, accuracy: 58.1%\n",
      "Epoch: 150, loss: 717.93, accuracy: 58.1%\n",
      "Epoch: 200, loss: 734.86, accuracy: 59.9%\n",
      "Epoch: 250, loss: 736.23, accuracy: 43.8%\n",
      "Epoch: 300, loss: 729.25, accuracy: 49.0%\n",
      "Epoch: 350, loss: 713.97, accuracy: 53.7%\n",
      "Epoch: 400, loss: 695.55, accuracy: 58.1%\n",
      "Epoch: 450, loss: 678.59, accuracy: 60.1%\n",
      "Epoch: 500, loss: 666.08, accuracy: 61.2%\n",
      "Epoch: 550, loss: 658.77, accuracy: 62.7%\n",
      "Epoch: 600, loss: 655.54, accuracy: 63.5%\n",
      "Epoch: 650, loss: 654.82, accuracy: 63.9%\n",
      "Epoch: 700, loss: 655.51, accuracy: 64.4%\n",
      "Epoch: 750, loss: 657.00, accuracy: 64.7%\n",
      "Epoch: 800, loss: 658.97, accuracy: 64.5%\n",
      "Epoch: 850, loss: 661.24, accuracy: 64.4%\n",
      "Epoch: 900, loss: 663.64, accuracy: 64.5%\n",
      "Epoch: 950, loss: 665.52, accuracy: 58.5%\n",
      "Epoch: 1000, loss: 664.83, accuracy: 58.3%\n",
      "Mean accuracy on T0: 60.81\n",
      "Mean losses on T0: 698.26\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 705.98, accuracy: 56.6%\n",
      "Epoch: 100, loss: 694.25, accuracy: 56.6%\n",
      "Epoch: 150, loss: 692.25, accuracy: 56.6%\n",
      "Epoch: 200, loss: 698.14, accuracy: 64.8%\n",
      "Epoch: 250, loss: 697.40, accuracy: 51.4%\n",
      "Epoch: 300, loss: 690.19, accuracy: 53.6%\n",
      "Epoch: 350, loss: 677.35, accuracy: 57.6%\n",
      "Epoch: 400, loss: 662.33, accuracy: 60.8%\n",
      "Epoch: 450, loss: 648.70, accuracy: 62.4%\n",
      "Epoch: 500, loss: 639.03, accuracy: 63.6%\n",
      "Epoch: 550, loss: 633.75, accuracy: 64.9%\n",
      "Epoch: 600, loss: 631.66, accuracy: 65.8%\n",
      "Epoch: 650, loss: 631.48, accuracy: 66.4%\n",
      "Epoch: 700, loss: 632.40, accuracy: 67.1%\n",
      "Epoch: 750, loss: 634.01, accuracy: 67.4%\n",
      "Epoch: 800, loss: 636.17, accuracy: 67.4%\n",
      "Epoch: 850, loss: 638.86, accuracy: 67.7%\n",
      "Epoch: 900, loss: 641.85, accuracy: 67.7%\n",
      "Epoch: 950, loss: 642.38, accuracy: 67.7%\n",
      "Epoch: 1000, loss: 632.20, accuracy: 68.3%\n",
      "Mean accuracy on T1: 62.60\n",
      "Mean losses on T1: 679.74\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 708.55, accuracy: 56.4%\n",
      "Epoch: 100, loss: 697.18, accuracy: 56.4%\n",
      "Epoch: 150, loss: 693.94, accuracy: 56.4%\n",
      "Epoch: 200, loss: 696.98, accuracy: 70.8%\n",
      "Epoch: 250, loss: 690.27, accuracy: 53.2%\n",
      "Epoch: 300, loss: 674.89, accuracy: 59.4%\n",
      "Epoch: 350, loss: 653.38, accuracy: 63.3%\n",
      "Epoch: 400, loss: 630.66, accuracy: 66.0%\n",
      "Epoch: 450, loss: 610.79, accuracy: 67.5%\n",
      "Epoch: 500, loss: 596.06, accuracy: 68.6%\n",
      "Epoch: 550, loss: 586.61, accuracy: 69.9%\n",
      "Epoch: 600, loss: 581.14, accuracy: 70.7%\n",
      "Epoch: 650, loss: 578.18, accuracy: 71.0%\n",
      "Epoch: 700, loss: 576.72, accuracy: 70.7%\n",
      "Epoch: 750, loss: 576.16, accuracy: 70.7%\n",
      "Epoch: 800, loss: 576.20, accuracy: 70.8%\n",
      "Epoch: 850, loss: 576.69, accuracy: 70.8%\n",
      "Epoch: 900, loss: 577.57, accuracy: 70.8%\n",
      "Epoch: 950, loss: 578.87, accuracy: 70.6%\n",
      "Epoch: 1000, loss: 580.54, accuracy: 70.6%\n",
      "Mean accuracy on T2: 64.07\n",
      "Mean losses on T2: 671.04\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 711.74, accuracy: 58.3%\n",
      "Epoch: 100, loss: 695.27, accuracy: 58.3%\n",
      "Epoch: 150, loss: 693.29, accuracy: 58.3%\n",
      "Epoch: 200, loss: 707.80, accuracy: 63.3%\n",
      "Epoch: 250, loss: 709.17, accuracy: 48.5%\n",
      "Epoch: 300, loss: 703.48, accuracy: 50.6%\n",
      "Epoch: 350, loss: 689.92, accuracy: 54.9%\n",
      "Epoch: 400, loss: 672.66, accuracy: 59.1%\n",
      "Epoch: 450, loss: 655.92, accuracy: 60.8%\n",
      "Epoch: 500, loss: 642.80, accuracy: 65.2%\n",
      "Epoch: 550, loss: 634.41, accuracy: 65.7%\n",
      "Epoch: 600, loss: 629.96, accuracy: 66.6%\n",
      "Epoch: 650, loss: 628.11, accuracy: 67.4%\n",
      "Epoch: 700, loss: 627.83, accuracy: 67.5%\n",
      "Epoch: 750, loss: 628.61, accuracy: 67.7%\n",
      "Epoch: 800, loss: 630.08, accuracy: 67.3%\n",
      "Epoch: 850, loss: 630.80, accuracy: 67.1%\n",
      "Epoch: 900, loss: 624.79, accuracy: 67.4%\n",
      "Epoch: 950, loss: 606.26, accuracy: 69.1%\n",
      "Epoch: 1000, loss: 583.54, accuracy: 70.4%\n",
      "Mean accuracy on T3: 63.60\n",
      "Mean losses on T3: 665.84\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 50, loss: 731.54, accuracy: 54.7%\n",
      "Epoch: 100, loss: 722.14, accuracy: 54.7%\n",
      "Epoch: 150, loss: 717.77, accuracy: 54.7%\n",
      "Epoch: 200, loss: 720.38, accuracy: 64.6%\n",
      "Epoch: 250, loss: 715.20, accuracy: 52.0%\n",
      "Epoch: 300, loss: 703.19, accuracy: 53.7%\n",
      "Epoch: 350, loss: 686.09, accuracy: 57.6%\n",
      "Epoch: 400, loss: 667.95, accuracy: 60.1%\n",
      "Epoch: 450, loss: 652.21, accuracy: 61.6%\n",
      "Epoch: 500, loss: 640.99, accuracy: 63.3%\n",
      "Epoch: 550, loss: 634.43, accuracy: 64.5%\n",
      "Epoch: 600, loss: 631.27, accuracy: 65.1%\n",
      "Epoch: 650, loss: 630.17, accuracy: 65.5%\n",
      "Epoch: 700, loss: 630.23, accuracy: 66.2%\n",
      "Epoch: 750, loss: 630.97, accuracy: 66.1%\n",
      "Epoch: 800, loss: 631.99, accuracy: 66.1%\n",
      "Epoch: 850, loss: 632.32, accuracy: 66.4%\n",
      "Epoch: 900, loss: 628.48, accuracy: 66.6%\n",
      "Epoch: 950, loss: 615.39, accuracy: 68.2%\n",
      "Epoch: 1000, loss: 596.65, accuracy: 69.6%\n",
      "Mean accuracy on T4: 60.83\n",
      "Mean losses on T4: 713.59\n",
      "\n",
      "Accuracy list on Ti sets: [60.80683311432326, 62.599342969776615, 64.0695137976347, 63.603547963206324, 60.82921052631579]\n",
      "Losses list on Ti sets: [698.257035401624, 679.7357907127146, 671.0395492358175, 665.8369284117206, 713.5875664499828]\n",
      "Mean accuracy on all T sets: 62.38\n",
      "Mean losses on all T sets: 685.69\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć trzecia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 100, activation: relu\n",
      "2. Layer - input_dim: 100, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=100, activation=\"relu\")\n",
    "\n",
    "mlp.add_layer(input_dim=100, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 703.73, accuracy: 58.3%\n",
      "Epoch: 100, loss: 686.45, accuracy: 58.3%\n",
      "Epoch: 150, loss: 771.97, accuracy: 58.3%\n",
      "Epoch: 200, loss: 783.05, accuracy: 58.3%\n",
      "Epoch: 250, loss: 714.75, accuracy: 58.3%\n",
      "Epoch: 300, loss: 797.05, accuracy: 58.3%\n",
      "Epoch: 350, loss: 704.03, accuracy: 58.3%\n",
      "Epoch: 400, loss: 704.03, accuracy: 58.3%\n",
      "Epoch: 450, loss: 704.59, accuracy: 58.3%\n",
      "Epoch: 500, loss: 703.74, accuracy: 58.3%\n",
      "Epoch: 550, loss: 698.45, accuracy: 59.3%\n",
      "Epoch: 600, loss: 695.07, accuracy: 59.5%\n",
      "Epoch: 650, loss: 702.02, accuracy: 58.7%\n",
      "Epoch: 700, loss: 701.89, accuracy: 58.7%\n",
      "Epoch: 750, loss: 696.10, accuracy: 59.5%\n",
      "Epoch: 800, loss: 609.64, accuracy: 67.3%\n",
      "Epoch: 850, loss: 678.63, accuracy: 67.0%\n",
      "Epoch: 900, loss: 644.02, accuracy: 66.0%\n",
      "Epoch: 950, loss: 877.41, accuracy: 61.2%\n",
      "Epoch: 1000, loss: 751.60, accuracy: 64.4%\n",
      "Mean accuracy on T0: 59.96\n",
      "Mean losses on T0: 706.59\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 694.56, accuracy: 60.6%\n",
      "Epoch: 100, loss: 669.32, accuracy: 59.0%\n",
      "Epoch: 150, loss: 679.87, accuracy: 59.4%\n",
      "Epoch: 200, loss: 673.50, accuracy: 71.2%\n",
      "Epoch: 250, loss: 689.33, accuracy: 58.9%\n",
      "Epoch: 300, loss: 698.00, accuracy: 58.7%\n",
      "Epoch: 350, loss: 697.91, accuracy: 58.7%\n",
      "Epoch: 400, loss: 694.06, accuracy: 59.1%\n",
      "Epoch: 450, loss: 657.39, accuracy: 63.5%\n",
      "Epoch: 500, loss: 697.97, accuracy: 58.7%\n",
      "Epoch: 550, loss: 697.09, accuracy: 58.9%\n",
      "Epoch: 600, loss: 699.80, accuracy: 58.9%\n",
      "Epoch: 650, loss: 690.43, accuracy: 59.7%\n",
      "Epoch: 700, loss: 697.55, accuracy: 58.9%\n",
      "Epoch: 750, loss: 696.50, accuracy: 59.0%\n",
      "Epoch: 800, loss: 681.94, accuracy: 59.8%\n",
      "Epoch: 850, loss: 696.49, accuracy: 59.1%\n",
      "Epoch: 900, loss: 694.59, accuracy: 59.1%\n",
      "Epoch: 950, loss: 691.49, accuracy: 59.7%\n",
      "Epoch: 1000, loss: 693.17, accuracy: 59.3%\n",
      "Mean accuracy on T1: 58.75\n",
      "Mean losses on T1: 703.00\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 736.62, accuracy: 58.0%\n",
      "Epoch: 100, loss: 701.36, accuracy: 58.0%\n",
      "Epoch: 150, loss: 811.37, accuracy: 33.5%\n",
      "Epoch: 200, loss: 681.85, accuracy: 58.0%\n",
      "Epoch: 250, loss: 1060.49, accuracy: 33.4%\n",
      "Epoch: 300, loss: 666.12, accuracy: 58.0%\n",
      "Epoch: 350, loss: 583.83, accuracy: 69.9%\n",
      "Epoch: 400, loss: 597.52, accuracy: 73.3%\n",
      "Epoch: 450, loss: 726.05, accuracy: 53.2%\n",
      "Epoch: 500, loss: 877.33, accuracy: 37.7%\n",
      "Epoch: 550, loss: 1087.89, accuracy: 61.5%\n",
      "Epoch: 600, loss: 1006.96, accuracy: 62.7%\n",
      "Epoch: 650, loss: 1155.06, accuracy: 58.7%\n",
      "Epoch: 700, loss: 759.00, accuracy: 64.7%\n",
      "Epoch: 750, loss: 1458.27, accuracy: 61.4%\n",
      "Epoch: 800, loss: 1068.78, accuracy: 67.1%\n",
      "Epoch: 850, loss: 803.57, accuracy: 71.7%\n",
      "Epoch: 900, loss: 661.78, accuracy: 72.4%\n",
      "Epoch: 950, loss: 666.65, accuracy: 72.5%\n",
      "Epoch: 1000, loss: 840.71, accuracy: 67.8%\n",
      "Mean accuracy on T2: 58.29\n",
      "Mean losses on T2: 744.23\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 725.86, accuracy: 53.9%\n",
      "Epoch: 100, loss: 726.77, accuracy: 53.9%\n",
      "Epoch: 150, loss: 729.50, accuracy: 53.9%\n",
      "Epoch: 200, loss: 705.99, accuracy: 54.5%\n",
      "Epoch: 250, loss: 674.10, accuracy: 54.9%\n",
      "Epoch: 300, loss: 727.46, accuracy: 53.9%\n",
      "Epoch: 350, loss: 910.49, accuracy: 53.9%\n",
      "Epoch: 400, loss: 600.32, accuracy: 72.7%\n",
      "Epoch: 450, loss: 725.20, accuracy: 54.4%\n",
      "Epoch: 500, loss: 703.00, accuracy: 69.5%\n",
      "Epoch: 550, loss: 713.54, accuracy: 54.3%\n",
      "Epoch: 600, loss: 721.45, accuracy: 54.5%\n",
      "Epoch: 650, loss: 721.74, accuracy: 54.0%\n",
      "Epoch: 700, loss: 723.82, accuracy: 53.9%\n",
      "Epoch: 750, loss: 712.56, accuracy: 54.9%\n",
      "Epoch: 800, loss: 716.24, accuracy: 54.1%\n",
      "Epoch: 850, loss: 697.09, accuracy: 56.6%\n",
      "Epoch: 900, loss: 533.55, accuracy: 73.1%\n",
      "Epoch: 950, loss: 967.65, accuracy: 57.6%\n",
      "Epoch: 1000, loss: 648.16, accuracy: 64.5%\n",
      "Mean accuracy on T3: 56.44\n",
      "Mean losses on T3: 724.96\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 50, loss: 709.76, accuracy: 55.3%\n",
      "Epoch: 100, loss: 702.00, accuracy: 55.3%\n",
      "Epoch: 150, loss: 707.88, accuracy: 55.3%\n",
      "Epoch: 200, loss: 704.33, accuracy: 55.3%\n",
      "Epoch: 250, loss: 704.81, accuracy: 55.3%\n",
      "Epoch: 300, loss: 695.88, accuracy: 55.3%\n",
      "Epoch: 350, loss: 707.33, accuracy: 55.3%\n",
      "Epoch: 400, loss: 700.59, accuracy: 55.3%\n",
      "Epoch: 450, loss: 707.74, accuracy: 55.3%\n",
      "Epoch: 500, loss: 719.92, accuracy: 55.3%\n",
      "Epoch: 550, loss: 693.81, accuracy: 56.7%\n",
      "Epoch: 600, loss: 708.13, accuracy: 55.3%\n",
      "Epoch: 650, loss: 707.89, accuracy: 55.4%\n",
      "Epoch: 700, loss: 677.95, accuracy: 55.4%\n",
      "Epoch: 750, loss: 682.36, accuracy: 56.4%\n",
      "Epoch: 800, loss: 679.21, accuracy: 63.7%\n",
      "Epoch: 850, loss: 694.27, accuracy: 56.2%\n",
      "Epoch: 900, loss: 703.26, accuracy: 56.2%\n",
      "Epoch: 950, loss: 828.47, accuracy: 36.7%\n",
      "Epoch: 1000, loss: 548.53, accuracy: 75.8%\n",
      "Mean accuracy on T4: 55.68\n",
      "Mean losses on T4: 710.25\n",
      "\n",
      "Accuracy list on Ti sets: [59.960972404730626, 58.745466491458615, 58.28515111695138, 56.43574244415243, 55.678684210526335]\n",
      "Losses list on Ti sets: [706.5918199038219, 703.0039620710409, 744.2348994506365, 724.9624341856693, 710.2533345683174]\n",
      "Mean accuracy on all T sets: 57.82\n",
      "Mean losses on all T sets: 717.81\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć czwarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 100, activation: sigmoid\n",
      "2. Layer - input_dim: 100, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp = net.MLP()\n",
    "\n",
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=100, activation=\"sigmoid\")\n",
    "\n",
    "mlp.add_layer(input_dim=100, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: T0,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 846.89, accuracy: 33.6%\n",
      "Epoch: 100, loss: 754.68, accuracy: 33.6%\n",
      "Epoch: 150, loss: 725.81, accuracy: 60.1%\n",
      "Epoch: 200, loss: 713.76, accuracy: 55.7%\n",
      "Epoch: 250, loss: 707.35, accuracy: 56.4%\n",
      "Epoch: 300, loss: 703.03, accuracy: 69.1%\n",
      "Epoch: 350, loss: 697.86, accuracy: 68.9%\n",
      "Epoch: 400, loss: 689.54, accuracy: 65.3%\n",
      "Epoch: 450, loss: 677.06, accuracy: 62.9%\n",
      "Epoch: 500, loss: 660.63, accuracy: 64.8%\n",
      "Epoch: 550, loss: 641.72, accuracy: 66.6%\n",
      "Epoch: 600, loss: 622.60, accuracy: 67.4%\n",
      "Epoch: 650, loss: 605.65, accuracy: 68.1%\n",
      "Epoch: 700, loss: 592.61, accuracy: 68.5%\n",
      "Epoch: 750, loss: 583.95, accuracy: 68.7%\n",
      "Epoch: 800, loss: 578.83, accuracy: 69.3%\n",
      "Epoch: 850, loss: 575.88, accuracy: 69.6%\n",
      "Epoch: 900, loss: 574.09, accuracy: 69.4%\n",
      "Epoch: 950, loss: 572.95, accuracy: 69.6%\n",
      "Epoch: 1000, loss: 572.22, accuracy: 69.8%\n",
      "Mean accuracy on T0: 60.27\n",
      "Mean losses on T0: 761.75\n",
      "\n",
      "Current fold: T1,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 886.09, accuracy: 30.9%\n",
      "Epoch: 100, loss: 771.53, accuracy: 30.9%\n",
      "Epoch: 150, loss: 734.61, accuracy: 44.9%\n",
      "Epoch: 200, loss: 719.03, accuracy: 58.2%\n",
      "Epoch: 250, loss: 712.12, accuracy: 59.8%\n",
      "Epoch: 300, loss: 709.81, accuracy: 69.3%\n",
      "Epoch: 350, loss: 708.47, accuracy: 66.4%\n",
      "Epoch: 400, loss: 705.02, accuracy: 57.7%\n",
      "Epoch: 450, loss: 697.98, accuracy: 55.7%\n",
      "Epoch: 500, loss: 686.82, accuracy: 57.3%\n",
      "Epoch: 550, loss: 672.02, accuracy: 59.1%\n",
      "Epoch: 600, loss: 655.09, accuracy: 61.8%\n",
      "Epoch: 650, loss: 638.23, accuracy: 63.9%\n",
      "Epoch: 700, loss: 623.90, accuracy: 65.2%\n",
      "Epoch: 750, loss: 613.87, accuracy: 65.8%\n",
      "Epoch: 800, loss: 608.31, accuracy: 66.8%\n",
      "Epoch: 850, loss: 605.98, accuracy: 67.4%\n",
      "Epoch: 900, loss: 605.46, accuracy: 67.0%\n",
      "Epoch: 950, loss: 605.93, accuracy: 67.1%\n",
      "Epoch: 1000, loss: 607.06, accuracy: 66.8%\n",
      "Mean accuracy on T1: 60.14\n",
      "Mean losses on T1: 750.82\n",
      "\n",
      "Current fold: T2,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 943.71, accuracy: 57.6%\n",
      "Epoch: 100, loss: 777.69, accuracy: 57.6%\n",
      "Epoch: 150, loss: 737.39, accuracy: 57.6%\n",
      "Epoch: 200, loss: 722.76, accuracy: 57.6%\n",
      "Epoch: 250, loss: 716.35, accuracy: 57.6%\n",
      "Epoch: 300, loss: 714.09, accuracy: 57.6%\n",
      "Epoch: 350, loss: 713.72, accuracy: 57.6%\n",
      "Epoch: 400, loss: 712.92, accuracy: 57.6%\n",
      "Epoch: 450, loss: 709.85, accuracy: 57.7%\n",
      "Epoch: 500, loss: 702.81, accuracy: 58.2%\n",
      "Epoch: 550, loss: 691.16, accuracy: 59.8%\n",
      "Epoch: 600, loss: 676.05, accuracy: 61.5%\n",
      "Epoch: 650, loss: 660.33, accuracy: 62.9%\n",
      "Epoch: 700, loss: 647.60, accuracy: 64.7%\n",
      "Epoch: 750, loss: 640.35, accuracy: 66.4%\n",
      "Epoch: 800, loss: 638.58, accuracy: 67.4%\n",
      "Epoch: 850, loss: 640.27, accuracy: 67.9%\n",
      "Epoch: 900, loss: 643.43, accuracy: 68.2%\n",
      "Epoch: 950, loss: 647.14, accuracy: 68.2%\n",
      "Epoch: 1000, loss: 651.17, accuracy: 68.3%\n",
      "Mean accuracy on T2: 59.19\n",
      "Mean losses on T2: 772.55\n",
      "\n",
      "Current fold: T3,\n",
      "Len of x_train: 3043,\n",
      "Len of x_test: 761.\n",
      "Epoch: 50, loss: 883.26, accuracy: 31.1%\n",
      "Epoch: 100, loss: 761.58, accuracy: 31.1%\n",
      "Epoch: 150, loss: 721.02, accuracy: 39.7%\n",
      "Epoch: 200, loss: 704.16, accuracy: 59.8%\n",
      "Epoch: 250, loss: 697.15, accuracy: 62.2%\n",
      "Epoch: 300, loss: 695.62, accuracy: 71.7%\n",
      "Epoch: 350, loss: 695.38, accuracy: 65.7%\n",
      "Epoch: 400, loss: 693.01, accuracy: 59.1%\n",
      "Epoch: 450, loss: 686.88, accuracy: 58.2%\n",
      "Epoch: 500, loss: 676.30, accuracy: 59.5%\n",
      "Epoch: 550, loss: 661.83, accuracy: 62.5%\n",
      "Epoch: 600, loss: 645.14, accuracy: 64.3%\n",
      "Epoch: 650, loss: 628.72, accuracy: 65.6%\n",
      "Epoch: 700, loss: 615.26, accuracy: 67.5%\n",
      "Epoch: 750, loss: 606.62, accuracy: 68.1%\n",
      "Epoch: 800, loss: 602.91, accuracy: 68.2%\n",
      "Epoch: 850, loss: 602.68, accuracy: 68.2%\n",
      "Epoch: 900, loss: 604.22, accuracy: 68.5%\n",
      "Epoch: 950, loss: 606.44, accuracy: 68.2%\n",
      "Epoch: 1000, loss: 608.94, accuracy: 68.6%\n",
      "Mean accuracy on T3: 61.59\n",
      "Mean losses on T3: 732.61\n",
      "\n",
      "Current fold: T4,\n",
      "Len of x_train: 3044,\n",
      "Len of x_test: 760.\n",
      "Epoch: 50, loss: 837.90, accuracy: 34.7%\n",
      "Epoch: 100, loss: 752.51, accuracy: 34.7%\n",
      "Epoch: 150, loss: 725.97, accuracy: 58.6%\n",
      "Epoch: 200, loss: 714.90, accuracy: 54.3%\n",
      "Epoch: 250, loss: 708.23, accuracy: 56.3%\n",
      "Epoch: 300, loss: 702.71, accuracy: 68.7%\n",
      "Epoch: 350, loss: 696.20, accuracy: 69.7%\n",
      "Epoch: 400, loss: 687.04, accuracy: 63.3%\n",
      "Epoch: 450, loss: 674.64, accuracy: 60.9%\n",
      "Epoch: 500, loss: 659.28, accuracy: 61.8%\n",
      "Epoch: 550, loss: 642.10, accuracy: 64.1%\n",
      "Epoch: 600, loss: 624.85, accuracy: 65.7%\n",
      "Epoch: 650, loss: 609.55, accuracy: 67.1%\n",
      "Epoch: 700, loss: 597.89, accuracy: 68.2%\n",
      "Epoch: 750, loss: 590.49, accuracy: 68.3%\n",
      "Epoch: 800, loss: 586.61, accuracy: 68.6%\n",
      "Epoch: 850, loss: 584.90, accuracy: 68.8%\n",
      "Epoch: 900, loss: 584.36, accuracy: 68.9%\n",
      "Epoch: 950, loss: 584.48, accuracy: 69.1%\n",
      "Epoch: 1000, loss: 585.08, accuracy: 69.2%\n",
      "Mean accuracy on T4: 59.78\n",
      "Mean losses on T4: 763.85\n",
      "\n",
      "Accuracy list on Ti sets: [60.27463863337714, 60.13837056504599, 59.18869908015768, 61.59132720105124, 59.77802631578948]\n",
      "Losses list on Ti sets: [761.7538340195222, 750.8212969607231, 772.5500470093633, 732.6111107726273, 763.8468158855679]\n",
      "Mean accuracy on all T sets: 60.19\n",
      "Mean losses on all T sets: 756.32\n"
     ]
    }
   ],
   "source": [
    "mlp.k_fold_validation(x_train, y_train, k=5, epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
