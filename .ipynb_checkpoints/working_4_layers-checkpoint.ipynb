{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pszt import net\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = net.MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (1000, 8257), y_train.shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "print(f'x_train.shape: {x_train.shape}, y_train.shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 1000, activation: relu\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=1000, activation=\"relu\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 1000, activation: relu\n",
      "2. Layer - input_dim: 1000, output_dim: 20, activation: relu\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=1000, output_dim=20, activation=\"relu\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 1000, activation: relu\n",
      "2. Layer - input_dim: 1000, output_dim: 20, activation: relu\n",
      "3. Layer - input_dim: 20, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=20, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.init_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.param_values['w2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.forward(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z = np.dot(mlp.memory['a1'], mlp.param_values['w2']) + mlp.param_values['b2']\n",
    "#a = 1/(1+np.exp(-z))\n",
    "#print(z)\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1094.09, accuracy: 34.0%\n",
      "loss: 975.51, accuracy: 55.5%\n",
      "loss: 973.68, accuracy: 33.6%\n",
      "loss: 944.60, accuracy: 55.5%\n",
      "loss: 939.52, accuracy: 55.5%\n",
      "loss: 936.44, accuracy: 55.5%\n",
      "loss: 934.44, accuracy: 55.5%\n",
      "loss: 932.59, accuracy: 55.5%\n",
      "loss: 930.75, accuracy: 55.5%\n",
      "loss: 928.84, accuracy: 55.5%\n",
      "loss: 926.76, accuracy: 55.5%\n",
      "loss: 924.47, accuracy: 55.5%\n",
      "loss: 921.91, accuracy: 55.5%\n",
      "loss: 919.00, accuracy: 55.5%\n",
      "loss: 915.68, accuracy: 55.5%\n",
      "loss: 911.87, accuracy: 55.5%\n",
      "loss: 907.49, accuracy: 55.5%\n",
      "loss: 902.44, accuracy: 55.6%\n",
      "loss: 896.62, accuracy: 55.8%\n",
      "loss: 889.94, accuracy: 56.2%\n",
      "loss: 882.30, accuracy: 56.4%\n",
      "loss: 873.63, accuracy: 57.7%\n",
      "loss: 863.87, accuracy: 58.8%\n",
      "loss: 853.04, accuracy: 60.1%\n",
      "loss: 841.29, accuracy: 62.3%\n",
      "loss: 828.96, accuracy: 63.3%\n",
      "loss: 816.98, accuracy: 65.8%\n",
      "loss: 808.25, accuracy: 65.8%\n",
      "loss: 817.61, accuracy: 69.1%\n",
      "loss: 898.23, accuracy: 62.6%\n",
      "loss: 1129.18, accuracy: 34.0%\n",
      "loss: 788.73, accuracy: 68.9%\n",
      "loss: 779.53, accuracy: 69.3%\n",
      "loss: 772.80, accuracy: 70.5%\n",
      "loss: 768.48, accuracy: 70.1%\n",
      "loss: 768.99, accuracy: 71.1%\n",
      "loss: 776.98, accuracy: 70.3%\n",
      "loss: 808.26, accuracy: 69.9%\n",
      "loss: 847.04, accuracy: 68.7%\n",
      "loss: 936.96, accuracy: 54.2%\n",
      "loss: 818.45, accuracy: 70.3%\n",
      "loss: 840.88, accuracy: 67.0%\n",
      "loss: 791.90, accuracy: 70.7%\n",
      "loss: 799.69, accuracy: 70.4%\n",
      "loss: 776.23, accuracy: 71.6%\n",
      "loss: 782.92, accuracy: 70.8%\n",
      "loss: 767.37, accuracy: 72.2%\n",
      "loss: 774.73, accuracy: 71.2%\n",
      "loss: 762.78, accuracy: 72.3%\n",
      "loss: 773.75, accuracy: 70.8%\n",
      "loss: 762.36, accuracy: 73.0%\n",
      "loss: 777.61, accuracy: 70.1%\n",
      "loss: 762.93, accuracy: 73.2%\n",
      "loss: 781.00, accuracy: 69.8%\n",
      "loss: 763.14, accuracy: 73.3%\n",
      "loss: 782.29, accuracy: 69.5%\n",
      "loss: 758.68, accuracy: 73.3%\n",
      "loss: 775.64, accuracy: 69.7%\n",
      "loss: 751.08, accuracy: 73.7%\n",
      "loss: 767.27, accuracy: 70.3%\n",
      "loss: 745.56, accuracy: 74.2%\n",
      "loss: 765.47, accuracy: 70.5%\n",
      "loss: 744.65, accuracy: 74.2%\n",
      "loss: 770.08, accuracy: 70.2%\n",
      "loss: 745.56, accuracy: 74.3%\n",
      "loss: 771.93, accuracy: 70.0%\n",
      "loss: 739.08, accuracy: 74.5%\n",
      "loss: 760.69, accuracy: 70.9%\n",
      "loss: 730.84, accuracy: 74.9%\n",
      "loss: 754.67, accuracy: 71.3%\n",
      "loss: 729.41, accuracy: 74.8%\n",
      "loss: 762.22, accuracy: 70.6%\n",
      "loss: 733.78, accuracy: 74.4%\n",
      "loss: 767.55, accuracy: 70.3%\n",
      "loss: 729.37, accuracy: 75.0%\n",
      "loss: 754.95, accuracy: 70.8%\n",
      "loss: 716.60, accuracy: 75.2%\n",
      "loss: 738.59, accuracy: 71.9%\n",
      "loss: 710.20, accuracy: 75.0%\n",
      "loss: 743.15, accuracy: 71.8%\n",
      "loss: 719.12, accuracy: 75.1%\n",
      "loss: 761.84, accuracy: 70.4%\n",
      "loss: 718.41, accuracy: 75.6%\n",
      "loss: 746.26, accuracy: 71.6%\n",
      "loss: 699.64, accuracy: 76.0%\n",
      "loss: 719.69, accuracy: 72.7%\n",
      "loss: 691.34, accuracy: 76.0%\n",
      "loss: 727.20, accuracy: 72.5%\n",
      "loss: 703.51, accuracy: 74.9%\n",
      "loss: 753.01, accuracy: 70.7%\n",
      "loss: 701.12, accuracy: 75.9%\n",
      "loss: 729.34, accuracy: 72.4%\n",
      "loss: 680.27, accuracy: 76.8%\n",
      "loss: 700.41, accuracy: 73.8%\n",
      "loss: 669.48, accuracy: 77.2%\n",
      "loss: 706.05, accuracy: 73.4%\n",
      "loss: 683.28, accuracy: 76.2%\n",
      "loss: 740.14, accuracy: 71.4%\n",
      "loss: 690.47, accuracy: 76.1%\n",
      "loss: 726.11, accuracy: 72.5%\n",
      "loss: 666.25, accuracy: 77.5%\n",
      "loss: 682.72, accuracy: 74.6%\n",
      "loss: 643.42, accuracy: 78.3%\n",
      "loss: 665.71, accuracy: 75.4%\n",
      "loss: 642.63, accuracy: 78.4%\n",
      "loss: 692.15, accuracy: 74.2%\n",
      "loss: 672.85, accuracy: 76.6%\n",
      "loss: 745.26, accuracy: 70.3%\n",
      "loss: 675.96, accuracy: 76.9%\n",
      "loss: 704.27, accuracy: 73.7%\n",
      "loss: 633.60, accuracy: 79.1%\n",
      "loss: 635.30, accuracy: 77.8%\n",
      "loss: 592.15, accuracy: 80.4%\n",
      "loss: 600.26, accuracy: 80.0%\n",
      "loss: 580.62, accuracy: 80.7%\n",
      "loss: 620.44, accuracy: 78.3%\n",
      "loss: 629.10, accuracy: 78.4%\n",
      "loss: 741.45, accuracy: 70.3%\n",
      "loss: 724.19, accuracy: 75.6%\n",
      "loss: 835.44, accuracy: 64.0%\n",
      "loss: 644.84, accuracy: 78.4%\n",
      "loss: 623.58, accuracy: 78.8%\n",
      "loss: 554.88, accuracy: 80.8%\n",
      "loss: 533.13, accuracy: 82.6%\n",
      "loss: 508.26, accuracy: 82.6%\n",
      "loss: 506.53, accuracy: 83.1%\n",
      "loss: 502.23, accuracy: 82.7%\n",
      "loss: 539.15, accuracy: 80.8%\n",
      "loss: 567.68, accuracy: 80.5%\n",
      "loss: 712.66, accuracy: 72.1%\n",
      "loss: 783.05, accuracy: 74.0%\n",
      "loss: 1031.21, accuracy: 52.3%\n",
      "loss: 589.57, accuracy: 78.7%\n",
      "loss: 562.75, accuracy: 81.2%\n",
      "loss: 509.86, accuracy: 81.8%\n",
      "loss: 489.41, accuracy: 83.8%\n",
      "loss: 471.26, accuracy: 83.5%\n",
      "loss: 468.72, accuracy: 84.6%\n",
      "loss: 466.44, accuracy: 83.4%\n",
      "loss: 496.59, accuracy: 82.9%\n",
      "loss: 518.23, accuracy: 82.0%\n",
      "loss: 627.13, accuracy: 77.4%\n",
      "loss: 697.72, accuracy: 76.0%\n",
      "loss: 937.83, accuracy: 57.8%\n",
      "loss: 674.26, accuracy: 77.8%\n",
      "loss: 700.17, accuracy: 74.7%\n",
      "loss: 580.54, accuracy: 79.2%\n",
      "loss: 567.11, accuracy: 81.3%\n",
      "loss: 498.97, accuracy: 81.7%\n",
      "loss: 474.29, accuracy: 84.5%\n",
      "loss: 444.27, accuracy: 83.9%\n",
      "loss: 432.07, accuracy: 86.0%\n",
      "loss: 420.54, accuracy: 85.2%\n",
      "loss: 421.36, accuracy: 85.7%\n",
      "loss: 419.25, accuracy: 85.1%\n",
      "loss: 442.94, accuracy: 84.9%\n",
      "loss: 459.13, accuracy: 83.3%\n",
      "loss: 548.22, accuracy: 80.5%\n",
      "loss: 575.13, accuracy: 81.4%\n",
      "loss: 774.68, accuracy: 66.7%\n",
      "loss: 829.48, accuracy: 71.6%\n",
      "loss: 1145.43, accuracy: 51.4%\n",
      "loss: 718.62, accuracy: 77.4%\n",
      "loss: 739.27, accuracy: 74.3%\n",
      "loss: 562.25, accuracy: 79.6%\n",
      "loss: 522.60, accuracy: 83.0%\n",
      "loss: 460.08, accuracy: 82.3%\n",
      "loss: 435.14, accuracy: 86.0%\n",
      "loss: 413.16, accuracy: 85.2%\n",
      "loss: 400.37, accuracy: 86.4%\n",
      "loss: 389.82, accuracy: 86.2%\n",
      "loss: 384.92, accuracy: 86.4%\n",
      "loss: 382.44, accuracy: 86.0%\n",
      "loss: 393.79, accuracy: 86.2%\n",
      "loss: 404.60, accuracy: 85.4%\n",
      "loss: 470.55, accuracy: 84.4%\n",
      "loss: 509.01, accuracy: 82.9%\n",
      "loss: 717.25, accuracy: 71.7%\n",
      "loss: 779.26, accuracy: 75.0%\n",
      "loss: 1082.59, accuracy: 52.6%\n",
      "loss: 811.59, accuracy: 74.6%\n",
      "loss: 925.73, accuracy: 65.2%\n",
      "loss: 651.75, accuracy: 79.7%\n",
      "loss: 581.24, accuracy: 81.5%\n",
      "loss: 467.70, accuracy: 81.9%\n",
      "loss: 439.55, accuracy: 85.9%\n",
      "loss: 403.21, accuracy: 84.6%\n",
      "loss: 385.82, accuracy: 86.7%\n",
      "loss: 372.78, accuracy: 86.5%\n",
      "loss: 365.12, accuracy: 86.9%\n",
      "loss: 358.75, accuracy: 86.7%\n",
      "loss: 359.15, accuracy: 86.6%\n",
      "loss: 359.91, accuracy: 86.5%\n",
      "loss: 379.05, accuracy: 86.3%\n",
      "loss: 391.49, accuracy: 86.0%\n",
      "loss: 450.83, accuracy: 84.6%\n",
      "loss: 466.14, accuracy: 84.2%\n",
      "loss: 554.06, accuracy: 80.5%\n",
      "loss: 514.21, accuracy: 82.9%\n",
      "loss: 547.09, accuracy: 80.4%\n",
      "loss: 500.30, accuracy: 82.3%\n",
      "loss: 519.56, accuracy: 82.6%\n",
      "loss: 446.38, accuracy: 83.4%\n",
      "loss: 417.96, accuracy: 86.0%\n",
      "loss: 360.80, accuracy: 86.6%\n",
      "loss: 335.72, accuracy: 87.0%\n",
      "loss: 317.94, accuracy: 87.8%\n",
      "loss: 309.31, accuracy: 87.4%\n",
      "loss: 301.44, accuracy: 88.1%\n",
      "loss: 298.90, accuracy: 87.5%\n",
      "loss: 296.31, accuracy: 88.0%\n",
      "loss: 302.69, accuracy: 87.2%\n",
      "loss: 307.72, accuracy: 87.9%\n",
      "loss: 335.47, accuracy: 86.6%\n",
      "loss: 355.58, accuracy: 86.9%\n",
      "loss: 447.62, accuracy: 85.3%\n",
      "loss: 440.81, accuracy: 84.8%\n",
      "loss: 566.55, accuracy: 79.3%\n",
      "loss: 621.26, accuracy: 81.8%\n",
      "loss: 975.78, accuracy: 63.4%\n",
      "loss: 1538.01, accuracy: 68.0%\n",
      "loss: 1801.87, accuracy: 34.1%\n",
      "loss: 661.86, accuracy: 78.5%\n",
      "loss: 484.16, accuracy: 81.3%\n",
      "loss: 406.30, accuracy: 83.6%\n",
      "loss: 380.54, accuracy: 87.0%\n",
      "loss: 366.63, accuracy: 86.0%\n",
      "loss: 366.23, accuracy: 87.1%\n",
      "loss: 362.25, accuracy: 86.2%\n",
      "loss: 387.80, accuracy: 86.5%\n",
      "loss: 397.19, accuracy: 85.1%\n",
      "loss: 477.51, accuracy: 84.5%\n",
      "loss: 505.26, accuracy: 82.7%\n",
      "loss: 671.46, accuracy: 73.7%\n",
      "loss: 766.69, accuracy: 77.6%\n",
      "loss: 998.43, accuracy: 58.0%\n",
      "loss: 902.23, accuracy: 76.3%\n",
      "loss: 849.61, accuracy: 69.2%\n",
      "loss: 533.79, accuracy: 81.6%\n",
      "loss: 467.06, accuracy: 86.6%\n",
      "loss: 401.37, accuracy: 83.5%\n",
      "loss: 375.92, accuracy: 88.0%\n",
      "loss: 349.29, accuracy: 86.3%\n",
      "loss: 334.18, accuracy: 88.2%\n",
      "loss: 323.49, accuracy: 87.5%\n",
      "loss: 318.58, accuracy: 88.0%\n",
      "loss: 315.14, accuracy: 87.8%\n",
      "loss: 325.49, accuracy: 87.8%\n",
      "loss: 333.78, accuracy: 86.8%\n",
      "loss: 375.38, accuracy: 86.8%\n",
      "loss: 383.97, accuracy: 85.7%\n",
      "loss: 434.50, accuracy: 85.9%\n",
      "loss: 408.27, accuracy: 84.7%\n",
      "loss: 419.45, accuracy: 86.2%\n",
      "loss: 378.84, accuracy: 85.8%\n",
      "loss: 361.87, accuracy: 87.0%\n",
      "loss: 323.36, accuracy: 87.3%\n",
      "loss: 298.39, accuracy: 88.0%\n",
      "loss: 281.19, accuracy: 88.5%\n",
      "loss: 270.16, accuracy: 88.5%\n",
      "loss: 262.69, accuracy: 88.7%\n",
      "loss: 258.75, accuracy: 88.6%\n",
      "loss: 255.46, accuracy: 88.7%\n",
      "loss: 257.43, accuracy: 88.4%\n",
      "loss: 259.32, accuracy: 88.6%\n",
      "loss: 274.41, accuracy: 88.6%\n",
      "loss: 287.77, accuracy: 87.9%\n",
      "loss: 341.85, accuracy: 87.4%\n",
      "loss: 377.70, accuracy: 86.4%\n",
      "loss: 560.23, accuracy: 78.7%\n",
      "loss: 761.25, accuracy: 80.9%\n",
      "loss: 1457.18, accuracy: 42.2%\n",
      "loss: 1930.57, accuracy: 62.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2105.96, accuracy: 34.0%\n",
      "loss: 854.88, accuracy: 72.5%\n",
      "loss: 730.71, accuracy: 73.8%\n",
      "loss: 651.39, accuracy: 76.1%\n",
      "loss: 603.48, accuracy: 76.2%\n",
      "loss: 571.18, accuracy: 78.4%\n",
      "loss: 527.53, accuracy: 79.3%\n",
      "loss: 462.15, accuracy: 83.2%\n",
      "loss: 423.88, accuracy: 84.7%\n",
      "loss: 396.25, accuracy: 85.8%\n",
      "loss: 370.86, accuracy: 86.6%\n",
      "loss: 352.22, accuracy: 87.1%\n",
      "loss: 338.43, accuracy: 87.4%\n",
      "loss: 327.08, accuracy: 87.9%\n",
      "loss: 317.58, accuracy: 87.9%\n",
      "loss: 311.05, accuracy: 88.0%\n",
      "loss: 313.45, accuracy: 87.9%\n",
      "loss: 323.02, accuracy: 87.8%\n",
      "loss: 388.99, accuracy: 86.4%\n",
      "loss: 471.99, accuracy: 83.5%\n",
      "loss: 845.59, accuracy: 63.9%\n",
      "loss: 1153.58, accuracy: 75.5%\n",
      "loss: 1087.95, accuracy: 42.3%\n",
      "loss: 544.69, accuracy: 81.3%\n",
      "loss: 482.28, accuracy: 87.1%\n",
      "loss: 395.43, accuracy: 84.0%\n",
      "loss: 363.07, accuracy: 88.1%\n",
      "loss: 336.29, accuracy: 86.7%\n",
      "loss: 321.64, accuracy: 88.5%\n",
      "loss: 308.34, accuracy: 88.2%\n",
      "loss: 300.30, accuracy: 88.6%\n",
      "loss: 293.45, accuracy: 88.3%\n",
      "loss: 294.23, accuracy: 88.5%\n",
      "loss: 294.38, accuracy: 87.9%\n",
      "loss: 318.28, accuracy: 87.8%\n",
      "loss: 329.34, accuracy: 87.1%\n",
      "loss: 389.81, accuracy: 86.5%\n",
      "loss: 380.06, accuracy: 85.6%\n",
      "loss: 398.93, accuracy: 86.4%\n",
      "loss: 353.00, accuracy: 86.4%\n",
      "loss: 326.93, accuracy: 87.8%\n",
      "loss: 292.04, accuracy: 87.9%\n",
      "loss: 270.14, accuracy: 88.4%\n",
      "loss: 253.62, accuracy: 88.8%\n",
      "loss: 243.26, accuracy: 89.6%\n",
      "loss: 235.76, accuracy: 88.8%\n",
      "loss: 231.29, accuracy: 92.8%\n",
      "loss: 227.21, accuracy: 89.0%\n",
      "loss: 226.91, accuracy: 94.1%\n",
      "loss: 226.14, accuracy: 88.5%\n",
      "loss: 234.79, accuracy: 93.6%\n",
      "loss: 239.87, accuracy: 88.5%\n",
      "loss: 269.71, accuracy: 90.3%\n",
      "loss: 280.47, accuracy: 87.7%\n",
      "loss: 341.16, accuracy: 86.5%\n",
      "loss: 359.00, accuracy: 86.4%\n",
      "loss: 443.75, accuracy: 80.5%\n",
      "loss: 564.39, accuracy: 83.7%\n",
      "loss: 811.62, accuracy: 59.6%\n",
      "loss: 1769.76, accuracy: 67.7%\n",
      "loss: 2286.42, accuracy: 34.6%\n",
      "loss: 885.54, accuracy: 67.0%\n",
      "loss: 737.92, accuracy: 73.5%\n",
      "loss: 636.44, accuracy: 77.4%\n",
      "loss: 569.17, accuracy: 77.1%\n",
      "loss: 485.75, accuracy: 81.2%\n",
      "loss: 403.81, accuracy: 83.8%\n",
      "loss: 355.41, accuracy: 86.8%\n",
      "loss: 324.55, accuracy: 87.3%\n",
      "loss: 303.96, accuracy: 88.0%\n",
      "loss: 289.61, accuracy: 88.3%\n",
      "loss: 278.63, accuracy: 88.2%\n",
      "loss: 269.40, accuracy: 88.8%\n",
      "loss: 262.12, accuracy: 90.2%\n",
      "loss: 256.55, accuracy: 88.9%\n",
      "loss: 255.87, accuracy: 92.2%\n",
      "loss: 256.71, accuracy: 88.3%\n",
      "loss: 273.69, accuracy: 91.9%\n",
      "loss: 284.07, accuracy: 87.5%\n",
      "loss: 325.21, accuracy: 89.7%\n",
      "loss: 354.15, accuracy: 86.4%\n",
      "loss: 414.84, accuracy: 84.1%\n",
      "loss: 472.04, accuracy: 84.6%\n",
      "loss: 527.81, accuracy: 75.5%\n",
      "loss: 560.57, accuracy: 83.6%\n",
      "loss: 502.48, accuracy: 78.3%\n",
      "loss: 431.18, accuracy: 85.3%\n",
      "loss: 320.77, accuracy: 91.7%\n",
      "loss: 251.55, accuracy: 87.9%\n",
      "loss: 219.19, accuracy: 95.8%\n",
      "loss: 206.30, accuracy: 93.5%\n",
      "loss: 197.58, accuracy: 95.9%\n",
      "loss: 190.46, accuracy: 96.3%\n",
      "loss: 184.23, accuracy: 96.7%\n",
      "loss: 178.67, accuracy: 96.7%\n",
      "loss: 173.54, accuracy: 97.1%\n",
      "loss: 168.71, accuracy: 97.2%\n",
      "loss: 164.14, accuracy: 97.3%\n",
      "loss: 159.79, accuracy: 97.4%\n",
      "loss: 155.71, accuracy: 97.6%\n",
      "loss: 151.88, accuracy: 97.6%\n",
      "loss: 148.35, accuracy: 97.7%\n",
      "loss: 145.07, accuracy: 97.8%\n",
      "loss: 142.36, accuracy: 97.9%\n",
      "loss: 139.58, accuracy: 97.9%\n",
      "loss: 137.54, accuracy: 97.9%\n",
      "loss: 134.47, accuracy: 97.9%\n",
      "loss: 132.56, accuracy: 97.9%\n",
      "loss: 128.76, accuracy: 97.9%\n",
      "loss: 126.92, accuracy: 97.9%\n",
      "loss: 122.72, accuracy: 98.1%\n",
      "loss: 120.44, accuracy: 98.0%\n",
      "loss: 116.17, accuracy: 98.1%\n",
      "loss: 113.47, accuracy: 98.1%\n",
      "loss: 109.75, accuracy: 98.4%\n",
      "loss: 107.24, accuracy: 98.3%\n",
      "loss: 104.01, accuracy: 98.5%\n",
      "loss: 101.64, accuracy: 98.4%\n",
      "loss: 98.73, accuracy: 98.5%\n",
      "loss: 96.65, accuracy: 98.6%\n",
      "loss: 93.79, accuracy: 98.5%\n",
      "loss: 91.72, accuracy: 98.7%\n",
      "loss: 89.35, accuracy: 98.6%\n",
      "loss: 87.54, accuracy: 98.7%\n",
      "loss: 85.46, accuracy: 98.6%\n",
      "loss: 83.83, accuracy: 98.8%\n",
      "loss: 82.00, accuracy: 98.7%\n"
     ]
    }
   ],
   "source": [
    "mlp.train(x_train, y_train, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.memory['a2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(100):\n",
    "#    mlp.train(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
