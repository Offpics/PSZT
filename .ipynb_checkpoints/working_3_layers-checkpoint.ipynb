{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pszt import net\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = net.MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (1000, 8257), y_train.shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "print(f'x_train.shape: {x_train.shape}, y_train.shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 50, activation: relu\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=x_train.shape[1], output_dim=50, activation=\"relu\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Layer - input_dim: 8257, output_dim: 50, activation: relu\n",
      "2. Layer - input_dim: 50, output_dim: 3, activation: softmax\n"
     ]
    }
   ],
   "source": [
    "mlp.add_layer(input_dim=50, output_dim=3, activation=\"softmax\")\n",
    "mlp.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.init_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1102.35, accuracy: 10.5%\n",
      "loss: 995.74, accuracy: 55.5%\n",
      "loss: 953.83, accuracy: 55.5%\n",
      "loss: 934.01, accuracy: 55.5%\n",
      "loss: 922.60, accuracy: 55.5%\n",
      "loss: 912.85, accuracy: 55.5%\n",
      "loss: 901.61, accuracy: 55.5%\n",
      "loss: 887.31, accuracy: 55.5%\n",
      "loss: 869.33, accuracy: 55.5%\n",
      "loss: 848.97, accuracy: 55.5%\n",
      "loss: 829.29, accuracy: 60.0%\n",
      "loss: 812.24, accuracy: 67.3%\n",
      "loss: 797.79, accuracy: 71.1%\n",
      "loss: 785.34, accuracy: 70.3%\n",
      "loss: 774.24, accuracy: 70.8%\n",
      "loss: 763.98, accuracy: 71.1%\n",
      "loss: 754.23, accuracy: 70.8%\n",
      "loss: 744.73, accuracy: 71.0%\n",
      "loss: 735.33, accuracy: 71.4%\n",
      "loss: 725.90, accuracy: 71.8%\n",
      "loss: 716.39, accuracy: 71.8%\n",
      "loss: 706.73, accuracy: 73.0%\n",
      "loss: 696.90, accuracy: 73.5%\n",
      "loss: 686.93, accuracy: 74.2%\n",
      "loss: 676.86, accuracy: 74.8%\n",
      "loss: 666.89, accuracy: 76.1%\n",
      "loss: 657.62, accuracy: 76.0%\n",
      "loss: 651.72, accuracy: 77.4%\n",
      "loss: 659.97, accuracy: 74.8%\n",
      "loss: 736.13, accuracy: 71.5%\n",
      "loss: 969.91, accuracy: 51.8%\n",
      "loss: 1292.53, accuracy: 57.9%\n",
      "loss: 882.26, accuracy: 61.5%\n",
      "loss: 690.05, accuracy: 72.3%\n",
      "loss: 668.89, accuracy: 72.5%\n",
      "loss: 654.43, accuracy: 74.3%\n",
      "loss: 640.89, accuracy: 75.2%\n",
      "loss: 627.90, accuracy: 76.6%\n",
      "loss: 615.42, accuracy: 77.3%\n",
      "loss: 603.44, accuracy: 78.0%\n",
      "loss: 592.08, accuracy: 78.8%\n",
      "loss: 581.25, accuracy: 79.7%\n",
      "loss: 570.77, accuracy: 80.0%\n",
      "loss: 560.54, accuracy: 80.2%\n",
      "loss: 550.57, accuracy: 80.7%\n",
      "loss: 540.83, accuracy: 81.2%\n",
      "loss: 531.70, accuracy: 81.6%\n",
      "loss: 525.19, accuracy: 81.5%\n",
      "loss: 530.10, accuracy: 80.8%\n",
      "loss: 594.43, accuracy: 75.7%\n",
      "loss: 821.07, accuracy: 61.2%\n",
      "loss: 1385.45, accuracy: 60.0%\n",
      "loss: 936.60, accuracy: 54.1%\n",
      "loss: 581.34, accuracy: 76.8%\n",
      "loss: 554.63, accuracy: 77.2%\n",
      "loss: 535.52, accuracy: 78.9%\n",
      "loss: 518.44, accuracy: 79.7%\n",
      "loss: 502.84, accuracy: 80.4%\n",
      "loss: 488.70, accuracy: 81.2%\n",
      "loss: 475.93, accuracy: 82.0%\n",
      "loss: 464.03, accuracy: 82.4%\n",
      "loss: 452.84, accuracy: 82.6%\n",
      "loss: 442.44, accuracy: 83.1%\n",
      "loss: 433.44, accuracy: 83.1%\n",
      "loss: 427.79, accuracy: 83.1%\n",
      "loss: 433.95, accuracy: 82.2%\n",
      "loss: 477.91, accuracy: 81.1%\n",
      "loss: 657.51, accuracy: 72.6%\n",
      "loss: 888.35, accuracy: 55.8%\n",
      "loss: 1022.91, accuracy: 63.7%\n",
      "loss: 713.27, accuracy: 69.7%\n",
      "loss: 503.80, accuracy: 79.9%\n",
      "loss: 451.34, accuracy: 80.9%\n",
      "loss: 426.64, accuracy: 82.3%\n",
      "loss: 409.21, accuracy: 84.6%\n",
      "loss: 396.38, accuracy: 83.4%\n",
      "loss: 387.99, accuracy: 86.2%\n",
      "loss: 384.50, accuracy: 83.6%\n",
      "loss: 387.93, accuracy: 87.8%\n",
      "loss: 404.06, accuracy: 82.6%\n",
      "loss: 434.96, accuracy: 86.2%\n",
      "loss: 496.43, accuracy: 77.7%\n",
      "loss: 550.35, accuracy: 77.9%\n",
      "loss: 608.55, accuracy: 74.7%\n",
      "loss: 571.99, accuracy: 77.1%\n",
      "loss: 520.07, accuracy: 78.1%\n",
      "loss: 429.85, accuracy: 84.9%\n",
      "loss: 389.24, accuracy: 84.5%\n",
      "loss: 352.07, accuracy: 89.8%\n",
      "loss: 334.05, accuracy: 85.9%\n",
      "loss: 318.69, accuracy: 92.0%\n",
      "loss: 311.86, accuracy: 87.2%\n",
      "loss: 301.65, accuracy: 93.1%\n",
      "loss: 300.06, accuracy: 87.2%\n",
      "loss: 292.14, accuracy: 93.7%\n",
      "loss: 295.84, accuracy: 87.3%\n",
      "loss: 291.73, accuracy: 93.5%\n",
      "loss: 302.87, accuracy: 86.9%\n",
      "loss: 307.80, accuracy: 92.5%\n",
      "loss: 336.23, accuracy: 86.0%\n",
      "loss: 362.79, accuracy: 88.5%\n",
      "loss: 436.55, accuracy: 80.9%\n",
      "loss: 484.96, accuracy: 79.0%\n",
      "loss: 657.08, accuracy: 75.2%\n",
      "loss: 505.38, accuracy: 77.5%\n",
      "loss: 532.15, accuracy: 81.7%\n",
      "loss: 290.90, accuracy: 87.2%\n",
      "loss: 250.18, accuracy: 92.7%\n",
      "loss: 233.12, accuracy: 90.9%\n",
      "loss: 224.69, accuracy: 93.9%\n",
      "loss: 236.17, accuracy: 90.4%\n",
      "loss: 229.59, accuracy: 94.4%\n",
      "loss: 260.33, accuracy: 88.9%\n",
      "loss: 234.13, accuracy: 94.4%\n",
      "loss: 267.65, accuracy: 88.7%\n",
      "loss: 225.49, accuracy: 95.1%\n",
      "loss: 240.02, accuracy: 89.6%\n",
      "loss: 208.66, accuracy: 95.6%\n",
      "loss: 211.13, accuracy: 90.9%\n",
      "loss: 190.37, accuracy: 95.9%\n",
      "loss: 186.89, accuracy: 92.4%\n",
      "loss: 174.01, accuracy: 96.1%\n",
      "loss: 168.91, accuracy: 93.3%\n",
      "loss: 160.28, accuracy: 96.5%\n",
      "loss: 155.15, accuracy: 95.0%\n",
      "loss: 149.13, accuracy: 96.8%\n",
      "loss: 145.08, accuracy: 95.4%\n",
      "loss: 141.02, accuracy: 96.8%\n",
      "loss: 137.51, accuracy: 95.6%\n",
      "loss: 134.51, accuracy: 97.0%\n",
      "loss: 131.93, accuracy: 95.7%\n",
      "loss: 129.49, accuracy: 97.1%\n",
      "loss: 127.18, accuracy: 96.1%\n",
      "loss: 126.14, accuracy: 97.1%\n",
      "loss: 125.37, accuracy: 96.0%\n",
      "loss: 125.27, accuracy: 97.3%\n",
      "loss: 125.14, accuracy: 96.1%\n",
      "loss: 126.53, accuracy: 97.1%\n",
      "loss: 128.84, accuracy: 95.4%\n",
      "loss: 131.17, accuracy: 97.0%\n",
      "loss: 133.59, accuracy: 95.3%\n",
      "loss: 136.29, accuracy: 96.9%\n",
      "loss: 139.68, accuracy: 94.7%\n",
      "loss: 141.40, accuracy: 96.7%\n",
      "loss: 145.59, accuracy: 94.5%\n",
      "loss: 146.66, accuracy: 96.5%\n",
      "loss: 149.55, accuracy: 94.4%\n",
      "loss: 145.67, accuracy: 96.5%\n",
      "loss: 145.46, accuracy: 94.7%\n",
      "loss: 135.90, accuracy: 96.7%\n",
      "loss: 126.33, accuracy: 96.1%\n",
      "loss: 110.77, accuracy: 97.4%\n",
      "loss: 98.66, accuracy: 97.6%\n",
      "loss: 89.48, accuracy: 98.2%\n",
      "loss: 84.67, accuracy: 98.4%\n",
      "loss: 81.92, accuracy: 98.7%\n",
      "loss: 79.98, accuracy: 98.5%\n",
      "loss: 78.42, accuracy: 98.9%\n",
      "loss: 77.07, accuracy: 98.8%\n",
      "loss: 75.78, accuracy: 99.0%\n",
      "loss: 74.61, accuracy: 98.8%\n",
      "loss: 73.48, accuracy: 99.0%\n",
      "loss: 72.41, accuracy: 98.9%\n",
      "loss: 71.39, accuracy: 99.0%\n",
      "loss: 70.46, accuracy: 98.9%\n",
      "loss: 69.54, accuracy: 99.0%\n",
      "loss: 68.74, accuracy: 98.9%\n",
      "loss: 67.89, accuracy: 99.0%\n",
      "loss: 67.22, accuracy: 99.0%\n",
      "loss: 66.39, accuracy: 99.0%\n",
      "loss: 65.74, accuracy: 98.9%\n",
      "loss: 64.95, accuracy: 99.1%\n",
      "loss: 64.44, accuracy: 99.0%\n",
      "loss: 63.60, accuracy: 99.1%\n",
      "loss: 62.96, accuracy: 99.1%\n",
      "loss: 62.18, accuracy: 99.1%\n",
      "loss: 61.57, accuracy: 99.1%\n",
      "loss: 60.76, accuracy: 99.2%\n",
      "loss: 60.11, accuracy: 99.2%\n",
      "loss: 59.30, accuracy: 99.2%\n",
      "loss: 58.69, accuracy: 99.3%\n",
      "loss: 57.89, accuracy: 99.3%\n",
      "loss: 57.25, accuracy: 99.4%\n",
      "loss: 56.47, accuracy: 99.3%\n",
      "loss: 55.80, accuracy: 99.4%\n",
      "loss: 55.07, accuracy: 99.3%\n",
      "loss: 54.45, accuracy: 99.4%\n",
      "loss: 53.83, accuracy: 99.3%\n",
      "loss: 53.30, accuracy: 99.4%\n",
      "loss: 52.70, accuracy: 99.4%\n",
      "loss: 52.20, accuracy: 99.4%\n",
      "loss: 51.68, accuracy: 99.4%\n",
      "loss: 51.23, accuracy: 99.4%\n",
      "loss: 50.75, accuracy: 99.5%\n",
      "loss: 50.36, accuracy: 99.4%\n",
      "loss: 49.95, accuracy: 99.5%\n",
      "loss: 49.62, accuracy: 99.4%\n",
      "loss: 49.21, accuracy: 99.5%\n",
      "loss: 48.90, accuracy: 99.4%\n",
      "loss: 48.44, accuracy: 99.5%\n",
      "loss: 48.11, accuracy: 99.4%\n",
      "loss: 47.69, accuracy: 99.5%\n",
      "loss: 47.33, accuracy: 99.4%\n",
      "loss: 46.84, accuracy: 99.5%\n",
      "loss: 46.43, accuracy: 99.4%\n",
      "loss: 45.92, accuracy: 99.5%\n",
      "loss: 45.55, accuracy: 99.4%\n",
      "loss: 45.04, accuracy: 99.5%\n",
      "loss: 44.61, accuracy: 99.5%\n",
      "loss: 44.17, accuracy: 99.5%\n",
      "loss: 43.77, accuracy: 99.5%\n",
      "loss: 43.35, accuracy: 99.5%\n",
      "loss: 42.99, accuracy: 99.5%\n",
      "loss: 42.62, accuracy: 99.5%\n",
      "loss: 42.27, accuracy: 99.5%\n",
      "loss: 41.92, accuracy: 99.5%\n",
      "loss: 41.60, accuracy: 99.5%\n",
      "loss: 41.28, accuracy: 99.5%\n",
      "loss: 40.97, accuracy: 99.5%\n",
      "loss: 40.68, accuracy: 99.5%\n",
      "loss: 40.41, accuracy: 99.5%\n",
      "loss: 40.15, accuracy: 99.5%\n",
      "loss: 39.94, accuracy: 99.5%\n",
      "loss: 39.72, accuracy: 99.5%\n",
      "loss: 39.53, accuracy: 99.5%\n",
      "loss: 39.31, accuracy: 99.5%\n",
      "loss: 39.13, accuracy: 99.5%\n",
      "loss: 38.89, accuracy: 99.5%\n",
      "loss: 38.72, accuracy: 99.5%\n",
      "loss: 38.44, accuracy: 99.5%\n",
      "loss: 38.25, accuracy: 99.5%\n",
      "loss: 37.93, accuracy: 99.5%\n",
      "loss: 37.71, accuracy: 99.5%\n",
      "loss: 37.36, accuracy: 99.5%\n",
      "loss: 37.10, accuracy: 99.5%\n",
      "loss: 36.79, accuracy: 99.5%\n",
      "loss: 36.53, accuracy: 99.5%\n",
      "loss: 36.23, accuracy: 99.5%\n",
      "loss: 35.98, accuracy: 99.5%\n",
      "loss: 35.71, accuracy: 99.5%\n",
      "loss: 35.49, accuracy: 99.5%\n",
      "loss: 35.25, accuracy: 99.5%\n",
      "loss: 35.03, accuracy: 99.5%\n",
      "loss: 34.81, accuracy: 99.5%\n",
      "loss: 34.60, accuracy: 99.5%\n",
      "loss: 34.38, accuracy: 99.5%\n",
      "loss: 34.19, accuracy: 99.5%\n",
      "loss: 34.00, accuracy: 99.5%\n",
      "loss: 33.84, accuracy: 99.5%\n",
      "loss: 33.67, accuracy: 99.5%\n",
      "loss: 33.52, accuracy: 99.5%\n",
      "loss: 33.37, accuracy: 99.5%\n",
      "loss: 33.25, accuracy: 99.5%\n",
      "loss: 33.07, accuracy: 99.5%\n",
      "loss: 32.94, accuracy: 99.5%\n",
      "loss: 32.76, accuracy: 99.5%\n",
      "loss: 32.61, accuracy: 99.5%\n",
      "loss: 32.43, accuracy: 99.5%\n",
      "loss: 32.28, accuracy: 99.5%\n",
      "loss: 32.08, accuracy: 99.5%\n",
      "loss: 31.91, accuracy: 99.5%\n",
      "loss: 31.70, accuracy: 99.5%\n",
      "loss: 31.54, accuracy: 99.5%\n",
      "loss: 31.34, accuracy: 99.5%\n",
      "loss: 31.18, accuracy: 99.5%\n",
      "loss: 30.99, accuracy: 99.5%\n",
      "loss: 30.84, accuracy: 99.5%\n",
      "loss: 30.66, accuracy: 99.5%\n",
      "loss: 30.51, accuracy: 99.5%\n",
      "loss: 30.34, accuracy: 99.5%\n",
      "loss: 30.19, accuracy: 99.5%\n",
      "loss: 30.04, accuracy: 99.5%\n",
      "loss: 29.90, accuracy: 99.5%\n",
      "loss: 29.75, accuracy: 99.5%\n",
      "loss: 29.62, accuracy: 99.5%\n",
      "loss: 29.49, accuracy: 99.5%\n",
      "loss: 29.37, accuracy: 99.5%\n",
      "loss: 29.26, accuracy: 99.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29.17, accuracy: 99.5%\n",
      "loss: 29.07, accuracy: 99.5%\n",
      "loss: 28.98, accuracy: 99.5%\n",
      "loss: 28.89, accuracy: 99.5%\n",
      "loss: 28.81, accuracy: 99.5%\n",
      "loss: 28.69, accuracy: 99.5%\n",
      "loss: 28.59, accuracy: 99.5%\n",
      "loss: 28.42, accuracy: 99.5%\n",
      "loss: 28.31, accuracy: 99.5%\n",
      "loss: 28.18, accuracy: 99.5%\n",
      "loss: 28.07, accuracy: 99.5%\n",
      "loss: 27.91, accuracy: 99.5%\n",
      "loss: 27.80, accuracy: 99.5%\n",
      "loss: 27.66, accuracy: 99.5%\n",
      "loss: 27.55, accuracy: 99.5%\n",
      "loss: 27.41, accuracy: 99.5%\n",
      "loss: 27.30, accuracy: 99.5%\n",
      "loss: 27.18, accuracy: 99.5%\n",
      "loss: 27.06, accuracy: 99.5%\n",
      "loss: 26.94, accuracy: 99.5%\n",
      "loss: 26.83, accuracy: 99.5%\n",
      "loss: 26.71, accuracy: 99.5%\n",
      "loss: 26.60, accuracy: 99.5%\n",
      "loss: 26.50, accuracy: 99.5%\n",
      "loss: 26.40, accuracy: 99.5%\n",
      "loss: 26.30, accuracy: 99.5%\n",
      "loss: 26.20, accuracy: 99.5%\n",
      "loss: 26.11, accuracy: 99.5%\n",
      "loss: 26.03, accuracy: 99.5%\n",
      "loss: 25.95, accuracy: 99.5%\n",
      "loss: 25.89, accuracy: 99.5%\n",
      "loss: 25.82, accuracy: 99.5%\n",
      "loss: 25.76, accuracy: 99.5%\n",
      "loss: 25.68, accuracy: 99.5%\n",
      "loss: 25.62, accuracy: 99.5%\n",
      "loss: 25.52, accuracy: 99.5%\n",
      "loss: 25.45, accuracy: 99.5%\n",
      "loss: 25.35, accuracy: 99.5%\n",
      "loss: 25.28, accuracy: 99.5%\n",
      "loss: 25.17, accuracy: 99.5%\n",
      "loss: 25.09, accuracy: 99.5%\n",
      "loss: 24.98, accuracy: 99.5%\n",
      "loss: 24.90, accuracy: 99.5%\n",
      "loss: 24.80, accuracy: 99.5%\n",
      "loss: 24.73, accuracy: 99.5%\n",
      "loss: 24.63, accuracy: 99.5%\n",
      "loss: 24.54, accuracy: 99.5%\n",
      "loss: 24.44, accuracy: 99.5%\n",
      "loss: 24.37, accuracy: 99.5%\n",
      "loss: 24.27, accuracy: 99.5%\n",
      "loss: 24.19, accuracy: 99.5%\n",
      "loss: 24.11, accuracy: 99.5%\n",
      "loss: 24.03, accuracy: 99.5%\n",
      "loss: 23.94, accuracy: 99.5%\n",
      "loss: 23.87, accuracy: 99.5%\n",
      "loss: 23.80, accuracy: 99.5%\n",
      "loss: 23.73, accuracy: 99.5%\n",
      "loss: 23.65, accuracy: 99.5%\n",
      "loss: 23.59, accuracy: 99.5%\n",
      "loss: 23.52, accuracy: 99.5%\n",
      "loss: 23.47, accuracy: 99.5%\n",
      "loss: 23.41, accuracy: 99.5%\n",
      "loss: 23.37, accuracy: 99.5%\n",
      "loss: 23.31, accuracy: 99.5%\n",
      "loss: 23.27, accuracy: 99.5%\n",
      "loss: 23.20, accuracy: 99.5%\n",
      "loss: 23.17, accuracy: 99.5%\n",
      "loss: 23.08, accuracy: 99.5%\n",
      "loss: 23.03, accuracy: 99.5%\n",
      "loss: 22.94, accuracy: 99.5%\n",
      "loss: 22.88, accuracy: 99.5%\n",
      "loss: 22.79, accuracy: 99.5%\n",
      "loss: 22.73, accuracy: 99.5%\n",
      "loss: 22.65, accuracy: 99.5%\n",
      "loss: 22.60, accuracy: 99.5%\n",
      "loss: 22.51, accuracy: 99.5%\n",
      "loss: 22.45, accuracy: 99.5%\n",
      "loss: 22.38, accuracy: 99.5%\n",
      "loss: 22.32, accuracy: 99.5%\n",
      "loss: 22.25, accuracy: 99.5%\n",
      "loss: 22.19, accuracy: 99.5%\n",
      "loss: 22.12, accuracy: 99.5%\n",
      "loss: 22.06, accuracy: 99.5%\n",
      "loss: 22.00, accuracy: 99.5%\n",
      "loss: 21.94, accuracy: 99.5%\n",
      "loss: 21.88, accuracy: 99.5%\n",
      "loss: 21.82, accuracy: 99.5%\n",
      "loss: 21.77, accuracy: 99.5%\n",
      "loss: 21.72, accuracy: 99.5%\n",
      "loss: 21.67, accuracy: 99.5%\n",
      "loss: 21.62, accuracy: 99.5%\n",
      "loss: 21.58, accuracy: 99.5%\n",
      "loss: 21.55, accuracy: 99.5%\n",
      "loss: 21.51, accuracy: 99.5%\n",
      "loss: 21.49, accuracy: 99.5%\n",
      "loss: 21.44, accuracy: 99.5%\n",
      "loss: 21.43, accuracy: 99.5%\n",
      "loss: 21.36, accuracy: 99.5%\n",
      "loss: 21.34, accuracy: 99.5%\n",
      "loss: 21.26, accuracy: 99.5%\n",
      "loss: 21.23, accuracy: 99.5%\n",
      "loss: 21.15, accuracy: 99.5%\n",
      "loss: 21.12, accuracy: 99.5%\n",
      "loss: 21.05, accuracy: 99.5%\n",
      "loss: 21.03, accuracy: 99.5%\n",
      "loss: 20.95, accuracy: 99.5%\n",
      "loss: 20.92, accuracy: 99.5%\n",
      "loss: 20.85, accuracy: 99.5%\n",
      "loss: 20.81, accuracy: 99.5%\n",
      "loss: 20.75, accuracy: 99.5%\n",
      "loss: 20.72, accuracy: 99.5%\n",
      "loss: 20.66, accuracy: 99.5%\n",
      "loss: 20.62, accuracy: 99.5%\n",
      "loss: 20.56, accuracy: 99.5%\n",
      "loss: 20.53, accuracy: 99.5%\n",
      "loss: 20.47, accuracy: 99.5%\n",
      "loss: 20.43, accuracy: 99.5%\n",
      "loss: 20.37, accuracy: 99.5%\n",
      "loss: 20.34, accuracy: 99.5%\n",
      "loss: 20.29, accuracy: 99.5%\n",
      "loss: 20.25, accuracy: 99.5%\n",
      "loss: 20.21, accuracy: 99.5%\n"
     ]
    }
   ],
   "source": [
    "mlp.train(x_train, y_train, 400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
